{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MainSportsBetting.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMlWdZdiBPmbmK9d6F2uWCm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-OGicb-LODOw","executionInfo":{"status":"ok","timestamp":1602917518859,"user_tz":420,"elapsed":484,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"0d6da2d7-6b20-42c4-978d-ee7c0223855d","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","import pathlib\n","drive.mount('/content/drive')\n","drive_dir = pathlib.Path.cwd() / 'drive' / 'My Drive' / 'Stanford SCPD' / 'CS221' / 'project'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXq7sKFvSusJ","executionInfo":{"status":"ok","timestamp":1602917527725,"user_tz":420,"elapsed":9341,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"8cb256c2-874c-4111-9532-f243857a9910","colab":{"base_uri":"https://localhost:8080/","height":836}},"source":["!pip install ray==0.8.0\n","!pip install selenium\n","!pip install pandas==1.0.0\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ray==0.8.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (1.3.0)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (1.18.5)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (3.6.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (20.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (3.13)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (0.4.4)\n","Requirement already satisfied: redis>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (3.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (3.0.12)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (3.12.4)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (2.6.0)\n","Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (7.1.2)\n","Requirement already satisfied: funcsigs in /usr/local/lib/python3.6/dist-packages (from ray==0.8.0) (1.0.2)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (1.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (1.9.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (20.2.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (0.7.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (50.3.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray==0.8.0) (8.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ray==0.8.0) (2.4.7)\n","Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n","Requirement already satisfied: pandas==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (2.8.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (1.18.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.0) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.0) (1.15.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e8G9p8e4z3jo","executionInfo":{"status":"ok","timestamp":1602917527726,"user_tz":420,"elapsed":9316,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"5dc0ac42-ed54-4c62-acaa-146c2e52797c","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["#import ray\n","import os\n","os.chdir('/content/drive/My Drive/Stanford SCPD/CS221/project/code')\n","!ls -a"],"execution_count":3,"outputs":[{"output_type":"stream","text":[" add-odds.ipynb\t\t\t\t  player_model.py\n"," baseline.py\t\t\t\t  player_model_v2.py\n"," config.py\t\t\t\t  player_scraper.py\n"," gamelog_scraper.py\t\t\t  Profitability.ipynb\n"," geckodriver.log\t\t\t  __pycache__\n"," hparam.py\t\t\t\t  results.txt\n"," .idea\t\t\t\t\t  ret.py\n"," MainSportsBetting.ipynb\t\t 'Sportsbook Odds Scraper.ipynb'\n"," model_john.py\t\t\t\t  team_gamelog.ipynb\n"," model.py\t\t\t\t  utils.py\n"," nn_model_OHE.py\t\t\t  webscraper_over_under_odds.py\n"," None\t\t\t\t\t  webscraper.py\n"," parallel_webscraper_over_under_odds.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SF96uwzWSsR1","executionInfo":{"status":"ok","timestamp":1602917527726,"user_tz":420,"elapsed":9103,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}}},"source":["# to run data scraping\n","#%run player_scraper.py"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cl4XYtzSso0X","executionInfo":{"status":"ok","timestamp":1602917527933,"user_tz":420,"elapsed":8399,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"f99bc048-fdab-44f3-c670-fae1738e173e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","print(pd.__version__)\n","import feather"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WzBYwxwWQ49M","executionInfo":{"status":"ok","timestamp":1602919080258,"user_tz":420,"elapsed":1559829,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"14b44471-8977-4822-bff8-a16a1c8ef0d4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model = 'regression'\n","date = '2020-10-06'\n","predictions_moneyline = {}\n","save_processed_data = 0\n","load_processed_data = 1\n","threshold = 216\n","date = '2020-10-06'\n","log_dir_folder = 'moneyline_10-06-20_512_256_lr_5e-3'\n","%run 'player_model.py' -weighted_sampler 0 -lin_layer_size 512 256 -lin_layer_dropout 0.5 0.5 -early_stopping 50 -swa 0 -lr 5e-4 '-date={date}' '-model={model}' '-threshold={threshold}' '-save_processed_data={save_processed_data}' '-load_processed_data={load_processed_data}' '-log_dir_folder={log_dir_folder}'\n","ppp = {k : v.ravel() for k,v in predictions.items()}\n","pr = pd.DataFrame(ppp)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='moneyline_10-06-20_512_256_lr_5e-3', lr=0.0005, model='regression', production=1, save_processed_data=0, scheduler='cosine', swa=0, threshold=216, weighted_sampler=0)\n","is score_diff in Features ? False\n","shape of data before dropping is (49298, 781)\n","shape of data after dropping is (49298, 781)\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a97165c50>\n","Epoch 1 : Train Loss of 4.01996 ; Valid Loss of 1.06798 ; MSE of 1.06798\n","Epoch 2 : Train Loss of 3.28872 ; Valid Loss of 0.70683 ; MSE of 0.70683\n","Epoch 3 : Train Loss of 2.59756 ; Valid Loss of 0.52014 ; MSE of 0.52014\n","Epoch 4 : Train Loss of 2.07469 ; Valid Loss of 0.43088 ; MSE of 0.43088\n","Epoch 5 : Train Loss of 1.66830 ; Valid Loss of 0.41953 ; MSE of 0.41953\n","Epoch 6 : Train Loss of 1.26498 ; Valid Loss of 0.39387 ; MSE of 0.39387\n","Epoch 7 : Train Loss of 0.97314 ; Valid Loss of 0.38996 ; MSE of 0.38996\n","Epoch 8 : Train Loss of 0.71727 ; Valid Loss of 0.41037 ; MSE of 0.41037\n","Epoch 9 : Train Loss of 0.53037 ; Valid Loss of 0.41236 ; MSE of 0.41236\n","Epoch 10 : Train Loss of 0.39809 ; Valid Loss of 0.41766 ; MSE of 0.41766\n","Epoch 11 : Train Loss of 0.29826 ; Valid Loss of 0.43007 ; MSE of 0.43007\n","Epoch 12 : Train Loss of 0.24095 ; Valid Loss of 0.44286 ; MSE of 0.44286\n","Epoch 13 : Train Loss of 0.20558 ; Valid Loss of 0.43669 ; MSE of 0.43669\n","Epoch 14 : Train Loss of 0.18543 ; Valid Loss of 0.43209 ; MSE of 0.43209\n","Epoch 15 : Train Loss of 0.17256 ; Valid Loss of 0.42800 ; MSE of 0.42800\n","Epoch 16 : Train Loss of 0.16598 ; Valid Loss of 0.43286 ; MSE of 0.43286\n","Epoch 17 : Train Loss of 0.16191 ; Valid Loss of 0.42840 ; MSE of 0.42840\n","Epoch 18 : Train Loss of 0.16063 ; Valid Loss of 0.43061 ; MSE of 0.43061\n","Epoch 19 : Train Loss of 0.15977 ; Valid Loss of 0.42837 ; MSE of 0.42837\n","Epoch 20 : Train Loss of 0.15922 ; Valid Loss of 0.42565 ; MSE of 0.42565\n","Epoch 21 : Train Loss of 0.15859 ; Valid Loss of 0.42577 ; MSE of 0.42577\n","Epoch 22 : Train Loss of 0.15834 ; Valid Loss of 0.41832 ; MSE of 0.41832\n","Epoch 23 : Train Loss of 0.15683 ; Valid Loss of 0.42564 ; MSE of 0.42564\n","Epoch 24 : Train Loss of 0.15653 ; Valid Loss of 0.42500 ; MSE of 0.42500\n","Epoch 25 : Train Loss of 0.15645 ; Valid Loss of 0.42102 ; MSE of 0.42102\n","Epoch 26 : Train Loss of 0.15576 ; Valid Loss of 0.43361 ; MSE of 0.43361\n","Epoch 27 : Train Loss of 0.15581 ; Valid Loss of 0.42010 ; MSE of 0.42010\n","Epoch 28 : Train Loss of 0.15489 ; Valid Loss of 0.42510 ; MSE of 0.42510\n","Epoch 29 : Train Loss of 0.15455 ; Valid Loss of 0.41681 ; MSE of 0.41681\n","Epoch 30 : Train Loss of 0.15448 ; Valid Loss of 0.41807 ; MSE of 0.41807\n","Epoch 31 : Train Loss of 0.15338 ; Valid Loss of 0.42187 ; MSE of 0.42187\n","Epoch 32 : Train Loss of 0.15366 ; Valid Loss of 0.41565 ; MSE of 0.41565\n","Epoch 33 : Train Loss of 0.15301 ; Valid Loss of 0.43574 ; MSE of 0.43574\n","Epoch 34 : Train Loss of 0.15297 ; Valid Loss of 0.40600 ; MSE of 0.40600\n","Epoch 35 : Train Loss of 0.15233 ; Valid Loss of 0.41597 ; MSE of 0.41597\n","Epoch 36 : Train Loss of 0.15203 ; Valid Loss of 0.41804 ; MSE of 0.41804\n","Epoch 37 : Train Loss of 0.15210 ; Valid Loss of 0.40937 ; MSE of 0.40937\n","Epoch 38 : Train Loss of 0.15066 ; Valid Loss of 0.41759 ; MSE of 0.41759\n","Epoch 39 : Train Loss of 0.15055 ; Valid Loss of 0.41285 ; MSE of 0.41285\n","Epoch 40 : Train Loss of 0.15007 ; Valid Loss of 0.41810 ; MSE of 0.41810\n","Epoch 41 : Train Loss of 0.15053 ; Valid Loss of 0.41043 ; MSE of 0.41043\n","Epoch 42 : Train Loss of 0.15001 ; Valid Loss of 0.40992 ; MSE of 0.40992\n","Epoch 43 : Train Loss of 0.14942 ; Valid Loss of 0.41257 ; MSE of 0.41257\n","Epoch 44 : Train Loss of 0.14879 ; Valid Loss of 0.41206 ; MSE of 0.41206\n","Epoch 45 : Train Loss of 0.14917 ; Valid Loss of 0.41120 ; MSE of 0.41120\n","Epoch 46 : Train Loss of 0.14817 ; Valid Loss of 0.39978 ; MSE of 0.39978\n","Epoch 47 : Train Loss of 0.14768 ; Valid Loss of 0.39962 ; MSE of 0.39962\n","Epoch 48 : Train Loss of 0.14763 ; Valid Loss of 0.40584 ; MSE of 0.40584\n","Epoch 49 : Train Loss of 0.14664 ; Valid Loss of 0.41926 ; MSE of 0.41926\n","Epoch 50 : Train Loss of 0.14645 ; Valid Loss of 0.40187 ; MSE of 0.40187\n","Epoch 51 : Train Loss of 0.14562 ; Valid Loss of 0.41453 ; MSE of 0.41453\n","Epoch 52 : Train Loss of 0.14491 ; Valid Loss of 0.40382 ; MSE of 0.40382\n","Epoch 53 : Train Loss of 0.14478 ; Valid Loss of 0.41131 ; MSE of 0.41131\n","Epoch 54 : Train Loss of 0.14430 ; Valid Loss of 0.41264 ; MSE of 0.41264\n","Epoch 55 : Train Loss of 0.14338 ; Valid Loss of 0.41018 ; MSE of 0.41018\n","Epoch 56 : Train Loss of 0.14270 ; Valid Loss of 0.41926 ; MSE of 0.41926\n","Epoch 57 : Train Loss of 0.14145 ; Valid Loss of 0.40812 ; MSE of 0.40812\n","Early Stopping, Best Optimal Number of Epoch is 7\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a984556a0>\n","Training For Optimal Number of Epochs 7 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.52012\n","Epoch 1 : Entire Train Loss of 2.77421\n","Epoch 2 : Entire Train Loss of 2.16727\n","Epoch 3 : Entire Train Loss of 1.67723\n","Epoch 4 : Entire Train Loss of 1.31827\n","Epoch 5 : Entire Train Loss of 0.99593\n","Epoch 6 : Entire Train Loss of 0.73919\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a9846d470>\n","Epoch 1 : Train Loss of 3.70820 ; Valid Loss of 1.07713 ; MSE of 1.07713\n","Epoch 2 : Train Loss of 2.94869 ; Valid Loss of 0.76938 ; MSE of 0.76938\n","Epoch 3 : Train Loss of 2.34312 ; Valid Loss of 0.59328 ; MSE of 0.59328\n","Epoch 4 : Train Loss of 1.83221 ; Valid Loss of 0.50779 ; MSE of 0.50779\n","Epoch 5 : Train Loss of 1.43467 ; Valid Loss of 0.46645 ; MSE of 0.46645\n","Epoch 6 : Train Loss of 1.08742 ; Valid Loss of 0.44966 ; MSE of 0.44966\n","Epoch 7 : Train Loss of 0.83090 ; Valid Loss of 0.44572 ; MSE of 0.44572\n","Epoch 8 : Train Loss of 0.60659 ; Valid Loss of 0.42816 ; MSE of 0.42816\n","Epoch 9 : Train Loss of 0.44261 ; Valid Loss of 0.45992 ; MSE of 0.45992\n","Epoch 10 : Train Loss of 0.33147 ; Valid Loss of 0.45515 ; MSE of 0.45515\n","Epoch 11 : Train Loss of 0.26426 ; Valid Loss of 0.45502 ; MSE of 0.45502\n","Epoch 12 : Train Loss of 0.22009 ; Valid Loss of 0.45742 ; MSE of 0.45742\n","Epoch 13 : Train Loss of 0.18937 ; Valid Loss of 0.45188 ; MSE of 0.45188\n","Epoch 14 : Train Loss of 0.17518 ; Valid Loss of 0.43253 ; MSE of 0.43253\n","Epoch 15 : Train Loss of 0.16854 ; Valid Loss of 0.43695 ; MSE of 0.43695\n","Epoch 16 : Train Loss of 0.16341 ; Valid Loss of 0.43287 ; MSE of 0.43287\n","Epoch 17 : Train Loss of 0.16034 ; Valid Loss of 0.43498 ; MSE of 0.43498\n","Epoch 18 : Train Loss of 0.16013 ; Valid Loss of 0.43401 ; MSE of 0.43401\n","Epoch 19 : Train Loss of 0.15953 ; Valid Loss of 0.42833 ; MSE of 0.42833\n","Epoch 20 : Train Loss of 0.15918 ; Valid Loss of 0.42730 ; MSE of 0.42730\n","Epoch 21 : Train Loss of 0.15825 ; Valid Loss of 0.42881 ; MSE of 0.42881\n","Epoch 22 : Train Loss of 0.15783 ; Valid Loss of 0.42462 ; MSE of 0.42462\n","Epoch 23 : Train Loss of 0.15725 ; Valid Loss of 0.42575 ; MSE of 0.42575\n","Epoch 24 : Train Loss of 0.15719 ; Valid Loss of 0.43242 ; MSE of 0.43242\n","Epoch 25 : Train Loss of 0.15646 ; Valid Loss of 0.43292 ; MSE of 0.43292\n","Epoch 26 : Train Loss of 0.15632 ; Valid Loss of 0.42299 ; MSE of 0.42299\n","Epoch 27 : Train Loss of 0.15643 ; Valid Loss of 0.42559 ; MSE of 0.42559\n","Epoch 28 : Train Loss of 0.15490 ; Valid Loss of 0.42621 ; MSE of 0.42621\n","Epoch 29 : Train Loss of 0.15475 ; Valid Loss of 0.41888 ; MSE of 0.41888\n","Epoch 30 : Train Loss of 0.15458 ; Valid Loss of 0.42164 ; MSE of 0.42164\n","Epoch 31 : Train Loss of 0.15381 ; Valid Loss of 0.41582 ; MSE of 0.41582\n","Epoch 32 : Train Loss of 0.15399 ; Valid Loss of 0.42535 ; MSE of 0.42535\n","Epoch 33 : Train Loss of 0.15276 ; Valid Loss of 0.42031 ; MSE of 0.42031\n","Epoch 34 : Train Loss of 0.15267 ; Valid Loss of 0.41739 ; MSE of 0.41739\n","Epoch 35 : Train Loss of 0.15284 ; Valid Loss of 0.42224 ; MSE of 0.42224\n","Epoch 36 : Train Loss of 0.15135 ; Valid Loss of 0.41272 ; MSE of 0.41272\n","Epoch 37 : Train Loss of 0.15232 ; Valid Loss of 0.41428 ; MSE of 0.41428\n","Epoch 38 : Train Loss of 0.15131 ; Valid Loss of 0.42597 ; MSE of 0.42597\n","Epoch 39 : Train Loss of 0.15109 ; Valid Loss of 0.40689 ; MSE of 0.40689\n","Epoch 40 : Train Loss of 0.15068 ; Valid Loss of 0.41288 ; MSE of 0.41288\n","Epoch 41 : Train Loss of 0.15002 ; Valid Loss of 0.40802 ; MSE of 0.40802\n","Epoch 42 : Train Loss of 0.14967 ; Valid Loss of 0.43105 ; MSE of 0.43105\n","Epoch 43 : Train Loss of 0.14900 ; Valid Loss of 0.42008 ; MSE of 0.42008\n","Epoch 44 : Train Loss of 0.14919 ; Valid Loss of 0.40903 ; MSE of 0.40903\n","Epoch 45 : Train Loss of 0.14832 ; Valid Loss of 0.40316 ; MSE of 0.40316\n","Epoch 46 : Train Loss of 0.14833 ; Valid Loss of 0.42131 ; MSE of 0.42131\n","Epoch 47 : Train Loss of 0.14740 ; Valid Loss of 0.42116 ; MSE of 0.42116\n","Epoch 48 : Train Loss of 0.14714 ; Valid Loss of 0.42108 ; MSE of 0.42108\n","Epoch 49 : Train Loss of 0.14612 ; Valid Loss of 0.40813 ; MSE of 0.40813\n","Epoch 50 : Train Loss of 0.14606 ; Valid Loss of 0.42639 ; MSE of 0.42639\n","Epoch 51 : Train Loss of 0.14444 ; Valid Loss of 0.42156 ; MSE of 0.42156\n","Epoch 52 : Train Loss of 0.14446 ; Valid Loss of 0.42865 ; MSE of 0.42865\n","Epoch 53 : Train Loss of 0.14366 ; Valid Loss of 0.42937 ; MSE of 0.42937\n","Epoch 54 : Train Loss of 0.14319 ; Valid Loss of 0.41434 ; MSE of 0.41434\n","Epoch 55 : Train Loss of 0.14250 ; Valid Loss of 0.42504 ; MSE of 0.42504\n","Epoch 56 : Train Loss of 0.14189 ; Valid Loss of 0.42906 ; MSE of 0.42906\n","Epoch 57 : Train Loss of 0.14076 ; Valid Loss of 0.43693 ; MSE of 0.43693\n","Epoch 58 : Train Loss of 0.13944 ; Valid Loss of 0.42793 ; MSE of 0.42793\n","Epoch 59 : Train Loss of 0.13854 ; Valid Loss of 0.42696 ; MSE of 0.42696\n","Epoch 60 : Train Loss of 0.13833 ; Valid Loss of 0.42541 ; MSE of 0.42541\n","Epoch 61 : Train Loss of 0.13790 ; Valid Loss of 0.43253 ; MSE of 0.43253\n","Epoch 62 : Train Loss of 0.13649 ; Valid Loss of 0.44221 ; MSE of 0.44221\n","Epoch 63 : Train Loss of 0.13544 ; Valid Loss of 0.41347 ; MSE of 0.41347\n","Epoch 64 : Train Loss of 0.13462 ; Valid Loss of 0.43182 ; MSE of 0.43182\n","Epoch 65 : Train Loss of 0.13267 ; Valid Loss of 0.42878 ; MSE of 0.42878\n","Epoch 66 : Train Loss of 0.13191 ; Valid Loss of 0.42864 ; MSE of 0.42864\n","Epoch 67 : Train Loss of 0.13040 ; Valid Loss of 0.43877 ; MSE of 0.43877\n","Epoch 68 : Train Loss of 0.12995 ; Valid Loss of 0.43467 ; MSE of 0.43467\n","Epoch 69 : Train Loss of 0.12821 ; Valid Loss of 0.44519 ; MSE of 0.44519\n","Epoch 70 : Train Loss of 0.12657 ; Valid Loss of 0.44774 ; MSE of 0.44774\n","Epoch 71 : Train Loss of 0.12624 ; Valid Loss of 0.44264 ; MSE of 0.44264\n","Epoch 72 : Train Loss of 0.12445 ; Valid Loss of 0.43484 ; MSE of 0.43484\n","Epoch 73 : Train Loss of 0.12436 ; Valid Loss of 0.45037 ; MSE of 0.45037\n","Epoch 74 : Train Loss of 0.12262 ; Valid Loss of 0.44590 ; MSE of 0.44590\n","Epoch 75 : Train Loss of 0.12107 ; Valid Loss of 0.44759 ; MSE of 0.44759\n","Epoch 76 : Train Loss of 0.11950 ; Valid Loss of 0.45369 ; MSE of 0.45369\n","Epoch 77 : Train Loss of 0.11858 ; Valid Loss of 0.45550 ; MSE of 0.45550\n","Epoch 78 : Train Loss of 0.11737 ; Valid Loss of 0.45134 ; MSE of 0.45134\n","Epoch 79 : Train Loss of 0.11652 ; Valid Loss of 0.45151 ; MSE of 0.45151\n","Epoch 80 : Train Loss of 0.11482 ; Valid Loss of 0.44961 ; MSE of 0.44961\n","Epoch 81 : Train Loss of 0.11398 ; Valid Loss of 0.45990 ; MSE of 0.45990\n","Epoch 82 : Train Loss of 0.11311 ; Valid Loss of 0.44100 ; MSE of 0.44100\n","Epoch 83 : Train Loss of 0.11161 ; Valid Loss of 0.44271 ; MSE of 0.44271\n","Epoch 84 : Train Loss of 0.11030 ; Valid Loss of 0.44751 ; MSE of 0.44751\n","Epoch 85 : Train Loss of 0.10930 ; Valid Loss of 0.45712 ; MSE of 0.45712\n","Epoch 86 : Train Loss of 0.10827 ; Valid Loss of 0.45259 ; MSE of 0.45259\n","Epoch 87 : Train Loss of 0.10732 ; Valid Loss of 0.45442 ; MSE of 0.45442\n","Epoch 88 : Train Loss of 0.10603 ; Valid Loss of 0.46321 ; MSE of 0.46321\n","Epoch 89 : Train Loss of 0.10442 ; Valid Loss of 0.46677 ; MSE of 0.46677\n","Epoch 90 : Train Loss of 0.10362 ; Valid Loss of 0.46348 ; MSE of 0.46348\n","Epoch 91 : Train Loss of 0.10196 ; Valid Loss of 0.46777 ; MSE of 0.46777\n","Epoch 92 : Train Loss of 0.10183 ; Valid Loss of 0.45386 ; MSE of 0.45386\n","Epoch 93 : Train Loss of 0.09937 ; Valid Loss of 0.45605 ; MSE of 0.45605\n","Epoch 94 : Train Loss of 0.09987 ; Valid Loss of 0.45643 ; MSE of 0.45643\n","Epoch 95 : Train Loss of 0.09907 ; Valid Loss of 0.44589 ; MSE of 0.44589\n","Early Stopping, Best Optimal Number of Epoch is 45\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a9844e748>\n","Training For Optimal Number of Epochs 45 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.44422\n","Epoch 1 : Entire Train Loss of 2.73636\n","Epoch 2 : Entire Train Loss of 2.10459\n","Epoch 3 : Entire Train Loss of 1.60611\n","Epoch 4 : Entire Train Loss of 1.27986\n","Epoch 5 : Entire Train Loss of 0.94017\n","Epoch 6 : Entire Train Loss of 0.68592\n","Epoch 7 : Entire Train Loss of 0.50244\n","Epoch 8 : Entire Train Loss of 0.36931\n","Epoch 9 : Entire Train Loss of 0.28119\n","Epoch 10 : Entire Train Loss of 0.22876\n","Epoch 11 : Entire Train Loss of 0.19828\n","Epoch 12 : Entire Train Loss of 0.18083\n","Epoch 13 : Entire Train Loss of 0.17272\n","Epoch 14 : Entire Train Loss of 0.16840\n","Epoch 15 : Entire Train Loss of 0.16606\n","Epoch 16 : Entire Train Loss of 0.16487\n","Epoch 17 : Entire Train Loss of 0.16380\n","Epoch 18 : Entire Train Loss of 0.16344\n","Epoch 19 : Entire Train Loss of 0.16245\n","Epoch 20 : Entire Train Loss of 0.16169\n","Epoch 21 : Entire Train Loss of 0.16148\n","Epoch 22 : Entire Train Loss of 0.16109\n","Epoch 23 : Entire Train Loss of 0.15968\n","Epoch 24 : Entire Train Loss of 0.15986\n","Epoch 25 : Entire Train Loss of 0.15943\n","Epoch 26 : Entire Train Loss of 0.15881\n","Epoch 27 : Entire Train Loss of 0.15764\n","Epoch 28 : Entire Train Loss of 0.15737\n","Epoch 29 : Entire Train Loss of 0.15713\n","Epoch 30 : Entire Train Loss of 0.15651\n","Epoch 31 : Entire Train Loss of 0.15622\n","Epoch 32 : Entire Train Loss of 0.15575\n","Epoch 33 : Entire Train Loss of 0.15545\n","Epoch 34 : Entire Train Loss of 0.15473\n","Epoch 35 : Entire Train Loss of 0.15398\n","Epoch 36 : Entire Train Loss of 0.15367\n","Epoch 37 : Entire Train Loss of 0.15327\n","Epoch 38 : Entire Train Loss of 0.15292\n","Epoch 39 : Entire Train Loss of 0.15321\n","Epoch 40 : Entire Train Loss of 0.15243\n","Epoch 41 : Entire Train Loss of 0.15122\n","Epoch 42 : Entire Train Loss of 0.15110\n","Epoch 43 : Entire Train Loss of 0.15018\n","Epoch 44 : Entire Train Loss of 0.15005\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a9844e8d0>\n","Epoch 1 : Train Loss of 3.46141 ; Valid Loss of 0.89475 ; MSE of 0.89475\n","Epoch 2 : Train Loss of 2.74249 ; Valid Loss of 0.60218 ; MSE of 0.60218\n","Epoch 3 : Train Loss of 2.11797 ; Valid Loss of 0.49088 ; MSE of 0.49088\n","Epoch 4 : Train Loss of 1.67646 ; Valid Loss of 0.43521 ; MSE of 0.43521\n","Epoch 5 : Train Loss of 1.30212 ; Valid Loss of 0.41656 ; MSE of 0.41656\n","Epoch 6 : Train Loss of 0.99567 ; Valid Loss of 0.39620 ; MSE of 0.39620\n","Epoch 7 : Train Loss of 0.74599 ; Valid Loss of 0.40581 ; MSE of 0.40581\n","Epoch 8 : Train Loss of 0.56271 ; Valid Loss of 0.42243 ; MSE of 0.42243\n","Epoch 9 : Train Loss of 0.40938 ; Valid Loss of 0.43197 ; MSE of 0.43197\n","Epoch 10 : Train Loss of 0.31385 ; Valid Loss of 0.43927 ; MSE of 0.43927\n","Epoch 11 : Train Loss of 0.25120 ; Valid Loss of 0.44732 ; MSE of 0.44732\n","Epoch 12 : Train Loss of 0.21137 ; Valid Loss of 0.44430 ; MSE of 0.44430\n","Epoch 13 : Train Loss of 0.18797 ; Valid Loss of 0.44516 ; MSE of 0.44516\n","Epoch 14 : Train Loss of 0.17353 ; Valid Loss of 0.43800 ; MSE of 0.43800\n","Epoch 15 : Train Loss of 0.16651 ; Valid Loss of 0.44790 ; MSE of 0.44790\n","Epoch 16 : Train Loss of 0.16299 ; Valid Loss of 0.42883 ; MSE of 0.42883\n","Epoch 17 : Train Loss of 0.16095 ; Valid Loss of 0.43546 ; MSE of 0.43546\n","Epoch 18 : Train Loss of 0.16017 ; Valid Loss of 0.43475 ; MSE of 0.43475\n","Epoch 19 : Train Loss of 0.15903 ; Valid Loss of 0.42795 ; MSE of 0.42795\n","Epoch 20 : Train Loss of 0.15829 ; Valid Loss of 0.42257 ; MSE of 0.42257\n","Epoch 21 : Train Loss of 0.15786 ; Valid Loss of 0.42381 ; MSE of 0.42381\n","Epoch 22 : Train Loss of 0.15742 ; Valid Loss of 0.41959 ; MSE of 0.41959\n","Epoch 23 : Train Loss of 0.15670 ; Valid Loss of 0.42949 ; MSE of 0.42949\n","Epoch 24 : Train Loss of 0.15668 ; Valid Loss of 0.42524 ; MSE of 0.42524\n","Epoch 25 : Train Loss of 0.15600 ; Valid Loss of 0.42474 ; MSE of 0.42474\n","Epoch 26 : Train Loss of 0.15545 ; Valid Loss of 0.42765 ; MSE of 0.42765\n","Epoch 27 : Train Loss of 0.15511 ; Valid Loss of 0.42492 ; MSE of 0.42492\n","Epoch 28 : Train Loss of 0.15471 ; Valid Loss of 0.41969 ; MSE of 0.41969\n","Epoch 29 : Train Loss of 0.15467 ; Valid Loss of 0.42524 ; MSE of 0.42524\n","Epoch 30 : Train Loss of 0.15391 ; Valid Loss of 0.41605 ; MSE of 0.41605\n","Epoch 31 : Train Loss of 0.15372 ; Valid Loss of 0.41632 ; MSE of 0.41632\n","Epoch 32 : Train Loss of 0.15344 ; Valid Loss of 0.41650 ; MSE of 0.41650\n","Epoch 33 : Train Loss of 0.15272 ; Valid Loss of 0.41835 ; MSE of 0.41835\n","Epoch 34 : Train Loss of 0.15218 ; Valid Loss of 0.42286 ; MSE of 0.42286\n","Epoch 35 : Train Loss of 0.15179 ; Valid Loss of 0.41338 ; MSE of 0.41338\n","Epoch 36 : Train Loss of 0.15186 ; Valid Loss of 0.41447 ; MSE of 0.41447\n","Epoch 37 : Train Loss of 0.15142 ; Valid Loss of 0.41495 ; MSE of 0.41495\n","Epoch 38 : Train Loss of 0.15069 ; Valid Loss of 0.41568 ; MSE of 0.41568\n","Epoch 39 : Train Loss of 0.15036 ; Valid Loss of 0.40879 ; MSE of 0.40879\n","Epoch 40 : Train Loss of 0.14956 ; Valid Loss of 0.41177 ; MSE of 0.41177\n","Epoch 41 : Train Loss of 0.14906 ; Valid Loss of 0.41888 ; MSE of 0.41888\n","Epoch 42 : Train Loss of 0.14890 ; Valid Loss of 0.41134 ; MSE of 0.41134\n","Epoch 43 : Train Loss of 0.14853 ; Valid Loss of 0.41221 ; MSE of 0.41221\n","Epoch 44 : Train Loss of 0.14785 ; Valid Loss of 0.41252 ; MSE of 0.41252\n","Epoch 45 : Train Loss of 0.14844 ; Valid Loss of 0.40777 ; MSE of 0.40777\n","Epoch 46 : Train Loss of 0.14756 ; Valid Loss of 0.40264 ; MSE of 0.40264\n","Epoch 47 : Train Loss of 0.14700 ; Valid Loss of 0.41650 ; MSE of 0.41650\n","Epoch 48 : Train Loss of 0.14652 ; Valid Loss of 0.40125 ; MSE of 0.40125\n","Epoch 49 : Train Loss of 0.14599 ; Valid Loss of 0.42607 ; MSE of 0.42607\n","Epoch 50 : Train Loss of 0.14567 ; Valid Loss of 0.41131 ; MSE of 0.41131\n","Epoch 51 : Train Loss of 0.14425 ; Valid Loss of 0.40579 ; MSE of 0.40579\n","Epoch 52 : Train Loss of 0.14403 ; Valid Loss of 0.40928 ; MSE of 0.40928\n","Epoch 53 : Train Loss of 0.14381 ; Valid Loss of 0.41434 ; MSE of 0.41434\n","Epoch 54 : Train Loss of 0.14288 ; Valid Loss of 0.40985 ; MSE of 0.40985\n","Epoch 55 : Train Loss of 0.14190 ; Valid Loss of 0.41934 ; MSE of 0.41934\n","Epoch 56 : Train Loss of 0.14114 ; Valid Loss of 0.40812 ; MSE of 0.40812\n","Early Stopping, Best Optimal Number of Epoch is 6\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a98455ac8>\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.94189\n","Epoch 1 : Entire Train Loss of 3.21115\n","Epoch 2 : Entire Train Loss of 2.48312\n","Epoch 3 : Entire Train Loss of 1.95249\n","Epoch 4 : Entire Train Loss of 1.54404\n","Epoch 5 : Entire Train Loss of 1.15885\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a97165e48>\n","Epoch 1 : Train Loss of 3.73752 ; Valid Loss of 0.92946 ; MSE of 0.92946\n","Epoch 2 : Train Loss of 3.06483 ; Valid Loss of 0.64699 ; MSE of 0.64699\n","Epoch 3 : Train Loss of 2.40847 ; Valid Loss of 0.48646 ; MSE of 0.48646\n","Epoch 4 : Train Loss of 1.88589 ; Valid Loss of 0.41346 ; MSE of 0.41346\n","Epoch 5 : Train Loss of 1.49345 ; Valid Loss of 0.40071 ; MSE of 0.40071\n","Epoch 6 : Train Loss of 1.13691 ; Valid Loss of 0.38564 ; MSE of 0.38564\n","Epoch 7 : Train Loss of 0.85738 ; Valid Loss of 0.40957 ; MSE of 0.40957\n","Epoch 8 : Train Loss of 0.63109 ; Valid Loss of 0.40650 ; MSE of 0.40650\n","Epoch 9 : Train Loss of 0.46149 ; Valid Loss of 0.42218 ; MSE of 0.42218\n","Epoch 10 : Train Loss of 0.35473 ; Valid Loss of 0.42892 ; MSE of 0.42892\n","Epoch 11 : Train Loss of 0.26377 ; Valid Loss of 0.43594 ; MSE of 0.43594\n","Epoch 12 : Train Loss of 0.21741 ; Valid Loss of 0.44596 ; MSE of 0.44596\n","Epoch 13 : Train Loss of 0.19284 ; Valid Loss of 0.43909 ; MSE of 0.43909\n","Epoch 14 : Train Loss of 0.17703 ; Valid Loss of 0.43145 ; MSE of 0.43145\n","Epoch 15 : Train Loss of 0.16733 ; Valid Loss of 0.43390 ; MSE of 0.43390\n","Epoch 16 : Train Loss of 0.16363 ; Valid Loss of 0.42371 ; MSE of 0.42371\n","Epoch 17 : Train Loss of 0.16112 ; Valid Loss of 0.42724 ; MSE of 0.42724\n","Epoch 18 : Train Loss of 0.15983 ; Valid Loss of 0.41365 ; MSE of 0.41365\n","Epoch 19 : Train Loss of 0.16014 ; Valid Loss of 0.41587 ; MSE of 0.41587\n","Epoch 20 : Train Loss of 0.15887 ; Valid Loss of 0.41732 ; MSE of 0.41732\n","Epoch 21 : Train Loss of 0.15859 ; Valid Loss of 0.41518 ; MSE of 0.41518\n","Epoch 22 : Train Loss of 0.15813 ; Valid Loss of 0.41381 ; MSE of 0.41381\n","Epoch 23 : Train Loss of 0.15714 ; Valid Loss of 0.40330 ; MSE of 0.40330\n","Epoch 24 : Train Loss of 0.15718 ; Valid Loss of 0.41077 ; MSE of 0.41077\n","Epoch 25 : Train Loss of 0.15696 ; Valid Loss of 0.41706 ; MSE of 0.41706\n","Epoch 26 : Train Loss of 0.15577 ; Valid Loss of 0.40601 ; MSE of 0.40601\n","Epoch 27 : Train Loss of 0.15544 ; Valid Loss of 0.40797 ; MSE of 0.40797\n","Epoch 28 : Train Loss of 0.15532 ; Valid Loss of 0.41020 ; MSE of 0.41020\n","Epoch 29 : Train Loss of 0.15516 ; Valid Loss of 0.40910 ; MSE of 0.40910\n","Epoch 30 : Train Loss of 0.15435 ; Valid Loss of 0.40458 ; MSE of 0.40458\n","Epoch 31 : Train Loss of 0.15439 ; Valid Loss of 0.40635 ; MSE of 0.40635\n","Epoch 32 : Train Loss of 0.15395 ; Valid Loss of 0.41208 ; MSE of 0.41208\n","Epoch 33 : Train Loss of 0.15321 ; Valid Loss of 0.40664 ; MSE of 0.40664\n","Epoch 34 : Train Loss of 0.15284 ; Valid Loss of 0.41050 ; MSE of 0.41050\n","Epoch 35 : Train Loss of 0.15208 ; Valid Loss of 0.39095 ; MSE of 0.39095\n","Epoch 36 : Train Loss of 0.15216 ; Valid Loss of 0.40671 ; MSE of 0.40671\n","Epoch 37 : Train Loss of 0.15155 ; Valid Loss of 0.39984 ; MSE of 0.39984\n","Epoch 38 : Train Loss of 0.15117 ; Valid Loss of 0.40631 ; MSE of 0.40631\n","Epoch 39 : Train Loss of 0.15131 ; Valid Loss of 0.39345 ; MSE of 0.39345\n","Epoch 40 : Train Loss of 0.15088 ; Valid Loss of 0.40852 ; MSE of 0.40852\n","Epoch 41 : Train Loss of 0.15040 ; Valid Loss of 0.39827 ; MSE of 0.39827\n","Epoch 42 : Train Loss of 0.14958 ; Valid Loss of 0.40433 ; MSE of 0.40433\n","Epoch 43 : Train Loss of 0.14941 ; Valid Loss of 0.40427 ; MSE of 0.40427\n","Epoch 44 : Train Loss of 0.14911 ; Valid Loss of 0.40791 ; MSE of 0.40791\n","Epoch 45 : Train Loss of 0.14871 ; Valid Loss of 0.39380 ; MSE of 0.39380\n","Epoch 46 : Train Loss of 0.14868 ; Valid Loss of 0.37599 ; MSE of 0.37599\n","Epoch 47 : Train Loss of 0.14852 ; Valid Loss of 0.38905 ; MSE of 0.38905\n","Epoch 48 : Train Loss of 0.14788 ; Valid Loss of 0.39792 ; MSE of 0.39792\n","Epoch 49 : Train Loss of 0.14651 ; Valid Loss of 0.38958 ; MSE of 0.38958\n","Epoch 50 : Train Loss of 0.14658 ; Valid Loss of 0.39012 ; MSE of 0.39012\n","Epoch 51 : Train Loss of 0.14586 ; Valid Loss of 0.38659 ; MSE of 0.38659\n","Epoch 52 : Train Loss of 0.14478 ; Valid Loss of 0.38429 ; MSE of 0.38429\n","Epoch 53 : Train Loss of 0.14468 ; Valid Loss of 0.38392 ; MSE of 0.38392\n","Epoch 54 : Train Loss of 0.14418 ; Valid Loss of 0.38603 ; MSE of 0.38603\n","Epoch 55 : Train Loss of 0.14386 ; Valid Loss of 0.40187 ; MSE of 0.40187\n","Epoch 56 : Train Loss of 0.14285 ; Valid Loss of 0.38314 ; MSE of 0.38314\n","Epoch 57 : Train Loss of 0.14167 ; Valid Loss of 0.39195 ; MSE of 0.39195\n","Epoch 58 : Train Loss of 0.14132 ; Valid Loss of 0.39338 ; MSE of 0.39338\n","Epoch 59 : Train Loss of 0.13949 ; Valid Loss of 0.39015 ; MSE of 0.39015\n","Epoch 60 : Train Loss of 0.13960 ; Valid Loss of 0.39946 ; MSE of 0.39946\n","Epoch 61 : Train Loss of 0.13810 ; Valid Loss of 0.39465 ; MSE of 0.39465\n","Epoch 62 : Train Loss of 0.13739 ; Valid Loss of 0.38166 ; MSE of 0.38166\n","Epoch 63 : Train Loss of 0.13712 ; Valid Loss of 0.38849 ; MSE of 0.38849\n","Epoch 64 : Train Loss of 0.13564 ; Valid Loss of 0.39992 ; MSE of 0.39992\n","Epoch 65 : Train Loss of 0.13477 ; Valid Loss of 0.40624 ; MSE of 0.40624\n","Epoch 66 : Train Loss of 0.13342 ; Valid Loss of 0.40431 ; MSE of 0.40431\n","Epoch 67 : Train Loss of 0.13230 ; Valid Loss of 0.39600 ; MSE of 0.39600\n","Epoch 68 : Train Loss of 0.13192 ; Valid Loss of 0.39524 ; MSE of 0.39524\n","Epoch 69 : Train Loss of 0.13051 ; Valid Loss of 0.38763 ; MSE of 0.38763\n","Epoch 70 : Train Loss of 0.12910 ; Valid Loss of 0.40213 ; MSE of 0.40213\n","Epoch 71 : Train Loss of 0.12755 ; Valid Loss of 0.40334 ; MSE of 0.40334\n","Epoch 72 : Train Loss of 0.12658 ; Valid Loss of 0.40205 ; MSE of 0.40205\n","Epoch 73 : Train Loss of 0.12614 ; Valid Loss of 0.40582 ; MSE of 0.40582\n","Epoch 74 : Train Loss of 0.12407 ; Valid Loss of 0.39383 ; MSE of 0.39383\n","Epoch 75 : Train Loss of 0.12248 ; Valid Loss of 0.40070 ; MSE of 0.40070\n","Epoch 76 : Train Loss of 0.12204 ; Valid Loss of 0.40143 ; MSE of 0.40143\n","Epoch 77 : Train Loss of 0.11987 ; Valid Loss of 0.41049 ; MSE of 0.41049\n","Epoch 78 : Train Loss of 0.11953 ; Valid Loss of 0.41936 ; MSE of 0.41936\n","Epoch 79 : Train Loss of 0.11725 ; Valid Loss of 0.40914 ; MSE of 0.40914\n","Epoch 80 : Train Loss of 0.11577 ; Valid Loss of 0.41354 ; MSE of 0.41354\n","Epoch 81 : Train Loss of 0.11621 ; Valid Loss of 0.41084 ; MSE of 0.41084\n","Epoch 82 : Train Loss of 0.11434 ; Valid Loss of 0.40707 ; MSE of 0.40707\n","Epoch 83 : Train Loss of 0.11331 ; Valid Loss of 0.41216 ; MSE of 0.41216\n","Epoch 84 : Train Loss of 0.11236 ; Valid Loss of 0.41497 ; MSE of 0.41497\n","Epoch 85 : Train Loss of 0.11108 ; Valid Loss of 0.42210 ; MSE of 0.42210\n","Epoch 86 : Train Loss of 0.10946 ; Valid Loss of 0.42167 ; MSE of 0.42167\n","Epoch 87 : Train Loss of 0.10849 ; Valid Loss of 0.41535 ; MSE of 0.41535\n","Epoch 88 : Train Loss of 0.10790 ; Valid Loss of 0.41861 ; MSE of 0.41861\n","Epoch 89 : Train Loss of 0.10684 ; Valid Loss of 0.41796 ; MSE of 0.41796\n","Epoch 90 : Train Loss of 0.10394 ; Valid Loss of 0.42526 ; MSE of 0.42526\n","Epoch 91 : Train Loss of 0.10316 ; Valid Loss of 0.40641 ; MSE of 0.40641\n","Epoch 92 : Train Loss of 0.10296 ; Valid Loss of 0.40693 ; MSE of 0.40693\n","Epoch 93 : Train Loss of 0.10224 ; Valid Loss of 0.42544 ; MSE of 0.42544\n","Epoch 94 : Train Loss of 0.10096 ; Valid Loss of 0.41349 ; MSE of 0.41349\n","Epoch 95 : Train Loss of 0.09886 ; Valid Loss of 0.41697 ; MSE of 0.41697\n","Epoch 96 : Train Loss of 0.09861 ; Valid Loss of 0.42119 ; MSE of 0.42119\n","Early Stopping, Best Optimal Number of Epoch is 46\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a9846d208>\n","Training For Optimal Number of Epochs 46 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 4.23624\n","Epoch 1 : Entire Train Loss of 3.35945\n","Epoch 2 : Entire Train Loss of 2.59550\n","Epoch 3 : Entire Train Loss of 2.05715\n","Epoch 4 : Entire Train Loss of 1.61648\n","Epoch 5 : Entire Train Loss of 1.27818\n","Epoch 6 : Entire Train Loss of 0.95218\n","Epoch 7 : Entire Train Loss of 0.71275\n","Epoch 8 : Entire Train Loss of 0.52346\n","Epoch 9 : Entire Train Loss of 0.38690\n","Epoch 10 : Entire Train Loss of 0.29960\n","Epoch 11 : Entire Train Loss of 0.24515\n","Epoch 12 : Entire Train Loss of 0.21149\n","Epoch 13 : Entire Train Loss of 0.18818\n","Epoch 14 : Entire Train Loss of 0.17665\n","Epoch 15 : Entire Train Loss of 0.16896\n","Epoch 16 : Entire Train Loss of 0.16733\n","Epoch 17 : Entire Train Loss of 0.16523\n","Epoch 18 : Entire Train Loss of 0.16466\n","Epoch 19 : Entire Train Loss of 0.16356\n","Epoch 20 : Entire Train Loss of 0.16255\n","Epoch 21 : Entire Train Loss of 0.16225\n","Epoch 22 : Entire Train Loss of 0.16105\n","Epoch 23 : Entire Train Loss of 0.16135\n","Epoch 24 : Entire Train Loss of 0.15983\n","Epoch 25 : Entire Train Loss of 0.15935\n","Epoch 26 : Entire Train Loss of 0.15881\n","Epoch 27 : Entire Train Loss of 0.15881\n","Epoch 28 : Entire Train Loss of 0.15826\n","Epoch 29 : Entire Train Loss of 0.15763\n","Epoch 30 : Entire Train Loss of 0.15695\n","Epoch 31 : Entire Train Loss of 0.15659\n","Epoch 32 : Entire Train Loss of 0.15622\n","Epoch 33 : Entire Train Loss of 0.15559\n","Epoch 34 : Entire Train Loss of 0.15549\n","Epoch 35 : Entire Train Loss of 0.15479\n","Epoch 36 : Entire Train Loss of 0.15448\n","Epoch 37 : Entire Train Loss of 0.15391\n","Epoch 38 : Entire Train Loss of 0.15357\n","Epoch 39 : Entire Train Loss of 0.15328\n","Epoch 40 : Entire Train Loss of 0.15317\n","Epoch 41 : Entire Train Loss of 0.15265\n","Epoch 42 : Entire Train Loss of 0.15188\n","Epoch 43 : Entire Train Loss of 0.15164\n","Epoch 44 : Entire Train Loss of 0.15027\n","Epoch 45 : Entire Train Loss of 0.15029\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a9844eda0>\n","Epoch 1 : Train Loss of 3.67479 ; Valid Loss of 1.41534 ; MSE of 1.41534\n","Epoch 2 : Train Loss of 2.91496 ; Valid Loss of 1.01298 ; MSE of 1.01298\n","Epoch 3 : Train Loss of 2.29532 ; Valid Loss of 0.73411 ; MSE of 0.73411\n","Epoch 4 : Train Loss of 1.77615 ; Valid Loss of 0.61032 ; MSE of 0.61032\n","Epoch 5 : Train Loss of 1.41241 ; Valid Loss of 0.52239 ; MSE of 0.52239\n","Epoch 6 : Train Loss of 1.04349 ; Valid Loss of 0.51465 ; MSE of 0.51465\n","Epoch 7 : Train Loss of 0.78142 ; Valid Loss of 0.49701 ; MSE of 0.49701\n","Epoch 8 : Train Loss of 0.57321 ; Valid Loss of 0.47394 ; MSE of 0.47394\n","Epoch 9 : Train Loss of 0.41537 ; Valid Loss of 0.45081 ; MSE of 0.45081\n","Epoch 10 : Train Loss of 0.31351 ; Valid Loss of 0.46285 ; MSE of 0.46285\n","Epoch 11 : Train Loss of 0.25247 ; Valid Loss of 0.46398 ; MSE of 0.46398\n","Epoch 12 : Train Loss of 0.20903 ; Valid Loss of 0.44496 ; MSE of 0.44496\n","Epoch 13 : Train Loss of 0.18619 ; Valid Loss of 0.45206 ; MSE of 0.45206\n","Epoch 14 : Train Loss of 0.17361 ; Valid Loss of 0.42955 ; MSE of 0.42955\n","Epoch 15 : Train Loss of 0.16711 ; Valid Loss of 0.43909 ; MSE of 0.43909\n","Epoch 16 : Train Loss of 0.16298 ; Valid Loss of 0.42609 ; MSE of 0.42609\n","Epoch 17 : Train Loss of 0.16161 ; Valid Loss of 0.44328 ; MSE of 0.44328\n","Epoch 18 : Train Loss of 0.16034 ; Valid Loss of 0.42859 ; MSE of 0.42859\n","Epoch 19 : Train Loss of 0.15914 ; Valid Loss of 0.42919 ; MSE of 0.42919\n","Epoch 20 : Train Loss of 0.15915 ; Valid Loss of 0.42282 ; MSE of 0.42282\n","Epoch 21 : Train Loss of 0.15844 ; Valid Loss of 0.43186 ; MSE of 0.43186\n","Epoch 22 : Train Loss of 0.15802 ; Valid Loss of 0.42331 ; MSE of 0.42331\n","Epoch 23 : Train Loss of 0.15765 ; Valid Loss of 0.43239 ; MSE of 0.43239\n","Epoch 24 : Train Loss of 0.15682 ; Valid Loss of 0.41944 ; MSE of 0.41944\n","Epoch 25 : Train Loss of 0.15696 ; Valid Loss of 0.41885 ; MSE of 0.41885\n","Epoch 26 : Train Loss of 0.15585 ; Valid Loss of 0.43273 ; MSE of 0.43273\n","Epoch 27 : Train Loss of 0.15544 ; Valid Loss of 0.44001 ; MSE of 0.44001\n","Epoch 28 : Train Loss of 0.15516 ; Valid Loss of 0.41866 ; MSE of 0.41866\n","Epoch 29 : Train Loss of 0.15464 ; Valid Loss of 0.43000 ; MSE of 0.43000\n","Epoch 30 : Train Loss of 0.15442 ; Valid Loss of 0.41905 ; MSE of 0.41905\n","Epoch 31 : Train Loss of 0.15367 ; Valid Loss of 0.42527 ; MSE of 0.42527\n","Epoch 32 : Train Loss of 0.15397 ; Valid Loss of 0.41261 ; MSE of 0.41261\n","Epoch 33 : Train Loss of 0.15294 ; Valid Loss of 0.41194 ; MSE of 0.41194\n","Epoch 34 : Train Loss of 0.15281 ; Valid Loss of 0.41371 ; MSE of 0.41371\n","Epoch 35 : Train Loss of 0.15218 ; Valid Loss of 0.41632 ; MSE of 0.41632\n","Epoch 36 : Train Loss of 0.15195 ; Valid Loss of 0.42944 ; MSE of 0.42944\n","Epoch 37 : Train Loss of 0.15167 ; Valid Loss of 0.42035 ; MSE of 0.42035\n","Epoch 38 : Train Loss of 0.15122 ; Valid Loss of 0.41441 ; MSE of 0.41441\n","Epoch 39 : Train Loss of 0.15049 ; Valid Loss of 0.42030 ; MSE of 0.42030\n","Epoch 40 : Train Loss of 0.15055 ; Valid Loss of 0.41219 ; MSE of 0.41219\n","Epoch 41 : Train Loss of 0.14982 ; Valid Loss of 0.41684 ; MSE of 0.41684\n","Epoch 42 : Train Loss of 0.14958 ; Valid Loss of 0.42176 ; MSE of 0.42176\n","Epoch 43 : Train Loss of 0.14879 ; Valid Loss of 0.41536 ; MSE of 0.41536\n","Epoch 44 : Train Loss of 0.14869 ; Valid Loss of 0.40959 ; MSE of 0.40959\n","Epoch 45 : Train Loss of 0.14786 ; Valid Loss of 0.41974 ; MSE of 0.41974\n","Epoch 46 : Train Loss of 0.14773 ; Valid Loss of 0.42933 ; MSE of 0.42933\n","Epoch 47 : Train Loss of 0.14740 ; Valid Loss of 0.41930 ; MSE of 0.41930\n","Epoch 48 : Train Loss of 0.14729 ; Valid Loss of 0.41311 ; MSE of 0.41311\n","Epoch 49 : Train Loss of 0.14634 ; Valid Loss of 0.42071 ; MSE of 0.42071\n","Epoch 50 : Train Loss of 0.14555 ; Valid Loss of 0.42601 ; MSE of 0.42601\n","Epoch 51 : Train Loss of 0.14502 ; Valid Loss of 0.41888 ; MSE of 0.41888\n","Epoch 52 : Train Loss of 0.14436 ; Valid Loss of 0.40404 ; MSE of 0.40404\n","Epoch 53 : Train Loss of 0.14339 ; Valid Loss of 0.41604 ; MSE of 0.41604\n","Epoch 54 : Train Loss of 0.14303 ; Valid Loss of 0.41373 ; MSE of 0.41373\n","Epoch 55 : Train Loss of 0.14290 ; Valid Loss of 0.41411 ; MSE of 0.41411\n","Epoch 56 : Train Loss of 0.14182 ; Valid Loss of 0.41750 ; MSE of 0.41750\n","Epoch 57 : Train Loss of 0.14127 ; Valid Loss of 0.41221 ; MSE of 0.41221\n","Epoch 58 : Train Loss of 0.14019 ; Valid Loss of 0.42231 ; MSE of 0.42231\n","Epoch 59 : Train Loss of 0.13928 ; Valid Loss of 0.41957 ; MSE of 0.41957\n","Epoch 60 : Train Loss of 0.13793 ; Valid Loss of 0.42718 ; MSE of 0.42718\n","Epoch 61 : Train Loss of 0.13743 ; Valid Loss of 0.42096 ; MSE of 0.42096\n","Epoch 62 : Train Loss of 0.13633 ; Valid Loss of 0.42580 ; MSE of 0.42580\n","Epoch 63 : Train Loss of 0.13609 ; Valid Loss of 0.42897 ; MSE of 0.42897\n","Epoch 64 : Train Loss of 0.13477 ; Valid Loss of 0.42589 ; MSE of 0.42589\n","Epoch 65 : Train Loss of 0.13358 ; Valid Loss of 0.42873 ; MSE of 0.42873\n","Epoch 66 : Train Loss of 0.13240 ; Valid Loss of 0.41666 ; MSE of 0.41666\n","Epoch 67 : Train Loss of 0.13106 ; Valid Loss of 0.43814 ; MSE of 0.43814\n","Epoch 68 : Train Loss of 0.12980 ; Valid Loss of 0.42930 ; MSE of 0.42930\n","Epoch 69 : Train Loss of 0.12855 ; Valid Loss of 0.42630 ; MSE of 0.42630\n","Epoch 70 : Train Loss of 0.12798 ; Valid Loss of 0.43341 ; MSE of 0.43341\n","Epoch 71 : Train Loss of 0.12620 ; Valid Loss of 0.42077 ; MSE of 0.42077\n","Epoch 72 : Train Loss of 0.12526 ; Valid Loss of 0.42883 ; MSE of 0.42883\n","Epoch 73 : Train Loss of 0.12449 ; Valid Loss of 0.43114 ; MSE of 0.43114\n","Epoch 74 : Train Loss of 0.12130 ; Valid Loss of 0.43024 ; MSE of 0.43024\n","Epoch 75 : Train Loss of 0.12141 ; Valid Loss of 0.43620 ; MSE of 0.43620\n","Epoch 76 : Train Loss of 0.12067 ; Valid Loss of 0.43342 ; MSE of 0.43342\n","Epoch 77 : Train Loss of 0.11870 ; Valid Loss of 0.43898 ; MSE of 0.43898\n","Epoch 78 : Train Loss of 0.11754 ; Valid Loss of 0.42889 ; MSE of 0.42889\n","Epoch 79 : Train Loss of 0.11624 ; Valid Loss of 0.44298 ; MSE of 0.44298\n","Epoch 80 : Train Loss of 0.11495 ; Valid Loss of 0.44183 ; MSE of 0.44183\n","Epoch 81 : Train Loss of 0.11407 ; Valid Loss of 0.43184 ; MSE of 0.43184\n","Epoch 82 : Train Loss of 0.11269 ; Valid Loss of 0.44648 ; MSE of 0.44648\n","Epoch 83 : Train Loss of 0.11133 ; Valid Loss of 0.44236 ; MSE of 0.44236\n","Epoch 84 : Train Loss of 0.11019 ; Valid Loss of 0.42265 ; MSE of 0.42265\n","Epoch 85 : Train Loss of 0.10859 ; Valid Loss of 0.43795 ; MSE of 0.43795\n","Epoch 86 : Train Loss of 0.10841 ; Valid Loss of 0.43617 ; MSE of 0.43617\n","Epoch 87 : Train Loss of 0.10672 ; Valid Loss of 0.42797 ; MSE of 0.42797\n","Epoch 88 : Train Loss of 0.10521 ; Valid Loss of 0.43502 ; MSE of 0.43502\n","Epoch 89 : Train Loss of 0.10449 ; Valid Loss of 0.44305 ; MSE of 0.44305\n","Epoch 90 : Train Loss of 0.10350 ; Valid Loss of 0.44202 ; MSE of 0.44202\n","Epoch 91 : Train Loss of 0.10332 ; Valid Loss of 0.42836 ; MSE of 0.42836\n","Epoch 92 : Train Loss of 0.10157 ; Valid Loss of 0.44043 ; MSE of 0.44043\n","Epoch 93 : Train Loss of 0.10096 ; Valid Loss of 0.44703 ; MSE of 0.44703\n","Epoch 94 : Train Loss of 0.09966 ; Valid Loss of 0.43868 ; MSE of 0.43868\n","Epoch 95 : Train Loss of 0.09873 ; Valid Loss of 0.44917 ; MSE of 0.44917\n","Epoch 96 : Train Loss of 0.09777 ; Valid Loss of 0.43919 ; MSE of 0.43919\n","Epoch 97 : Train Loss of 0.09607 ; Valid Loss of 0.43635 ; MSE of 0.43635\n","Epoch 98 : Train Loss of 0.09469 ; Valid Loss of 0.42982 ; MSE of 0.42982\n","Epoch 99 : Train Loss of 0.09360 ; Valid Loss of 0.42540 ; MSE of 0.42540\n","Epoch 100 : Train Loss of 0.09337 ; Valid Loss of 0.44003 ; MSE of 0.44003\n","Epoch 101 : Train Loss of 0.09269 ; Valid Loss of 0.43825 ; MSE of 0.43825\n","Epoch 102 : Train Loss of 0.09217 ; Valid Loss of 0.43711 ; MSE of 0.43711\n","Early Stopping, Best Optimal Number of Epoch is 52\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a984555f8>\n","Training For Optimal Number of Epochs 52 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 4.05225\n","Epoch 1 : Entire Train Loss of 3.18216\n","Epoch 2 : Entire Train Loss of 2.44291\n","Epoch 3 : Entire Train Loss of 1.92668\n","Epoch 4 : Entire Train Loss of 1.51207\n","Epoch 5 : Entire Train Loss of 1.15892\n","Epoch 6 : Entire Train Loss of 0.87615\n","Epoch 7 : Entire Train Loss of 0.64526\n","Epoch 8 : Entire Train Loss of 0.46065\n","Epoch 9 : Entire Train Loss of 0.34307\n","Epoch 10 : Entire Train Loss of 0.26925\n","Epoch 11 : Entire Train Loss of 0.21897\n","Epoch 12 : Entire Train Loss of 0.19331\n","Epoch 13 : Entire Train Loss of 0.17912\n","Epoch 14 : Entire Train Loss of 0.17178\n","Epoch 15 : Entire Train Loss of 0.16793\n","Epoch 16 : Entire Train Loss of 0.16583\n","Epoch 17 : Entire Train Loss of 0.16482\n","Epoch 18 : Entire Train Loss of 0.16397\n","Epoch 19 : Entire Train Loss of 0.16340\n","Epoch 20 : Entire Train Loss of 0.16287\n","Epoch 21 : Entire Train Loss of 0.16271\n","Epoch 22 : Entire Train Loss of 0.16173\n","Epoch 23 : Entire Train Loss of 0.16176\n","Epoch 24 : Entire Train Loss of 0.16081\n","Epoch 25 : Entire Train Loss of 0.16058\n","Epoch 26 : Entire Train Loss of 0.15969\n","Epoch 27 : Entire Train Loss of 0.15970\n","Epoch 28 : Entire Train Loss of 0.15892\n","Epoch 29 : Entire Train Loss of 0.15845\n","Epoch 30 : Entire Train Loss of 0.15812\n","Epoch 31 : Entire Train Loss of 0.15707\n","Epoch 32 : Entire Train Loss of 0.15706\n","Epoch 33 : Entire Train Loss of 0.15639\n","Epoch 34 : Entire Train Loss of 0.15566\n","Epoch 35 : Entire Train Loss of 0.15561\n","Epoch 36 : Entire Train Loss of 0.15491\n","Epoch 37 : Entire Train Loss of 0.15456\n","Epoch 38 : Entire Train Loss of 0.15453\n","Epoch 39 : Entire Train Loss of 0.15336\n","Epoch 40 : Entire Train Loss of 0.15286\n","Epoch 41 : Entire Train Loss of 0.15253\n","Epoch 42 : Entire Train Loss of 0.15239\n","Epoch 43 : Entire Train Loss of 0.15161\n","Epoch 44 : Entire Train Loss of 0.15080\n","Epoch 45 : Entire Train Loss of 0.15065\n","Epoch 46 : Entire Train Loss of 0.15010\n","Epoch 47 : Entire Train Loss of 0.14983\n","Epoch 48 : Entire Train Loss of 0.14909\n","Epoch 49 : Entire Train Loss of 0.14859\n","Epoch 50 : Entire Train Loss of 0.14787\n","Epoch 51 : Entire Train Loss of 0.14735\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60198>\n","Epoch 1 : Train Loss of 4.14610 ; Valid Loss of 1.11201 ; MSE of 1.11201\n","Epoch 2 : Train Loss of 3.24521 ; Valid Loss of 0.72766 ; MSE of 0.72766\n","Epoch 3 : Train Loss of 2.61364 ; Valid Loss of 0.50752 ; MSE of 0.50752\n","Epoch 4 : Train Loss of 2.04402 ; Valid Loss of 0.41590 ; MSE of 0.41590\n","Epoch 5 : Train Loss of 1.60207 ; Valid Loss of 0.36512 ; MSE of 0.36512\n","Epoch 6 : Train Loss of 1.22358 ; Valid Loss of 0.35860 ; MSE of 0.35860\n","Epoch 7 : Train Loss of 0.93726 ; Valid Loss of 0.37037 ; MSE of 0.37037\n","Epoch 8 : Train Loss of 0.66991 ; Valid Loss of 0.38068 ; MSE of 0.38068\n","Epoch 9 : Train Loss of 0.48616 ; Valid Loss of 0.39173 ; MSE of 0.39173\n","Epoch 10 : Train Loss of 0.36345 ; Valid Loss of 0.40489 ; MSE of 0.40489\n","Epoch 11 : Train Loss of 0.28027 ; Valid Loss of 0.42794 ; MSE of 0.42794\n","Epoch 12 : Train Loss of 0.22868 ; Valid Loss of 0.43115 ; MSE of 0.43115\n","Epoch 13 : Train Loss of 0.19842 ; Valid Loss of 0.43832 ; MSE of 0.43832\n","Epoch 14 : Train Loss of 0.17975 ; Valid Loss of 0.41545 ; MSE of 0.41545\n","Epoch 15 : Train Loss of 0.16956 ; Valid Loss of 0.42128 ; MSE of 0.42128\n","Epoch 16 : Train Loss of 0.16504 ; Valid Loss of 0.41740 ; MSE of 0.41740\n","Epoch 17 : Train Loss of 0.16261 ; Valid Loss of 0.42281 ; MSE of 0.42281\n","Epoch 18 : Train Loss of 0.16134 ; Valid Loss of 0.42086 ; MSE of 0.42086\n","Epoch 19 : Train Loss of 0.16048 ; Valid Loss of 0.42459 ; MSE of 0.42459\n","Epoch 20 : Train Loss of 0.15938 ; Valid Loss of 0.42077 ; MSE of 0.42077\n","Epoch 21 : Train Loss of 0.15925 ; Valid Loss of 0.41652 ; MSE of 0.41652\n","Epoch 22 : Train Loss of 0.15795 ; Valid Loss of 0.41717 ; MSE of 0.41717\n","Epoch 23 : Train Loss of 0.15800 ; Valid Loss of 0.40821 ; MSE of 0.40821\n","Epoch 24 : Train Loss of 0.15710 ; Valid Loss of 0.40850 ; MSE of 0.40850\n","Epoch 25 : Train Loss of 0.15700 ; Valid Loss of 0.40168 ; MSE of 0.40168\n","Epoch 26 : Train Loss of 0.15659 ; Valid Loss of 0.40936 ; MSE of 0.40936\n","Epoch 27 : Train Loss of 0.15636 ; Valid Loss of 0.40235 ; MSE of 0.40235\n","Epoch 28 : Train Loss of 0.15555 ; Valid Loss of 0.40472 ; MSE of 0.40472\n","Epoch 29 : Train Loss of 0.15491 ; Valid Loss of 0.40599 ; MSE of 0.40599\n","Epoch 30 : Train Loss of 0.15502 ; Valid Loss of 0.40602 ; MSE of 0.40602\n","Epoch 31 : Train Loss of 0.15451 ; Valid Loss of 0.40943 ; MSE of 0.40943\n","Epoch 32 : Train Loss of 0.15403 ; Valid Loss of 0.40801 ; MSE of 0.40801\n","Epoch 33 : Train Loss of 0.15375 ; Valid Loss of 0.41057 ; MSE of 0.41057\n","Epoch 34 : Train Loss of 0.15300 ; Valid Loss of 0.41129 ; MSE of 0.41129\n","Epoch 35 : Train Loss of 0.15273 ; Valid Loss of 0.40890 ; MSE of 0.40890\n","Epoch 36 : Train Loss of 0.15311 ; Valid Loss of 0.40185 ; MSE of 0.40185\n","Epoch 37 : Train Loss of 0.15233 ; Valid Loss of 0.40586 ; MSE of 0.40586\n","Epoch 38 : Train Loss of 0.15168 ; Valid Loss of 0.41102 ; MSE of 0.41102\n","Epoch 39 : Train Loss of 0.15101 ; Valid Loss of 0.40017 ; MSE of 0.40017\n","Epoch 40 : Train Loss of 0.15071 ; Valid Loss of 0.40192 ; MSE of 0.40192\n","Epoch 41 : Train Loss of 0.15052 ; Valid Loss of 0.42020 ; MSE of 0.42020\n","Epoch 42 : Train Loss of 0.15050 ; Valid Loss of 0.41408 ; MSE of 0.41408\n","Epoch 43 : Train Loss of 0.14970 ; Valid Loss of 0.41497 ; MSE of 0.41497\n","Epoch 44 : Train Loss of 0.14918 ; Valid Loss of 0.41272 ; MSE of 0.41272\n","Epoch 45 : Train Loss of 0.14903 ; Valid Loss of 0.41019 ; MSE of 0.41019\n","Epoch 46 : Train Loss of 0.14858 ; Valid Loss of 0.41783 ; MSE of 0.41783\n","Epoch 47 : Train Loss of 0.14771 ; Valid Loss of 0.40482 ; MSE of 0.40482\n","Epoch 48 : Train Loss of 0.14733 ; Valid Loss of 0.40800 ; MSE of 0.40800\n","Epoch 49 : Train Loss of 0.14725 ; Valid Loss of 0.40269 ; MSE of 0.40269\n","Epoch 50 : Train Loss of 0.14666 ; Valid Loss of 0.40688 ; MSE of 0.40688\n","Epoch 51 : Train Loss of 0.14648 ; Valid Loss of 0.40662 ; MSE of 0.40662\n","Epoch 52 : Train Loss of 0.14540 ; Valid Loss of 0.41378 ; MSE of 0.41378\n","Epoch 53 : Train Loss of 0.14505 ; Valid Loss of 0.40836 ; MSE of 0.40836\n","Epoch 54 : Train Loss of 0.14490 ; Valid Loss of 0.40815 ; MSE of 0.40815\n","Epoch 55 : Train Loss of 0.14385 ; Valid Loss of 0.40493 ; MSE of 0.40493\n","Epoch 56 : Train Loss of 0.14309 ; Valid Loss of 0.41688 ; MSE of 0.41688\n","Early Stopping, Best Optimal Number of Epoch is 6\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60400>\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.81321\n","Epoch 1 : Entire Train Loss of 3.00900\n","Epoch 2 : Entire Train Loss of 2.42628\n","Epoch 3 : Entire Train Loss of 1.88017\n","Epoch 4 : Entire Train Loss of 1.48361\n","Epoch 5 : Entire Train Loss of 1.11823\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60fd0>\n","Epoch 1 : Train Loss of 3.75865 ; Valid Loss of 0.87807 ; MSE of 0.87807\n","Epoch 2 : Train Loss of 2.95835 ; Valid Loss of 0.62591 ; MSE of 0.62591\n","Epoch 3 : Train Loss of 2.32503 ; Valid Loss of 0.44558 ; MSE of 0.44558\n","Epoch 4 : Train Loss of 1.83793 ; Valid Loss of 0.37777 ; MSE of 0.37777\n","Epoch 5 : Train Loss of 1.43637 ; Valid Loss of 0.36249 ; MSE of 0.36249\n","Epoch 6 : Train Loss of 1.09125 ; Valid Loss of 0.35475 ; MSE of 0.35475\n","Epoch 7 : Train Loss of 0.84893 ; Valid Loss of 0.37059 ; MSE of 0.37059\n","Epoch 8 : Train Loss of 0.62960 ; Valid Loss of 0.39093 ; MSE of 0.39093\n","Epoch 9 : Train Loss of 0.47174 ; Valid Loss of 0.41345 ; MSE of 0.41345\n","Epoch 10 : Train Loss of 0.34923 ; Valid Loss of 0.42712 ; MSE of 0.42712\n","Epoch 11 : Train Loss of 0.28050 ; Valid Loss of 0.42424 ; MSE of 0.42424\n","Epoch 12 : Train Loss of 0.23207 ; Valid Loss of 0.43416 ; MSE of 0.43416\n","Epoch 13 : Train Loss of 0.19909 ; Valid Loss of 0.42558 ; MSE of 0.42558\n","Epoch 14 : Train Loss of 0.18190 ; Valid Loss of 0.42851 ; MSE of 0.42851\n","Epoch 15 : Train Loss of 0.17207 ; Valid Loss of 0.43345 ; MSE of 0.43345\n","Epoch 16 : Train Loss of 0.16524 ; Valid Loss of 0.42147 ; MSE of 0.42147\n","Epoch 17 : Train Loss of 0.16258 ; Valid Loss of 0.42414 ; MSE of 0.42414\n","Epoch 18 : Train Loss of 0.16090 ; Valid Loss of 0.42455 ; MSE of 0.42455\n","Epoch 19 : Train Loss of 0.16036 ; Valid Loss of 0.42119 ; MSE of 0.42119\n","Epoch 20 : Train Loss of 0.15904 ; Valid Loss of 0.41540 ; MSE of 0.41540\n","Epoch 21 : Train Loss of 0.15895 ; Valid Loss of 0.41817 ; MSE of 0.41817\n","Epoch 22 : Train Loss of 0.15782 ; Valid Loss of 0.42313 ; MSE of 0.42313\n","Epoch 23 : Train Loss of 0.15753 ; Valid Loss of 0.42093 ; MSE of 0.42093\n","Epoch 24 : Train Loss of 0.15720 ; Valid Loss of 0.41363 ; MSE of 0.41363\n","Epoch 25 : Train Loss of 0.15732 ; Valid Loss of 0.40306 ; MSE of 0.40306\n","Epoch 26 : Train Loss of 0.15648 ; Valid Loss of 0.41510 ; MSE of 0.41510\n","Epoch 27 : Train Loss of 0.15601 ; Valid Loss of 0.41312 ; MSE of 0.41312\n","Epoch 28 : Train Loss of 0.15556 ; Valid Loss of 0.41679 ; MSE of 0.41679\n","Epoch 29 : Train Loss of 0.15524 ; Valid Loss of 0.41384 ; MSE of 0.41384\n","Epoch 30 : Train Loss of 0.15491 ; Valid Loss of 0.42628 ; MSE of 0.42628\n","Epoch 31 : Train Loss of 0.15404 ; Valid Loss of 0.41087 ; MSE of 0.41087\n","Epoch 32 : Train Loss of 0.15375 ; Valid Loss of 0.41455 ; MSE of 0.41455\n","Epoch 33 : Train Loss of 0.15392 ; Valid Loss of 0.40990 ; MSE of 0.40990\n","Epoch 34 : Train Loss of 0.15316 ; Valid Loss of 0.41479 ; MSE of 0.41479\n","Epoch 35 : Train Loss of 0.15316 ; Valid Loss of 0.42443 ; MSE of 0.42443\n","Epoch 36 : Train Loss of 0.15167 ; Valid Loss of 0.41370 ; MSE of 0.41370\n","Epoch 37 : Train Loss of 0.15212 ; Valid Loss of 0.41987 ; MSE of 0.41987\n","Epoch 38 : Train Loss of 0.15163 ; Valid Loss of 0.40405 ; MSE of 0.40405\n","Epoch 39 : Train Loss of 0.15145 ; Valid Loss of 0.41212 ; MSE of 0.41212\n","Epoch 40 : Train Loss of 0.15102 ; Valid Loss of 0.42096 ; MSE of 0.42096\n","Epoch 41 : Train Loss of 0.15043 ; Valid Loss of 0.41842 ; MSE of 0.41842\n","Epoch 42 : Train Loss of 0.14966 ; Valid Loss of 0.40541 ; MSE of 0.40541\n","Epoch 43 : Train Loss of 0.14981 ; Valid Loss of 0.40828 ; MSE of 0.40828\n","Epoch 44 : Train Loss of 0.14874 ; Valid Loss of 0.43170 ; MSE of 0.43170\n","Epoch 45 : Train Loss of 0.14863 ; Valid Loss of 0.42999 ; MSE of 0.42999\n","Epoch 46 : Train Loss of 0.14832 ; Valid Loss of 0.41201 ; MSE of 0.41201\n","Epoch 47 : Train Loss of 0.14733 ; Valid Loss of 0.41273 ; MSE of 0.41273\n","Epoch 48 : Train Loss of 0.14743 ; Valid Loss of 0.41264 ; MSE of 0.41264\n","Epoch 49 : Train Loss of 0.14732 ; Valid Loss of 0.42967 ; MSE of 0.42967\n","Epoch 50 : Train Loss of 0.14639 ; Valid Loss of 0.41858 ; MSE of 0.41858\n","Epoch 51 : Train Loss of 0.14577 ; Valid Loss of 0.41924 ; MSE of 0.41924\n","Epoch 52 : Train Loss of 0.14558 ; Valid Loss of 0.42536 ; MSE of 0.42536\n","Epoch 53 : Train Loss of 0.14429 ; Valid Loss of 0.40970 ; MSE of 0.40970\n","Epoch 54 : Train Loss of 0.14436 ; Valid Loss of 0.42245 ; MSE of 0.42245\n","Epoch 55 : Train Loss of 0.14336 ; Valid Loss of 0.41557 ; MSE of 0.41557\n","Epoch 56 : Train Loss of 0.14280 ; Valid Loss of 0.42501 ; MSE of 0.42501\n","Early Stopping, Best Optimal Number of Epoch is 6\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60ac8>\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.33782\n","Epoch 1 : Entire Train Loss of 2.61144\n","Epoch 2 : Entire Train Loss of 2.02806\n","Epoch 3 : Entire Train Loss of 1.58578\n","Epoch 4 : Entire Train Loss of 1.24782\n","Epoch 5 : Entire Train Loss of 0.96817\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60ac8>\n","Epoch 1 : Train Loss of 3.77085 ; Valid Loss of 0.94792 ; MSE of 0.94792\n","Epoch 2 : Train Loss of 3.06031 ; Valid Loss of 0.66834 ; MSE of 0.66834\n","Epoch 3 : Train Loss of 2.37145 ; Valid Loss of 0.47359 ; MSE of 0.47359\n","Epoch 4 : Train Loss of 1.82975 ; Valid Loss of 0.39158 ; MSE of 0.39158\n","Epoch 5 : Train Loss of 1.46347 ; Valid Loss of 0.36229 ; MSE of 0.36229\n","Epoch 6 : Train Loss of 1.08335 ; Valid Loss of 0.35709 ; MSE of 0.35709\n","Epoch 7 : Train Loss of 0.80688 ; Valid Loss of 0.36399 ; MSE of 0.36399\n","Epoch 8 : Train Loss of 0.59720 ; Valid Loss of 0.38348 ; MSE of 0.38348\n","Epoch 9 : Train Loss of 0.43435 ; Valid Loss of 0.40490 ; MSE of 0.40490\n","Epoch 10 : Train Loss of 0.32618 ; Valid Loss of 0.41266 ; MSE of 0.41266\n","Epoch 11 : Train Loss of 0.25528 ; Valid Loss of 0.43247 ; MSE of 0.43247\n","Epoch 12 : Train Loss of 0.21330 ; Valid Loss of 0.43769 ; MSE of 0.43769\n","Epoch 13 : Train Loss of 0.18823 ; Valid Loss of 0.43854 ; MSE of 0.43854\n","Epoch 14 : Train Loss of 0.17415 ; Valid Loss of 0.42695 ; MSE of 0.42695\n","Epoch 15 : Train Loss of 0.16727 ; Valid Loss of 0.42156 ; MSE of 0.42156\n","Epoch 16 : Train Loss of 0.16262 ; Valid Loss of 0.41700 ; MSE of 0.41700\n","Epoch 17 : Train Loss of 0.16067 ; Valid Loss of 0.41145 ; MSE of 0.41145\n","Epoch 18 : Train Loss of 0.16074 ; Valid Loss of 0.40928 ; MSE of 0.40928\n","Epoch 19 : Train Loss of 0.15852 ; Valid Loss of 0.41153 ; MSE of 0.41153\n","Epoch 20 : Train Loss of 0.15847 ; Valid Loss of 0.41276 ; MSE of 0.41276\n","Epoch 21 : Train Loss of 0.15795 ; Valid Loss of 0.41095 ; MSE of 0.41095\n","Epoch 22 : Train Loss of 0.15763 ; Valid Loss of 0.40103 ; MSE of 0.40103\n","Epoch 23 : Train Loss of 0.15707 ; Valid Loss of 0.41000 ; MSE of 0.41000\n","Epoch 24 : Train Loss of 0.15644 ; Valid Loss of 0.39913 ; MSE of 0.39913\n","Epoch 25 : Train Loss of 0.15584 ; Valid Loss of 0.41936 ; MSE of 0.41936\n","Epoch 26 : Train Loss of 0.15523 ; Valid Loss of 0.40606 ; MSE of 0.40606\n","Epoch 27 : Train Loss of 0.15549 ; Valid Loss of 0.40216 ; MSE of 0.40216\n","Epoch 28 : Train Loss of 0.15494 ; Valid Loss of 0.39431 ; MSE of 0.39431\n","Epoch 29 : Train Loss of 0.15463 ; Valid Loss of 0.39694 ; MSE of 0.39694\n","Epoch 30 : Train Loss of 0.15438 ; Valid Loss of 0.39959 ; MSE of 0.39959\n","Epoch 31 : Train Loss of 0.15397 ; Valid Loss of 0.39839 ; MSE of 0.39839\n","Epoch 32 : Train Loss of 0.15301 ; Valid Loss of 0.39556 ; MSE of 0.39556\n","Epoch 33 : Train Loss of 0.15315 ; Valid Loss of 0.39099 ; MSE of 0.39099\n","Epoch 34 : Train Loss of 0.15246 ; Valid Loss of 0.39450 ; MSE of 0.39450\n","Epoch 35 : Train Loss of 0.15239 ; Valid Loss of 0.39040 ; MSE of 0.39040\n","Epoch 36 : Train Loss of 0.15179 ; Valid Loss of 0.39459 ; MSE of 0.39459\n","Epoch 37 : Train Loss of 0.15166 ; Valid Loss of 0.39274 ; MSE of 0.39274\n","Epoch 38 : Train Loss of 0.15106 ; Valid Loss of 0.39162 ; MSE of 0.39162\n","Epoch 39 : Train Loss of 0.15107 ; Valid Loss of 0.38991 ; MSE of 0.38991\n","Epoch 40 : Train Loss of 0.15059 ; Valid Loss of 0.39051 ; MSE of 0.39051\n","Epoch 41 : Train Loss of 0.15024 ; Valid Loss of 0.39695 ; MSE of 0.39695\n","Epoch 42 : Train Loss of 0.14996 ; Valid Loss of 0.39130 ; MSE of 0.39130\n","Epoch 43 : Train Loss of 0.14902 ; Valid Loss of 0.39797 ; MSE of 0.39797\n","Epoch 44 : Train Loss of 0.14944 ; Valid Loss of 0.38871 ; MSE of 0.38871\n","Epoch 45 : Train Loss of 0.14819 ; Valid Loss of 0.39405 ; MSE of 0.39405\n","Epoch 46 : Train Loss of 0.14780 ; Valid Loss of 0.39556 ; MSE of 0.39556\n","Epoch 47 : Train Loss of 0.14717 ; Valid Loss of 0.38983 ; MSE of 0.38983\n","Epoch 48 : Train Loss of 0.14712 ; Valid Loss of 0.41033 ; MSE of 0.41033\n","Epoch 49 : Train Loss of 0.14666 ; Valid Loss of 0.39987 ; MSE of 0.39987\n","Epoch 50 : Train Loss of 0.14647 ; Valid Loss of 0.39065 ; MSE of 0.39065\n","Epoch 51 : Train Loss of 0.14545 ; Valid Loss of 0.39771 ; MSE of 0.39771\n","Epoch 52 : Train Loss of 0.14460 ; Valid Loss of 0.39990 ; MSE of 0.39990\n","Epoch 53 : Train Loss of 0.14435 ; Valid Loss of 0.39160 ; MSE of 0.39160\n","Epoch 54 : Train Loss of 0.14360 ; Valid Loss of 0.40366 ; MSE of 0.40366\n","Epoch 55 : Train Loss of 0.14302 ; Valid Loss of 0.39497 ; MSE of 0.39497\n","Epoch 56 : Train Loss of 0.14305 ; Valid Loss of 0.39318 ; MSE of 0.39318\n","Early Stopping, Best Optimal Number of Epoch is 6\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e60c18>\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 3.73751\n","Epoch 1 : Entire Train Loss of 2.93366\n","Epoch 2 : Entire Train Loss of 2.33352\n","Epoch 3 : Entire Train Loss of 1.82357\n","Epoch 4 : Entire Train Loss of 1.39992\n","Epoch 5 : Entire Train Loss of 1.09680\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a98455358>\n","Epoch 1 : Train Loss of 4.65201 ; Valid Loss of 0.89059 ; MSE of 0.89059\n","Epoch 2 : Train Loss of 3.66921 ; Valid Loss of 0.58683 ; MSE of 0.58683\n","Epoch 3 : Train Loss of 2.88505 ; Valid Loss of 0.45695 ; MSE of 0.45695\n","Epoch 4 : Train Loss of 2.29076 ; Valid Loss of 0.38139 ; MSE of 0.38139\n","Epoch 5 : Train Loss of 1.78973 ; Valid Loss of 0.35352 ; MSE of 0.35352\n","Epoch 6 : Train Loss of 1.38802 ; Valid Loss of 0.33730 ; MSE of 0.33730\n","Epoch 7 : Train Loss of 1.04829 ; Valid Loss of 0.33378 ; MSE of 0.33378\n","Epoch 8 : Train Loss of 0.76278 ; Valid Loss of 0.35174 ; MSE of 0.35174\n","Epoch 9 : Train Loss of 0.56035 ; Valid Loss of 0.36689 ; MSE of 0.36689\n","Epoch 10 : Train Loss of 0.40597 ; Valid Loss of 0.38630 ; MSE of 0.38630\n","Epoch 11 : Train Loss of 0.30985 ; Valid Loss of 0.39811 ; MSE of 0.39811\n","Epoch 12 : Train Loss of 0.24421 ; Valid Loss of 0.41395 ; MSE of 0.41395\n","Epoch 13 : Train Loss of 0.20555 ; Valid Loss of 0.40822 ; MSE of 0.40822\n","Epoch 14 : Train Loss of 0.18405 ; Valid Loss of 0.41207 ; MSE of 0.41207\n","Epoch 15 : Train Loss of 0.17259 ; Valid Loss of 0.41566 ; MSE of 0.41566\n","Epoch 16 : Train Loss of 0.16590 ; Valid Loss of 0.42030 ; MSE of 0.42030\n","Epoch 17 : Train Loss of 0.16408 ; Valid Loss of 0.41600 ; MSE of 0.41600\n","Epoch 18 : Train Loss of 0.16144 ; Valid Loss of 0.41132 ; MSE of 0.41132\n","Epoch 19 : Train Loss of 0.16038 ; Valid Loss of 0.41084 ; MSE of 0.41084\n","Epoch 20 : Train Loss of 0.15968 ; Valid Loss of 0.40216 ; MSE of 0.40216\n","Epoch 21 : Train Loss of 0.15896 ; Valid Loss of 0.41904 ; MSE of 0.41904\n","Epoch 22 : Train Loss of 0.15816 ; Valid Loss of 0.41380 ; MSE of 0.41380\n","Epoch 23 : Train Loss of 0.15849 ; Valid Loss of 0.40429 ; MSE of 0.40429\n","Epoch 24 : Train Loss of 0.15741 ; Valid Loss of 0.40703 ; MSE of 0.40703\n","Epoch 25 : Train Loss of 0.15761 ; Valid Loss of 0.40664 ; MSE of 0.40664\n","Epoch 26 : Train Loss of 0.15665 ; Valid Loss of 0.40987 ; MSE of 0.40987\n","Epoch 27 : Train Loss of 0.15630 ; Valid Loss of 0.41247 ; MSE of 0.41247\n","Epoch 28 : Train Loss of 0.15608 ; Valid Loss of 0.39821 ; MSE of 0.39821\n","Epoch 29 : Train Loss of 0.15551 ; Valid Loss of 0.40706 ; MSE of 0.40706\n","Epoch 30 : Train Loss of 0.15498 ; Valid Loss of 0.40588 ; MSE of 0.40588\n","Epoch 31 : Train Loss of 0.15444 ; Valid Loss of 0.40832 ; MSE of 0.40832\n","Epoch 32 : Train Loss of 0.15407 ; Valid Loss of 0.41623 ; MSE of 0.41623\n","Epoch 33 : Train Loss of 0.15426 ; Valid Loss of 0.39910 ; MSE of 0.39910\n","Epoch 34 : Train Loss of 0.15296 ; Valid Loss of 0.39863 ; MSE of 0.39863\n","Epoch 35 : Train Loss of 0.15297 ; Valid Loss of 0.40317 ; MSE of 0.40317\n","Epoch 36 : Train Loss of 0.15249 ; Valid Loss of 0.40425 ; MSE of 0.40425\n","Epoch 37 : Train Loss of 0.15207 ; Valid Loss of 0.39771 ; MSE of 0.39771\n","Epoch 38 : Train Loss of 0.15179 ; Valid Loss of 0.40509 ; MSE of 0.40509\n","Epoch 39 : Train Loss of 0.15169 ; Valid Loss of 0.40355 ; MSE of 0.40355\n","Epoch 40 : Train Loss of 0.15064 ; Valid Loss of 0.39613 ; MSE of 0.39613\n","Epoch 41 : Train Loss of 0.15084 ; Valid Loss of 0.40491 ; MSE of 0.40491\n","Epoch 42 : Train Loss of 0.15018 ; Valid Loss of 0.39628 ; MSE of 0.39628\n","Epoch 43 : Train Loss of 0.15046 ; Valid Loss of 0.40276 ; MSE of 0.40276\n","Epoch 44 : Train Loss of 0.14936 ; Valid Loss of 0.40291 ; MSE of 0.40291\n","Epoch 45 : Train Loss of 0.14938 ; Valid Loss of 0.39342 ; MSE of 0.39342\n","Epoch 46 : Train Loss of 0.14865 ; Valid Loss of 0.39475 ; MSE of 0.39475\n","Epoch 47 : Train Loss of 0.14857 ; Valid Loss of 0.38873 ; MSE of 0.38873\n","Epoch 48 : Train Loss of 0.14792 ; Valid Loss of 0.39206 ; MSE of 0.39206\n","Epoch 49 : Train Loss of 0.14797 ; Valid Loss of 0.39351 ; MSE of 0.39351\n","Epoch 50 : Train Loss of 0.14711 ; Valid Loss of 0.39432 ; MSE of 0.39432\n","Epoch 51 : Train Loss of 0.14683 ; Valid Loss of 0.39533 ; MSE of 0.39533\n","Epoch 52 : Train Loss of 0.14609 ; Valid Loss of 0.39616 ; MSE of 0.39616\n","Epoch 53 : Train Loss of 0.14591 ; Valid Loss of 0.40435 ; MSE of 0.40435\n","Epoch 54 : Train Loss of 0.14495 ; Valid Loss of 0.39941 ; MSE of 0.39941\n","Epoch 55 : Train Loss of 0.14446 ; Valid Loss of 0.39985 ; MSE of 0.39985\n","Epoch 56 : Train Loss of 0.14433 ; Valid Loss of 0.41081 ; MSE of 0.41081\n","Epoch 57 : Train Loss of 0.14386 ; Valid Loss of 0.39112 ; MSE of 0.39112\n","Early Stopping, Best Optimal Number of Epoch is 7\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f6a95e65080>\n","Training For Optimal Number of Epochs 7 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 4.00426\n","Epoch 1 : Entire Train Loss of 3.07096\n","Epoch 2 : Entire Train Loss of 2.44129\n","Epoch 3 : Entire Train Loss of 1.96281\n","Epoch 4 : Entire Train Loss of 1.48117\n","Epoch 5 : Entire Train Loss of 1.15620\n","Epoch 6 : Entire Train Loss of 0.89263\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZU27sdfOEalw","executionInfo":{"status":"ok","timestamp":1602045918247,"user_tz":420,"elapsed":3529439,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"a64b4eec-192e-4b6b-fe6f-685d4e22d1c8","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = 'moneyline'\n","date = '2020-10-06'\n","predictions_moneyline = {}\n","save_processed_data = 0\n","load_processed_data = 1\n","threshold = 216\n","date = '2020-10-06'\n","log_dir_folder = 'moneyline_10-06-20_512_256_lr_5e-3'\n","%run 'player_model.py' -lin_layer_size 512 256 -lin_layer_dropout 0.5 0.5 -early_stopping 50 -swa 0 -lr 5e-4 '-date={date}' '-model={model}' '-threshold={threshold}' '-save_processed_data={save_processed_data}' '-load_processed_data={load_processed_data}' '-log_dir_folder={log_dir_folder}'\n","ppp = {k : v.ravel() for k,v in predictions.items()}\n","pr = pd.DataFrame(ppp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='moneyline_10-06-20_512_256_lr_5e-3', lr=0.0005, model='moneyline', production=1, save_processed_data=0, swa=0, threshold=216)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea75f8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.02997 ; Valid Loss of 0.73029 ; Accuracy of 0.55176\n","Epoch 2 : Train Loss of 0.97480 ; Valid Loss of 0.71865 ; Accuracy of 0.57227\n","Epoch 3 : Train Loss of 0.93893 ; Valid Loss of 0.71173 ; Accuracy of 0.58105\n","Epoch 4 : Train Loss of 0.91101 ; Valid Loss of 0.71002 ; Accuracy of 0.58789\n","Epoch 5 : Train Loss of 0.89160 ; Valid Loss of 0.71113 ; Accuracy of 0.58594\n","Epoch 6 : Train Loss of 0.88228 ; Valid Loss of 0.70590 ; Accuracy of 0.58203\n","Epoch 7 : Train Loss of 0.86864 ; Valid Loss of 0.70992 ; Accuracy of 0.58398\n","Epoch 8 : Train Loss of 0.85801 ; Valid Loss of 0.70660 ; Accuracy of 0.58203\n","Epoch 9 : Train Loss of 0.83900 ; Valid Loss of 0.70408 ; Accuracy of 0.59277\n","Epoch 10 : Train Loss of 0.84015 ; Valid Loss of 0.71513 ; Accuracy of 0.58398\n","Epoch 11 : Train Loss of 0.81792 ; Valid Loss of 0.70234 ; Accuracy of 0.59766\n","Epoch 12 : Train Loss of 0.81331 ; Valid Loss of 0.71510 ; Accuracy of 0.58203\n","Epoch 13 : Train Loss of 0.81066 ; Valid Loss of 0.71413 ; Accuracy of 0.58691\n","Epoch 14 : Train Loss of 0.80258 ; Valid Loss of 0.71060 ; Accuracy of 0.59082\n","Epoch 15 : Train Loss of 0.78941 ; Valid Loss of 0.70285 ; Accuracy of 0.59961\n","Epoch 16 : Train Loss of 0.78449 ; Valid Loss of 0.70594 ; Accuracy of 0.58594\n","Epoch 17 : Train Loss of 0.78498 ; Valid Loss of 0.70708 ; Accuracy of 0.59277\n","Epoch 18 : Train Loss of 0.77224 ; Valid Loss of 0.70619 ; Accuracy of 0.59473\n","Epoch 19 : Train Loss of 0.77257 ; Valid Loss of 0.70579 ; Accuracy of 0.58984\n","Epoch 20 : Train Loss of 0.76565 ; Valid Loss of 0.70167 ; Accuracy of 0.60156\n","Epoch 21 : Train Loss of 0.76225 ; Valid Loss of 0.70849 ; Accuracy of 0.58984\n","Epoch 22 : Train Loss of 0.76068 ; Valid Loss of 0.70478 ; Accuracy of 0.59180\n","Epoch 23 : Train Loss of 0.75545 ; Valid Loss of 0.71266 ; Accuracy of 0.58301\n","Epoch 24 : Train Loss of 0.74858 ; Valid Loss of 0.70575 ; Accuracy of 0.58008\n","Epoch 25 : Train Loss of 0.74394 ; Valid Loss of 0.71898 ; Accuracy of 0.57031\n","Epoch 26 : Train Loss of 0.74292 ; Valid Loss of 0.70934 ; Accuracy of 0.58398\n","Epoch 27 : Train Loss of 0.73718 ; Valid Loss of 0.70791 ; Accuracy of 0.58008\n","Epoch 28 : Train Loss of 0.73495 ; Valid Loss of 0.71738 ; Accuracy of 0.57617\n","Epoch 29 : Train Loss of 0.73069 ; Valid Loss of 0.70994 ; Accuracy of 0.58691\n","Epoch 30 : Train Loss of 0.72845 ; Valid Loss of 0.69670 ; Accuracy of 0.58594\n","Epoch 31 : Train Loss of 0.72634 ; Valid Loss of 0.71196 ; Accuracy of 0.57520\n","Epoch 32 : Train Loss of 0.73302 ; Valid Loss of 0.70996 ; Accuracy of 0.58105\n","Epoch 33 : Train Loss of 0.71833 ; Valid Loss of 0.71408 ; Accuracy of 0.56836\n","Epoch 34 : Train Loss of 0.71598 ; Valid Loss of 0.70963 ; Accuracy of 0.58301\n","Epoch 35 : Train Loss of 0.71587 ; Valid Loss of 0.70617 ; Accuracy of 0.58398\n","Epoch 36 : Train Loss of 0.71674 ; Valid Loss of 0.70137 ; Accuracy of 0.58301\n","Epoch 37 : Train Loss of 0.71518 ; Valid Loss of 0.69894 ; Accuracy of 0.58887\n","Epoch 38 : Train Loss of 0.71116 ; Valid Loss of 0.70303 ; Accuracy of 0.57422\n","Epoch 39 : Train Loss of 0.70379 ; Valid Loss of 0.70144 ; Accuracy of 0.59375\n","Epoch 40 : Train Loss of 0.70361 ; Valid Loss of 0.70871 ; Accuracy of 0.58398\n","Epoch 41 : Train Loss of 0.70429 ; Valid Loss of 0.69736 ; Accuracy of 0.59863\n","Epoch 42 : Train Loss of 0.69819 ; Valid Loss of 0.69796 ; Accuracy of 0.58984\n","Epoch 43 : Train Loss of 0.69776 ; Valid Loss of 0.69433 ; Accuracy of 0.58789\n","Epoch 44 : Train Loss of 0.69534 ; Valid Loss of 0.71086 ; Accuracy of 0.57715\n","Epoch 45 : Train Loss of 0.69421 ; Valid Loss of 0.70198 ; Accuracy of 0.58887\n","Epoch 46 : Train Loss of 0.68938 ; Valid Loss of 0.69711 ; Accuracy of 0.58496\n","Epoch 47 : Train Loss of 0.68810 ; Valid Loss of 0.69779 ; Accuracy of 0.58691\n","Epoch 48 : Train Loss of 0.69321 ; Valid Loss of 0.69770 ; Accuracy of 0.58984\n","Epoch 49 : Train Loss of 0.69031 ; Valid Loss of 0.70289 ; Accuracy of 0.58203\n","Epoch 50 : Train Loss of 0.68900 ; Valid Loss of 0.70425 ; Accuracy of 0.58301\n","Epoch 51 : Train Loss of 0.68710 ; Valid Loss of 0.70378 ; Accuracy of 0.58203\n","Epoch 52 : Train Loss of 0.67871 ; Valid Loss of 0.70248 ; Accuracy of 0.58887\n","Epoch 53 : Train Loss of 0.67960 ; Valid Loss of 0.69045 ; Accuracy of 0.59668\n","Epoch 54 : Train Loss of 0.67835 ; Valid Loss of 0.69325 ; Accuracy of 0.59375\n","Epoch 55 : Train Loss of 0.67523 ; Valid Loss of 0.68362 ; Accuracy of 0.59180\n","Epoch 56 : Train Loss of 0.67843 ; Valid Loss of 0.70142 ; Accuracy of 0.59082\n","Epoch 57 : Train Loss of 0.67417 ; Valid Loss of 0.69712 ; Accuracy of 0.59473\n","Epoch 58 : Train Loss of 0.66933 ; Valid Loss of 0.69504 ; Accuracy of 0.58984\n","Epoch 59 : Train Loss of 0.67142 ; Valid Loss of 0.69696 ; Accuracy of 0.59277\n","Epoch 60 : Train Loss of 0.67147 ; Valid Loss of 0.69494 ; Accuracy of 0.59180\n","Epoch 61 : Train Loss of 0.67020 ; Valid Loss of 0.69642 ; Accuracy of 0.59082\n","Epoch 62 : Train Loss of 0.67001 ; Valid Loss of 0.70760 ; Accuracy of 0.59180\n","Epoch 63 : Train Loss of 0.67247 ; Valid Loss of 0.69249 ; Accuracy of 0.59570\n","Epoch 64 : Train Loss of 0.66707 ; Valid Loss of 0.70187 ; Accuracy of 0.58789\n","Epoch 65 : Train Loss of 0.66847 ; Valid Loss of 0.70315 ; Accuracy of 0.58984\n","Epoch 66 : Train Loss of 0.66542 ; Valid Loss of 0.69983 ; Accuracy of 0.59277\n","Epoch 67 : Train Loss of 0.66226 ; Valid Loss of 0.69533 ; Accuracy of 0.59961\n","Epoch 68 : Train Loss of 0.66205 ; Valid Loss of 0.69855 ; Accuracy of 0.59473\n","Epoch 69 : Train Loss of 0.65687 ; Valid Loss of 0.70231 ; Accuracy of 0.58984\n","Epoch 70 : Train Loss of 0.65938 ; Valid Loss of 0.70616 ; Accuracy of 0.58789\n","Epoch 71 : Train Loss of 0.66235 ; Valid Loss of 0.70437 ; Accuracy of 0.59180\n","Epoch 72 : Train Loss of 0.65817 ; Valid Loss of 0.69990 ; Accuracy of 0.59180\n","Epoch 73 : Train Loss of 0.65674 ; Valid Loss of 0.70166 ; Accuracy of 0.59668\n","Epoch 74 : Train Loss of 0.65264 ; Valid Loss of 0.69608 ; Accuracy of 0.59961\n","Epoch 75 : Train Loss of 0.65592 ; Valid Loss of 0.70076 ; Accuracy of 0.59766\n","Epoch 76 : Train Loss of 0.65808 ; Valid Loss of 0.68868 ; Accuracy of 0.60742\n","Epoch 77 : Train Loss of 0.65196 ; Valid Loss of 0.69267 ; Accuracy of 0.59766\n","Epoch 78 : Train Loss of 0.65556 ; Valid Loss of 0.70390 ; Accuracy of 0.59277\n","Epoch 79 : Train Loss of 0.65410 ; Valid Loss of 0.69347 ; Accuracy of 0.60645\n","Epoch 80 : Train Loss of 0.65333 ; Valid Loss of 0.69286 ; Accuracy of 0.59570\n","Epoch 81 : Train Loss of 0.64819 ; Valid Loss of 0.69674 ; Accuracy of 0.59766\n","Epoch 82 : Train Loss of 0.65114 ; Valid Loss of 0.69976 ; Accuracy of 0.59961\n","Epoch 83 : Train Loss of 0.64596 ; Valid Loss of 0.70231 ; Accuracy of 0.60352\n","Epoch 84 : Train Loss of 0.64680 ; Valid Loss of 0.69638 ; Accuracy of 0.60742\n","Epoch 85 : Train Loss of 0.64753 ; Valid Loss of 0.70039 ; Accuracy of 0.59473\n","Epoch 86 : Train Loss of 0.64754 ; Valid Loss of 0.70791 ; Accuracy of 0.59570\n","Epoch 87 : Train Loss of 0.64584 ; Valid Loss of 0.70709 ; Accuracy of 0.58691\n","Epoch 88 : Train Loss of 0.64573 ; Valid Loss of 0.69943 ; Accuracy of 0.59570\n","Epoch 89 : Train Loss of 0.63988 ; Valid Loss of 0.70666 ; Accuracy of 0.59375\n","Epoch 90 : Train Loss of 0.64238 ; Valid Loss of 0.69442 ; Accuracy of 0.59766\n","Epoch 91 : Train Loss of 0.64391 ; Valid Loss of 0.68619 ; Accuracy of 0.60449\n","Epoch 92 : Train Loss of 0.64152 ; Valid Loss of 0.69747 ; Accuracy of 0.60156\n","Epoch 93 : Train Loss of 0.64255 ; Valid Loss of 0.69432 ; Accuracy of 0.60156\n","Epoch 94 : Train Loss of 0.63775 ; Valid Loss of 0.70335 ; Accuracy of 0.58594\n","Epoch 95 : Train Loss of 0.64117 ; Valid Loss of 0.70109 ; Accuracy of 0.58984\n","Epoch 96 : Train Loss of 0.63670 ; Valid Loss of 0.69911 ; Accuracy of 0.59277\n","Epoch 97 : Train Loss of 0.63878 ; Valid Loss of 0.69007 ; Accuracy of 0.60156\n","Epoch 98 : Train Loss of 0.64160 ; Valid Loss of 0.70263 ; Accuracy of 0.59277\n","Epoch 99 : Train Loss of 0.63729 ; Valid Loss of 0.71129 ; Accuracy of 0.58887\n","Epoch 100 : Train Loss of 0.63599 ; Valid Loss of 0.69011 ; Accuracy of 0.59766\n","Epoch 101 : Train Loss of 0.63304 ; Valid Loss of 0.70532 ; Accuracy of 0.58984\n","Epoch 102 : Train Loss of 0.63470 ; Valid Loss of 0.71408 ; Accuracy of 0.58203\n","Epoch 103 : Train Loss of 0.63481 ; Valid Loss of 0.69999 ; Accuracy of 0.59961\n","Epoch 104 : Train Loss of 0.63149 ; Valid Loss of 0.70835 ; Accuracy of 0.59277\n","Epoch 105 : Train Loss of 0.63100 ; Valid Loss of 0.69761 ; Accuracy of 0.60449\n","Early Stopping, Best Optimal Number of Epoch is 55\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea7198>\n","Training For Optimal Number of Epochs 55 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.02946\n","Epoch 1 : Entire Train Loss of 0.94006\n","Epoch 2 : Entire Train Loss of 0.87045\n","Epoch 3 : Entire Train Loss of 0.80289\n","Epoch 4 : Entire Train Loss of 0.76574\n","Epoch 5 : Entire Train Loss of 0.73624\n","Epoch 6 : Entire Train Loss of 0.70740\n","Epoch 7 : Entire Train Loss of 0.68936\n","Epoch 8 : Entire Train Loss of 0.66984\n","Epoch 9 : Entire Train Loss of 0.65874\n","Epoch 10 : Entire Train Loss of 0.64816\n","Epoch 11 : Entire Train Loss of 0.63930\n","Epoch 12 : Entire Train Loss of 0.63541\n","Epoch 13 : Entire Train Loss of 0.62710\n","Epoch 14 : Entire Train Loss of 0.62162\n","Epoch 15 : Entire Train Loss of 0.61549\n","Epoch 16 : Entire Train Loss of 0.61318\n","Epoch 17 : Entire Train Loss of 0.60921\n","Epoch 18 : Entire Train Loss of 0.60445\n","Epoch 19 : Entire Train Loss of 0.60272\n","Epoch 20 : Entire Train Loss of 0.60131\n","Epoch 21 : Entire Train Loss of 0.59835\n","Epoch 22 : Entire Train Loss of 0.59622\n","Epoch 23 : Entire Train Loss of 0.59440\n","Epoch 24 : Entire Train Loss of 0.58999\n","Epoch 25 : Entire Train Loss of 0.58872\n","Epoch 26 : Entire Train Loss of 0.58409\n","Epoch 27 : Entire Train Loss of 0.58286\n","Epoch 28 : Entire Train Loss of 0.57847\n","Epoch 29 : Entire Train Loss of 0.57603\n","Epoch 30 : Entire Train Loss of 0.57238\n","Epoch 31 : Entire Train Loss of 0.56956\n","Epoch 32 : Entire Train Loss of 0.56406\n","Epoch 33 : Entire Train Loss of 0.56228\n","Epoch 34 : Entire Train Loss of 0.55773\n","Epoch 35 : Entire Train Loss of 0.55265\n","Epoch 36 : Entire Train Loss of 0.54752\n","Epoch 37 : Entire Train Loss of 0.54589\n","Epoch 38 : Entire Train Loss of 0.54141\n","Epoch 39 : Entire Train Loss of 0.53519\n","Epoch 40 : Entire Train Loss of 0.53133\n","Epoch 41 : Entire Train Loss of 0.52509\n","Epoch 42 : Entire Train Loss of 0.51881\n","Epoch 43 : Entire Train Loss of 0.51508\n","Epoch 44 : Entire Train Loss of 0.51171\n","Epoch 45 : Entire Train Loss of 0.50778\n","Epoch 46 : Entire Train Loss of 0.50150\n","Epoch 47 : Entire Train Loss of 0.49502\n","Epoch 48 : Entire Train Loss of 0.49200\n","Epoch 49 : Entire Train Loss of 0.48502\n","Epoch 50 : Entire Train Loss of 0.48017\n","Epoch 51 : Entire Train Loss of 0.47679\n","Epoch 52 : Entire Train Loss of 0.46988\n","Epoch 53 : Entire Train Loss of 0.46499\n","Epoch 54 : Entire Train Loss of 0.46153\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea1db38>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.01662 ; Valid Loss of 0.75916 ; Accuracy of 0.52344\n","Epoch 2 : Train Loss of 0.94966 ; Valid Loss of 0.74406 ; Accuracy of 0.53516\n","Epoch 3 : Train Loss of 0.91330 ; Valid Loss of 0.73220 ; Accuracy of 0.54590\n","Epoch 4 : Train Loss of 0.90049 ; Valid Loss of 0.72984 ; Accuracy of 0.55664\n","Epoch 5 : Train Loss of 0.88137 ; Valid Loss of 0.72860 ; Accuracy of 0.55566\n","Epoch 6 : Train Loss of 0.86260 ; Valid Loss of 0.71567 ; Accuracy of 0.56934\n","Epoch 7 : Train Loss of 0.83987 ; Valid Loss of 0.71395 ; Accuracy of 0.56934\n","Epoch 8 : Train Loss of 0.83139 ; Valid Loss of 0.71059 ; Accuracy of 0.57324\n","Epoch 9 : Train Loss of 0.82192 ; Valid Loss of 0.70886 ; Accuracy of 0.57617\n","Epoch 10 : Train Loss of 0.81646 ; Valid Loss of 0.71427 ; Accuracy of 0.56836\n","Epoch 11 : Train Loss of 0.80078 ; Valid Loss of 0.71213 ; Accuracy of 0.57227\n","Epoch 12 : Train Loss of 0.80043 ; Valid Loss of 0.69863 ; Accuracy of 0.59570\n","Epoch 13 : Train Loss of 0.79361 ; Valid Loss of 0.71709 ; Accuracy of 0.57422\n","Epoch 14 : Train Loss of 0.78322 ; Valid Loss of 0.70297 ; Accuracy of 0.58984\n","Epoch 15 : Train Loss of 0.78138 ; Valid Loss of 0.70040 ; Accuracy of 0.59082\n","Epoch 16 : Train Loss of 0.77361 ; Valid Loss of 0.70536 ; Accuracy of 0.58691\n","Epoch 17 : Train Loss of 0.76974 ; Valid Loss of 0.70773 ; Accuracy of 0.58594\n","Epoch 18 : Train Loss of 0.75934 ; Valid Loss of 0.69651 ; Accuracy of 0.59863\n","Epoch 19 : Train Loss of 0.75240 ; Valid Loss of 0.69740 ; Accuracy of 0.58496\n","Epoch 20 : Train Loss of 0.75648 ; Valid Loss of 0.70180 ; Accuracy of 0.59082\n","Epoch 21 : Train Loss of 0.74860 ; Valid Loss of 0.70882 ; Accuracy of 0.59082\n","Epoch 22 : Train Loss of 0.74050 ; Valid Loss of 0.69909 ; Accuracy of 0.58398\n","Epoch 23 : Train Loss of 0.74530 ; Valid Loss of 0.71039 ; Accuracy of 0.58008\n","Epoch 24 : Train Loss of 0.73765 ; Valid Loss of 0.70909 ; Accuracy of 0.58105\n","Epoch 25 : Train Loss of 0.73501 ; Valid Loss of 0.69909 ; Accuracy of 0.57910\n","Epoch 26 : Train Loss of 0.73331 ; Valid Loss of 0.70354 ; Accuracy of 0.59473\n","Epoch 27 : Train Loss of 0.72281 ; Valid Loss of 0.69683 ; Accuracy of 0.59180\n","Epoch 28 : Train Loss of 0.72123 ; Valid Loss of 0.69594 ; Accuracy of 0.59180\n","Epoch 29 : Train Loss of 0.72154 ; Valid Loss of 0.70499 ; Accuracy of 0.58789\n","Epoch 30 : Train Loss of 0.72147 ; Valid Loss of 0.68535 ; Accuracy of 0.60742\n","Epoch 31 : Train Loss of 0.72010 ; Valid Loss of 0.69283 ; Accuracy of 0.59668\n","Epoch 32 : Train Loss of 0.71294 ; Valid Loss of 0.70378 ; Accuracy of 0.58008\n","Epoch 33 : Train Loss of 0.70939 ; Valid Loss of 0.70508 ; Accuracy of 0.58496\n","Epoch 34 : Train Loss of 0.70892 ; Valid Loss of 0.70136 ; Accuracy of 0.59180\n","Epoch 35 : Train Loss of 0.70679 ; Valid Loss of 0.69694 ; Accuracy of 0.58887\n","Epoch 36 : Train Loss of 0.70021 ; Valid Loss of 0.68949 ; Accuracy of 0.59570\n","Epoch 37 : Train Loss of 0.70059 ; Valid Loss of 0.70316 ; Accuracy of 0.58203\n","Epoch 38 : Train Loss of 0.70709 ; Valid Loss of 0.70153 ; Accuracy of 0.58691\n","Epoch 39 : Train Loss of 0.69757 ; Valid Loss of 0.68807 ; Accuracy of 0.59863\n","Epoch 40 : Train Loss of 0.69996 ; Valid Loss of 0.69627 ; Accuracy of 0.58594\n","Epoch 41 : Train Loss of 0.69579 ; Valid Loss of 0.70124 ; Accuracy of 0.59277\n","Epoch 42 : Train Loss of 0.69209 ; Valid Loss of 0.69654 ; Accuracy of 0.59180\n","Epoch 43 : Train Loss of 0.68760 ; Valid Loss of 0.69898 ; Accuracy of 0.59082\n","Epoch 44 : Train Loss of 0.69046 ; Valid Loss of 0.69805 ; Accuracy of 0.59375\n","Epoch 45 : Train Loss of 0.68564 ; Valid Loss of 0.69813 ; Accuracy of 0.58984\n","Epoch 46 : Train Loss of 0.68191 ; Valid Loss of 0.68653 ; Accuracy of 0.60742\n","Epoch 47 : Train Loss of 0.68391 ; Valid Loss of 0.69627 ; Accuracy of 0.59082\n","Epoch 48 : Train Loss of 0.67790 ; Valid Loss of 0.69433 ; Accuracy of 0.58887\n","Epoch 49 : Train Loss of 0.67449 ; Valid Loss of 0.69446 ; Accuracy of 0.59375\n","Epoch 50 : Train Loss of 0.67862 ; Valid Loss of 0.69679 ; Accuracy of 0.58887\n","Epoch 51 : Train Loss of 0.67914 ; Valid Loss of 0.70081 ; Accuracy of 0.58984\n","Epoch 52 : Train Loss of 0.67368 ; Valid Loss of 0.69462 ; Accuracy of 0.58887\n","Epoch 53 : Train Loss of 0.67446 ; Valid Loss of 0.69771 ; Accuracy of 0.59375\n","Epoch 54 : Train Loss of 0.67079 ; Valid Loss of 0.69163 ; Accuracy of 0.59375\n","Epoch 55 : Train Loss of 0.66711 ; Valid Loss of 0.69270 ; Accuracy of 0.58887\n","Epoch 56 : Train Loss of 0.66502 ; Valid Loss of 0.69168 ; Accuracy of 0.58301\n","Epoch 57 : Train Loss of 0.66828 ; Valid Loss of 0.70316 ; Accuracy of 0.58105\n","Epoch 58 : Train Loss of 0.66665 ; Valid Loss of 0.69587 ; Accuracy of 0.58398\n","Epoch 59 : Train Loss of 0.66688 ; Valid Loss of 0.68731 ; Accuracy of 0.59180\n","Epoch 60 : Train Loss of 0.66553 ; Valid Loss of 0.69629 ; Accuracy of 0.58203\n","Epoch 61 : Train Loss of 0.65980 ; Valid Loss of 0.69128 ; Accuracy of 0.58398\n","Epoch 62 : Train Loss of 0.66457 ; Valid Loss of 0.69805 ; Accuracy of 0.58301\n","Epoch 63 : Train Loss of 0.66075 ; Valid Loss of 0.69173 ; Accuracy of 0.58984\n","Epoch 64 : Train Loss of 0.66057 ; Valid Loss of 0.71085 ; Accuracy of 0.57129\n","Epoch 65 : Train Loss of 0.66148 ; Valid Loss of 0.70225 ; Accuracy of 0.56934\n","Epoch 66 : Train Loss of 0.65854 ; Valid Loss of 0.69522 ; Accuracy of 0.58398\n","Epoch 67 : Train Loss of 0.65660 ; Valid Loss of 0.69390 ; Accuracy of 0.58398\n","Epoch 68 : Train Loss of 0.65352 ; Valid Loss of 0.69093 ; Accuracy of 0.58203\n","Epoch 69 : Train Loss of 0.65644 ; Valid Loss of 0.69632 ; Accuracy of 0.57910\n","Epoch 70 : Train Loss of 0.65507 ; Valid Loss of 0.69531 ; Accuracy of 0.58301\n","Epoch 71 : Train Loss of 0.65115 ; Valid Loss of 0.69273 ; Accuracy of 0.58301\n","Epoch 72 : Train Loss of 0.64969 ; Valid Loss of 0.69558 ; Accuracy of 0.58496\n","Epoch 73 : Train Loss of 0.64981 ; Valid Loss of 0.69741 ; Accuracy of 0.57617\n","Epoch 74 : Train Loss of 0.64988 ; Valid Loss of 0.69881 ; Accuracy of 0.57812\n","Epoch 75 : Train Loss of 0.64730 ; Valid Loss of 0.69966 ; Accuracy of 0.57812\n","Epoch 76 : Train Loss of 0.64895 ; Valid Loss of 0.70185 ; Accuracy of 0.58594\n","Epoch 77 : Train Loss of 0.64523 ; Valid Loss of 0.70254 ; Accuracy of 0.57715\n","Epoch 78 : Train Loss of 0.64704 ; Valid Loss of 0.69414 ; Accuracy of 0.57910\n","Epoch 79 : Train Loss of 0.64298 ; Valid Loss of 0.70015 ; Accuracy of 0.58398\n","Epoch 80 : Train Loss of 0.64592 ; Valid Loss of 0.69024 ; Accuracy of 0.58887\n","Early Stopping, Best Optimal Number of Epoch is 30\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea7b240>\n","Training For Optimal Number of Epochs 30 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.02037\n","Epoch 1 : Entire Train Loss of 0.93105\n","Epoch 2 : Entire Train Loss of 0.86688\n","Epoch 3 : Entire Train Loss of 0.80214\n","Epoch 4 : Entire Train Loss of 0.76471\n","Epoch 5 : Entire Train Loss of 0.73329\n","Epoch 6 : Entire Train Loss of 0.69991\n","Epoch 7 : Entire Train Loss of 0.68068\n","Epoch 8 : Entire Train Loss of 0.66741\n","Epoch 9 : Entire Train Loss of 0.65877\n","Epoch 10 : Entire Train Loss of 0.64708\n","Epoch 11 : Entire Train Loss of 0.64068\n","Epoch 12 : Entire Train Loss of 0.63025\n","Epoch 13 : Entire Train Loss of 0.62620\n","Epoch 14 : Entire Train Loss of 0.62203\n","Epoch 15 : Entire Train Loss of 0.61468\n","Epoch 16 : Entire Train Loss of 0.61082\n","Epoch 17 : Entire Train Loss of 0.60883\n","Epoch 18 : Entire Train Loss of 0.60541\n","Epoch 19 : Entire Train Loss of 0.60299\n","Epoch 20 : Entire Train Loss of 0.60109\n","Epoch 21 : Entire Train Loss of 0.59744\n","Epoch 22 : Entire Train Loss of 0.59636\n","Epoch 23 : Entire Train Loss of 0.59439\n","Epoch 24 : Entire Train Loss of 0.59129\n","Epoch 25 : Entire Train Loss of 0.58810\n","Epoch 26 : Entire Train Loss of 0.58508\n","Epoch 27 : Entire Train Loss of 0.58313\n","Epoch 28 : Entire Train Loss of 0.58080\n","Epoch 29 : Entire Train Loss of 0.57553\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea41c88>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.98812 ; Valid Loss of 0.75558 ; Accuracy of 0.49609\n","Epoch 2 : Train Loss of 0.93879 ; Valid Loss of 0.73247 ; Accuracy of 0.51758\n","Epoch 3 : Train Loss of 0.89340 ; Valid Loss of 0.72101 ; Accuracy of 0.53809\n","Epoch 4 : Train Loss of 0.86333 ; Valid Loss of 0.71678 ; Accuracy of 0.54590\n","Epoch 5 : Train Loss of 0.84824 ; Valid Loss of 0.71988 ; Accuracy of 0.53906\n","Epoch 6 : Train Loss of 0.83294 ; Valid Loss of 0.71705 ; Accuracy of 0.53711\n","Epoch 7 : Train Loss of 0.81779 ; Valid Loss of 0.70399 ; Accuracy of 0.55859\n","Epoch 8 : Train Loss of 0.80906 ; Valid Loss of 0.70517 ; Accuracy of 0.56152\n","Epoch 9 : Train Loss of 0.80345 ; Valid Loss of 0.70787 ; Accuracy of 0.55762\n","Epoch 10 : Train Loss of 0.78743 ; Valid Loss of 0.71056 ; Accuracy of 0.56445\n","Epoch 11 : Train Loss of 0.78139 ; Valid Loss of 0.70878 ; Accuracy of 0.56543\n","Epoch 12 : Train Loss of 0.77477 ; Valid Loss of 0.70622 ; Accuracy of 0.56250\n","Epoch 13 : Train Loss of 0.76890 ; Valid Loss of 0.70590 ; Accuracy of 0.56738\n","Epoch 14 : Train Loss of 0.76082 ; Valid Loss of 0.70537 ; Accuracy of 0.55664\n","Epoch 15 : Train Loss of 0.75341 ; Valid Loss of 0.70438 ; Accuracy of 0.56250\n","Epoch 16 : Train Loss of 0.74698 ; Valid Loss of 0.70490 ; Accuracy of 0.56738\n","Epoch 17 : Train Loss of 0.74177 ; Valid Loss of 0.70570 ; Accuracy of 0.56348\n","Epoch 18 : Train Loss of 0.73759 ; Valid Loss of 0.70510 ; Accuracy of 0.56934\n","Epoch 19 : Train Loss of 0.74040 ; Valid Loss of 0.69782 ; Accuracy of 0.57910\n","Epoch 20 : Train Loss of 0.73842 ; Valid Loss of 0.70700 ; Accuracy of 0.57031\n","Epoch 21 : Train Loss of 0.73507 ; Valid Loss of 0.70755 ; Accuracy of 0.57422\n","Epoch 22 : Train Loss of 0.72890 ; Valid Loss of 0.70481 ; Accuracy of 0.56934\n","Epoch 23 : Train Loss of 0.71982 ; Valid Loss of 0.71748 ; Accuracy of 0.55859\n","Epoch 24 : Train Loss of 0.72075 ; Valid Loss of 0.70549 ; Accuracy of 0.57422\n","Epoch 25 : Train Loss of 0.71697 ; Valid Loss of 0.70447 ; Accuracy of 0.56934\n","Epoch 26 : Train Loss of 0.71717 ; Valid Loss of 0.70137 ; Accuracy of 0.58008\n","Epoch 27 : Train Loss of 0.71018 ; Valid Loss of 0.70790 ; Accuracy of 0.57324\n","Epoch 28 : Train Loss of 0.71120 ; Valid Loss of 0.69799 ; Accuracy of 0.58594\n","Epoch 29 : Train Loss of 0.70429 ; Valid Loss of 0.70252 ; Accuracy of 0.57520\n","Epoch 30 : Train Loss of 0.70449 ; Valid Loss of 0.70201 ; Accuracy of 0.57617\n","Epoch 31 : Train Loss of 0.70604 ; Valid Loss of 0.70273 ; Accuracy of 0.57422\n","Epoch 32 : Train Loss of 0.70215 ; Valid Loss of 0.70003 ; Accuracy of 0.57617\n","Epoch 33 : Train Loss of 0.69283 ; Valid Loss of 0.70183 ; Accuracy of 0.57227\n","Epoch 34 : Train Loss of 0.69718 ; Valid Loss of 0.70762 ; Accuracy of 0.57422\n","Epoch 35 : Train Loss of 0.69156 ; Valid Loss of 0.70132 ; Accuracy of 0.57129\n","Epoch 36 : Train Loss of 0.69274 ; Valid Loss of 0.70239 ; Accuracy of 0.57715\n","Epoch 37 : Train Loss of 0.69222 ; Valid Loss of 0.69922 ; Accuracy of 0.57422\n","Epoch 38 : Train Loss of 0.68969 ; Valid Loss of 0.70466 ; Accuracy of 0.57129\n","Epoch 39 : Train Loss of 0.68779 ; Valid Loss of 0.70322 ; Accuracy of 0.57227\n","Epoch 40 : Train Loss of 0.68436 ; Valid Loss of 0.69788 ; Accuracy of 0.57324\n","Epoch 41 : Train Loss of 0.68574 ; Valid Loss of 0.69865 ; Accuracy of 0.57520\n","Epoch 42 : Train Loss of 0.68294 ; Valid Loss of 0.68467 ; Accuracy of 0.58887\n","Epoch 43 : Train Loss of 0.67966 ; Valid Loss of 0.69347 ; Accuracy of 0.57812\n","Epoch 44 : Train Loss of 0.68039 ; Valid Loss of 0.70142 ; Accuracy of 0.57910\n","Epoch 45 : Train Loss of 0.67639 ; Valid Loss of 0.69472 ; Accuracy of 0.57715\n","Epoch 46 : Train Loss of 0.67487 ; Valid Loss of 0.70090 ; Accuracy of 0.57910\n","Epoch 47 : Train Loss of 0.67374 ; Valid Loss of 0.69059 ; Accuracy of 0.58594\n","Epoch 48 : Train Loss of 0.67296 ; Valid Loss of 0.69369 ; Accuracy of 0.57129\n","Epoch 49 : Train Loss of 0.67493 ; Valid Loss of 0.69194 ; Accuracy of 0.58398\n","Epoch 50 : Train Loss of 0.67312 ; Valid Loss of 0.69172 ; Accuracy of 0.58105\n","Epoch 51 : Train Loss of 0.67036 ; Valid Loss of 0.70300 ; Accuracy of 0.58105\n","Epoch 52 : Train Loss of 0.67176 ; Valid Loss of 0.68679 ; Accuracy of 0.59473\n","Epoch 53 : Train Loss of 0.66451 ; Valid Loss of 0.69412 ; Accuracy of 0.58594\n","Epoch 54 : Train Loss of 0.66771 ; Valid Loss of 0.70289 ; Accuracy of 0.57520\n","Epoch 55 : Train Loss of 0.66371 ; Valid Loss of 0.69867 ; Accuracy of 0.57715\n","Epoch 56 : Train Loss of 0.66268 ; Valid Loss of 0.69533 ; Accuracy of 0.57812\n","Epoch 57 : Train Loss of 0.66538 ; Valid Loss of 0.68894 ; Accuracy of 0.58301\n","Epoch 58 : Train Loss of 0.66224 ; Valid Loss of 0.69474 ; Accuracy of 0.57520\n","Epoch 59 : Train Loss of 0.66273 ; Valid Loss of 0.69771 ; Accuracy of 0.58301\n","Epoch 60 : Train Loss of 0.66104 ; Valid Loss of 0.69471 ; Accuracy of 0.58887\n","Epoch 61 : Train Loss of 0.65776 ; Valid Loss of 0.68987 ; Accuracy of 0.59082\n","Epoch 62 : Train Loss of 0.65387 ; Valid Loss of 0.69950 ; Accuracy of 0.58301\n","Epoch 63 : Train Loss of 0.65743 ; Valid Loss of 0.68436 ; Accuracy of 0.60156\n","Epoch 64 : Train Loss of 0.65712 ; Valid Loss of 0.69316 ; Accuracy of 0.59180\n","Epoch 65 : Train Loss of 0.65351 ; Valid Loss of 0.69616 ; Accuracy of 0.58984\n","Epoch 66 : Train Loss of 0.65112 ; Valid Loss of 0.68669 ; Accuracy of 0.60449\n","Epoch 67 : Train Loss of 0.65283 ; Valid Loss of 0.69898 ; Accuracy of 0.59570\n","Epoch 68 : Train Loss of 0.64953 ; Valid Loss of 0.69390 ; Accuracy of 0.60059\n","Epoch 69 : Train Loss of 0.65047 ; Valid Loss of 0.68805 ; Accuracy of 0.60449\n","Epoch 70 : Train Loss of 0.64856 ; Valid Loss of 0.68623 ; Accuracy of 0.60254\n","Epoch 71 : Train Loss of 0.64932 ; Valid Loss of 0.68918 ; Accuracy of 0.60547\n","Epoch 72 : Train Loss of 0.64552 ; Valid Loss of 0.68971 ; Accuracy of 0.59570\n","Epoch 73 : Train Loss of 0.64777 ; Valid Loss of 0.68813 ; Accuracy of 0.60156\n","Epoch 74 : Train Loss of 0.64376 ; Valid Loss of 0.69952 ; Accuracy of 0.59375\n","Epoch 75 : Train Loss of 0.64642 ; Valid Loss of 0.69030 ; Accuracy of 0.59961\n","Epoch 76 : Train Loss of 0.64708 ; Valid Loss of 0.69256 ; Accuracy of 0.59180\n","Epoch 77 : Train Loss of 0.64564 ; Valid Loss of 0.70088 ; Accuracy of 0.58984\n","Epoch 78 : Train Loss of 0.64438 ; Valid Loss of 0.69314 ; Accuracy of 0.59375\n","Epoch 79 : Train Loss of 0.64153 ; Valid Loss of 0.69657 ; Accuracy of 0.59570\n","Epoch 80 : Train Loss of 0.64284 ; Valid Loss of 0.69881 ; Accuracy of 0.59375\n","Epoch 81 : Train Loss of 0.63824 ; Valid Loss of 0.68955 ; Accuracy of 0.59961\n","Epoch 82 : Train Loss of 0.64265 ; Valid Loss of 0.69992 ; Accuracy of 0.58398\n","Epoch 83 : Train Loss of 0.63884 ; Valid Loss of 0.69156 ; Accuracy of 0.59082\n","Epoch 84 : Train Loss of 0.64131 ; Valid Loss of 0.69407 ; Accuracy of 0.59668\n","Epoch 85 : Train Loss of 0.63836 ; Valid Loss of 0.69970 ; Accuracy of 0.59180\n","Epoch 86 : Train Loss of 0.63823 ; Valid Loss of 0.69226 ; Accuracy of 0.59473\n","Epoch 87 : Train Loss of 0.63566 ; Valid Loss of 0.68760 ; Accuracy of 0.59375\n","Epoch 88 : Train Loss of 0.63533 ; Valid Loss of 0.68967 ; Accuracy of 0.59863\n","Epoch 89 : Train Loss of 0.63806 ; Valid Loss of 0.68979 ; Accuracy of 0.59375\n","Epoch 90 : Train Loss of 0.63455 ; Valid Loss of 0.69571 ; Accuracy of 0.59082\n","Epoch 91 : Train Loss of 0.63681 ; Valid Loss of 0.69938 ; Accuracy of 0.59473\n","Epoch 92 : Train Loss of 0.63322 ; Valid Loss of 0.69648 ; Accuracy of 0.59570\n","Epoch 93 : Train Loss of 0.63159 ; Valid Loss of 0.69609 ; Accuracy of 0.59082\n","Epoch 94 : Train Loss of 0.63592 ; Valid Loss of 0.69127 ; Accuracy of 0.59668\n","Epoch 95 : Train Loss of 0.63251 ; Valid Loss of 0.68922 ; Accuracy of 0.59668\n","Epoch 96 : Train Loss of 0.63155 ; Valid Loss of 0.69556 ; Accuracy of 0.59668\n","Epoch 97 : Train Loss of 0.63066 ; Valid Loss of 0.69172 ; Accuracy of 0.59766\n","Epoch 98 : Train Loss of 0.63326 ; Valid Loss of 0.68599 ; Accuracy of 0.60156\n","Epoch 99 : Train Loss of 0.63069 ; Valid Loss of 0.68404 ; Accuracy of 0.60254\n","Epoch 100 : Train Loss of 0.63112 ; Valid Loss of 0.69229 ; Accuracy of 0.60059\n","Epoch 101 : Train Loss of 0.62928 ; Valid Loss of 0.69311 ; Accuracy of 0.58887\n","Epoch 102 : Train Loss of 0.63027 ; Valid Loss of 0.68744 ; Accuracy of 0.59180\n","Epoch 103 : Train Loss of 0.62622 ; Valid Loss of 0.69364 ; Accuracy of 0.59277\n","Epoch 104 : Train Loss of 0.62719 ; Valid Loss of 0.69823 ; Accuracy of 0.59180\n","Epoch 105 : Train Loss of 0.62745 ; Valid Loss of 0.69793 ; Accuracy of 0.58203\n","Epoch 106 : Train Loss of 0.62752 ; Valid Loss of 0.68999 ; Accuracy of 0.59766\n","Epoch 107 : Train Loss of 0.62505 ; Valid Loss of 0.68822 ; Accuracy of 0.59668\n","Epoch 108 : Train Loss of 0.62419 ; Valid Loss of 0.68623 ; Accuracy of 0.59473\n","Epoch 109 : Train Loss of 0.62144 ; Valid Loss of 0.69414 ; Accuracy of 0.58887\n","Epoch 110 : Train Loss of 0.62663 ; Valid Loss of 0.70729 ; Accuracy of 0.58594\n","Epoch 111 : Train Loss of 0.62390 ; Valid Loss of 0.68968 ; Accuracy of 0.58887\n","Epoch 112 : Train Loss of 0.62074 ; Valid Loss of 0.68205 ; Accuracy of 0.59668\n","Epoch 113 : Train Loss of 0.62236 ; Valid Loss of 0.69422 ; Accuracy of 0.58691\n","Epoch 114 : Train Loss of 0.62331 ; Valid Loss of 0.69269 ; Accuracy of 0.59082\n","Epoch 115 : Train Loss of 0.62190 ; Valid Loss of 0.70413 ; Accuracy of 0.58398\n","Epoch 116 : Train Loss of 0.62094 ; Valid Loss of 0.68823 ; Accuracy of 0.59961\n","Epoch 117 : Train Loss of 0.62012 ; Valid Loss of 0.69230 ; Accuracy of 0.58594\n","Epoch 118 : Train Loss of 0.62078 ; Valid Loss of 0.69359 ; Accuracy of 0.59277\n","Epoch 119 : Train Loss of 0.62082 ; Valid Loss of 0.69232 ; Accuracy of 0.58984\n","Epoch 120 : Train Loss of 0.61821 ; Valid Loss of 0.69843 ; Accuracy of 0.59375\n","Epoch 121 : Train Loss of 0.61864 ; Valid Loss of 0.70161 ; Accuracy of 0.58496\n","Epoch 122 : Train Loss of 0.61704 ; Valid Loss of 0.68643 ; Accuracy of 0.60547\n","Epoch 123 : Train Loss of 0.61641 ; Valid Loss of 0.69904 ; Accuracy of 0.58496\n","Epoch 124 : Train Loss of 0.61914 ; Valid Loss of 0.68949 ; Accuracy of 0.60254\n","Epoch 125 : Train Loss of 0.61741 ; Valid Loss of 0.70200 ; Accuracy of 0.58691\n","Epoch 126 : Train Loss of 0.61658 ; Valid Loss of 0.70068 ; Accuracy of 0.58789\n","Epoch 127 : Train Loss of 0.61487 ; Valid Loss of 0.69387 ; Accuracy of 0.59570\n","Epoch 128 : Train Loss of 0.61421 ; Valid Loss of 0.70135 ; Accuracy of 0.57715\n","Epoch 129 : Train Loss of 0.61182 ; Valid Loss of 0.69987 ; Accuracy of 0.58984\n","Epoch 130 : Train Loss of 0.61498 ; Valid Loss of 0.69496 ; Accuracy of 0.58984\n","Epoch 131 : Train Loss of 0.61221 ; Valid Loss of 0.69613 ; Accuracy of 0.59082\n","Epoch 132 : Train Loss of 0.61380 ; Valid Loss of 0.70861 ; Accuracy of 0.58398\n","Epoch 133 : Train Loss of 0.61193 ; Valid Loss of 0.70467 ; Accuracy of 0.58789\n","Epoch 134 : Train Loss of 0.61170 ; Valid Loss of 0.69604 ; Accuracy of 0.60742\n","Epoch 135 : Train Loss of 0.61299 ; Valid Loss of 0.69823 ; Accuracy of 0.59375\n","Epoch 136 : Train Loss of 0.61094 ; Valid Loss of 0.69793 ; Accuracy of 0.59668\n","Epoch 137 : Train Loss of 0.61133 ; Valid Loss of 0.68347 ; Accuracy of 0.60449\n","Epoch 138 : Train Loss of 0.60918 ; Valid Loss of 0.68958 ; Accuracy of 0.60254\n","Epoch 139 : Train Loss of 0.61225 ; Valid Loss of 0.68796 ; Accuracy of 0.60742\n","Epoch 140 : Train Loss of 0.61104 ; Valid Loss of 0.69533 ; Accuracy of 0.59863\n","Epoch 141 : Train Loss of 0.60979 ; Valid Loss of 0.70050 ; Accuracy of 0.59375\n","Epoch 142 : Train Loss of 0.61062 ; Valid Loss of 0.70103 ; Accuracy of 0.59375\n","Epoch 143 : Train Loss of 0.60942 ; Valid Loss of 0.70720 ; Accuracy of 0.59473\n","Epoch 144 : Train Loss of 0.60780 ; Valid Loss of 0.70086 ; Accuracy of 0.59668\n","Epoch 145 : Train Loss of 0.60781 ; Valid Loss of 0.70403 ; Accuracy of 0.60059\n","Epoch 146 : Train Loss of 0.60752 ; Valid Loss of 0.69699 ; Accuracy of 0.59863\n","Epoch 147 : Train Loss of 0.60497 ; Valid Loss of 0.69321 ; Accuracy of 0.60254\n","Epoch 148 : Train Loss of 0.60548 ; Valid Loss of 0.70039 ; Accuracy of 0.59082\n","Epoch 149 : Train Loss of 0.60632 ; Valid Loss of 0.69299 ; Accuracy of 0.60547\n","Epoch 150 : Train Loss of 0.60565 ; Valid Loss of 0.69096 ; Accuracy of 0.60059\n","Epoch 151 : Train Loss of 0.60640 ; Valid Loss of 0.70288 ; Accuracy of 0.59766\n","Epoch 152 : Train Loss of 0.60379 ; Valid Loss of 0.69866 ; Accuracy of 0.59570\n","Epoch 153 : Train Loss of 0.60149 ; Valid Loss of 0.69303 ; Accuracy of 0.59961\n","Epoch 154 : Train Loss of 0.60459 ; Valid Loss of 0.70569 ; Accuracy of 0.59082\n","Epoch 155 : Train Loss of 0.60431 ; Valid Loss of 0.70168 ; Accuracy of 0.59766\n","Epoch 156 : Train Loss of 0.60207 ; Valid Loss of 0.69622 ; Accuracy of 0.60547\n","Epoch 157 : Train Loss of 0.60587 ; Valid Loss of 0.70679 ; Accuracy of 0.60449\n","Epoch 158 : Train Loss of 0.60288 ; Valid Loss of 0.69987 ; Accuracy of 0.60449\n","Epoch 159 : Train Loss of 0.59902 ; Valid Loss of 0.69848 ; Accuracy of 0.60645\n","Epoch 160 : Train Loss of 0.60201 ; Valid Loss of 0.70302 ; Accuracy of 0.59961\n","Epoch 161 : Train Loss of 0.60001 ; Valid Loss of 0.69837 ; Accuracy of 0.60352\n","Epoch 162 : Train Loss of 0.59946 ; Valid Loss of 0.69589 ; Accuracy of 0.60645\n","Early Stopping, Best Optimal Number of Epoch is 112\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea41f28>\n","Training For Optimal Number of Epochs 112 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.97031\n","Epoch 1 : Entire Train Loss of 0.89732\n","Epoch 2 : Entire Train Loss of 0.83205\n","Epoch 3 : Entire Train Loss of 0.78659\n","Epoch 4 : Entire Train Loss of 0.74802\n","Epoch 5 : Entire Train Loss of 0.71652\n","Epoch 6 : Entire Train Loss of 0.69678\n","Epoch 7 : Entire Train Loss of 0.67416\n","Epoch 8 : Entire Train Loss of 0.66390\n","Epoch 9 : Entire Train Loss of 0.64890\n","Epoch 10 : Entire Train Loss of 0.63758\n","Epoch 11 : Entire Train Loss of 0.63322\n","Epoch 12 : Entire Train Loss of 0.62538\n","Epoch 13 : Entire Train Loss of 0.62102\n","Epoch 14 : Entire Train Loss of 0.61595\n","Epoch 15 : Entire Train Loss of 0.61233\n","Epoch 16 : Entire Train Loss of 0.60691\n","Epoch 17 : Entire Train Loss of 0.60558\n","Epoch 18 : Entire Train Loss of 0.60240\n","Epoch 19 : Entire Train Loss of 0.60013\n","Epoch 20 : Entire Train Loss of 0.59860\n","Epoch 21 : Entire Train Loss of 0.59532\n","Epoch 22 : Entire Train Loss of 0.59407\n","Epoch 23 : Entire Train Loss of 0.59234\n","Epoch 24 : Entire Train Loss of 0.58989\n","Epoch 25 : Entire Train Loss of 0.58679\n","Epoch 26 : Entire Train Loss of 0.58431\n","Epoch 27 : Entire Train Loss of 0.58121\n","Epoch 28 : Entire Train Loss of 0.57747\n","Epoch 29 : Entire Train Loss of 0.57428\n","Epoch 30 : Entire Train Loss of 0.57142\n","Epoch 31 : Entire Train Loss of 0.56767\n","Epoch 32 : Entire Train Loss of 0.56302\n","Epoch 33 : Entire Train Loss of 0.55913\n","Epoch 34 : Entire Train Loss of 0.55682\n","Epoch 35 : Entire Train Loss of 0.55062\n","Epoch 36 : Entire Train Loss of 0.54913\n","Epoch 37 : Entire Train Loss of 0.54372\n","Epoch 38 : Entire Train Loss of 0.53905\n","Epoch 39 : Entire Train Loss of 0.53284\n","Epoch 40 : Entire Train Loss of 0.52845\n","Epoch 41 : Entire Train Loss of 0.52555\n","Epoch 42 : Entire Train Loss of 0.51939\n","Epoch 43 : Entire Train Loss of 0.51390\n","Epoch 44 : Entire Train Loss of 0.51294\n","Epoch 45 : Entire Train Loss of 0.50733\n","Epoch 46 : Entire Train Loss of 0.50253\n","Epoch 47 : Entire Train Loss of 0.49768\n","Epoch 48 : Entire Train Loss of 0.49075\n","Epoch 49 : Entire Train Loss of 0.48702\n","Epoch 50 : Entire Train Loss of 0.48384\n","Epoch 51 : Entire Train Loss of 0.47914\n","Epoch 52 : Entire Train Loss of 0.47296\n","Epoch 53 : Entire Train Loss of 0.46838\n","Epoch 54 : Entire Train Loss of 0.46413\n","Epoch 55 : Entire Train Loss of 0.45878\n","Epoch 56 : Entire Train Loss of 0.45716\n","Epoch 57 : Entire Train Loss of 0.45302\n","Epoch 58 : Entire Train Loss of 0.44506\n","Epoch 59 : Entire Train Loss of 0.44062\n","Epoch 60 : Entire Train Loss of 0.43458\n","Epoch 61 : Entire Train Loss of 0.43193\n","Epoch 62 : Entire Train Loss of 0.42831\n","Epoch 63 : Entire Train Loss of 0.42462\n","Epoch 64 : Entire Train Loss of 0.41827\n","Epoch 65 : Entire Train Loss of 0.41344\n","Epoch 66 : Entire Train Loss of 0.41247\n","Epoch 67 : Entire Train Loss of 0.40623\n","Epoch 68 : Entire Train Loss of 0.40281\n","Epoch 69 : Entire Train Loss of 0.39801\n","Epoch 70 : Entire Train Loss of 0.39321\n","Epoch 71 : Entire Train Loss of 0.39112\n","Epoch 72 : Entire Train Loss of 0.38794\n","Epoch 73 : Entire Train Loss of 0.38658\n","Epoch 74 : Entire Train Loss of 0.37985\n","Epoch 75 : Entire Train Loss of 0.37727\n","Epoch 76 : Entire Train Loss of 0.36969\n","Epoch 77 : Entire Train Loss of 0.37027\n","Epoch 78 : Entire Train Loss of 0.36236\n","Epoch 79 : Entire Train Loss of 0.35997\n","Epoch 80 : Entire Train Loss of 0.35557\n","Epoch 81 : Entire Train Loss of 0.35925\n","Epoch 82 : Entire Train Loss of 0.35566\n","Epoch 83 : Entire Train Loss of 0.34997\n","Epoch 84 : Entire Train Loss of 0.34379\n","Epoch 85 : Entire Train Loss of 0.34570\n","Epoch 86 : Entire Train Loss of 0.34316\n","Epoch 87 : Entire Train Loss of 0.34128\n","Epoch 88 : Entire Train Loss of 0.33343\n","Epoch 89 : Entire Train Loss of 0.33472\n","Epoch 90 : Entire Train Loss of 0.33078\n","Epoch 91 : Entire Train Loss of 0.32398\n","Epoch 92 : Entire Train Loss of 0.32483\n","Epoch 93 : Entire Train Loss of 0.31597\n","Epoch 94 : Entire Train Loss of 0.31757\n","Epoch 95 : Entire Train Loss of 0.31710\n","Epoch 96 : Entire Train Loss of 0.31299\n","Epoch 97 : Entire Train Loss of 0.31142\n","Epoch 98 : Entire Train Loss of 0.30520\n","Epoch 99 : Entire Train Loss of 0.30534\n","Epoch 100 : Entire Train Loss of 0.30131\n","Epoch 101 : Entire Train Loss of 0.29722\n","Epoch 102 : Entire Train Loss of 0.29985\n","Epoch 103 : Entire Train Loss of 0.29881\n","Epoch 104 : Entire Train Loss of 0.29391\n","Epoch 105 : Entire Train Loss of 0.29536\n","Epoch 106 : Entire Train Loss of 0.29149\n","Epoch 107 : Entire Train Loss of 0.28350\n","Epoch 108 : Entire Train Loss of 0.28412\n","Epoch 109 : Entire Train Loss of 0.28417\n","Epoch 110 : Entire Train Loss of 0.27944\n","Epoch 111 : Entire Train Loss of 0.27671\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d6a5160>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.01239 ; Valid Loss of 0.76386 ; Accuracy of 0.54297\n","Epoch 2 : Train Loss of 0.96029 ; Valid Loss of 0.74785 ; Accuracy of 0.56250\n","Epoch 3 : Train Loss of 0.92401 ; Valid Loss of 0.75308 ; Accuracy of 0.55469\n","Epoch 4 : Train Loss of 0.89704 ; Valid Loss of 0.74545 ; Accuracy of 0.56152\n","Epoch 5 : Train Loss of 0.87973 ; Valid Loss of 0.74755 ; Accuracy of 0.56445\n","Epoch 6 : Train Loss of 0.85420 ; Valid Loss of 0.73963 ; Accuracy of 0.56543\n","Epoch 7 : Train Loss of 0.85564 ; Valid Loss of 0.74325 ; Accuracy of 0.56934\n","Epoch 8 : Train Loss of 0.83527 ; Valid Loss of 0.73330 ; Accuracy of 0.57520\n","Epoch 9 : Train Loss of 0.83119 ; Valid Loss of 0.74368 ; Accuracy of 0.56055\n","Epoch 10 : Train Loss of 0.81563 ; Valid Loss of 0.73026 ; Accuracy of 0.57715\n","Epoch 11 : Train Loss of 0.80958 ; Valid Loss of 0.73726 ; Accuracy of 0.57324\n","Epoch 12 : Train Loss of 0.79870 ; Valid Loss of 0.72734 ; Accuracy of 0.58398\n","Epoch 13 : Train Loss of 0.79077 ; Valid Loss of 0.72747 ; Accuracy of 0.58008\n","Epoch 14 : Train Loss of 0.78333 ; Valid Loss of 0.73287 ; Accuracy of 0.57227\n","Epoch 15 : Train Loss of 0.78080 ; Valid Loss of 0.72642 ; Accuracy of 0.58496\n","Epoch 16 : Train Loss of 0.76897 ; Valid Loss of 0.72819 ; Accuracy of 0.57129\n","Epoch 17 : Train Loss of 0.76681 ; Valid Loss of 0.73363 ; Accuracy of 0.57910\n","Epoch 18 : Train Loss of 0.75854 ; Valid Loss of 0.72810 ; Accuracy of 0.58105\n","Epoch 19 : Train Loss of 0.75788 ; Valid Loss of 0.72753 ; Accuracy of 0.57812\n","Epoch 20 : Train Loss of 0.75500 ; Valid Loss of 0.71506 ; Accuracy of 0.58398\n","Epoch 21 : Train Loss of 0.74748 ; Valid Loss of 0.72595 ; Accuracy of 0.57520\n","Epoch 22 : Train Loss of 0.74720 ; Valid Loss of 0.72930 ; Accuracy of 0.57617\n","Epoch 23 : Train Loss of 0.74043 ; Valid Loss of 0.72560 ; Accuracy of 0.58301\n","Epoch 24 : Train Loss of 0.73586 ; Valid Loss of 0.72430 ; Accuracy of 0.58887\n","Epoch 25 : Train Loss of 0.73596 ; Valid Loss of 0.71107 ; Accuracy of 0.59668\n","Epoch 26 : Train Loss of 0.73495 ; Valid Loss of 0.72089 ; Accuracy of 0.58496\n","Epoch 27 : Train Loss of 0.72535 ; Valid Loss of 0.71148 ; Accuracy of 0.59180\n","Epoch 28 : Train Loss of 0.72716 ; Valid Loss of 0.72887 ; Accuracy of 0.57910\n","Epoch 29 : Train Loss of 0.72150 ; Valid Loss of 0.71685 ; Accuracy of 0.58105\n","Epoch 30 : Train Loss of 0.71988 ; Valid Loss of 0.71431 ; Accuracy of 0.58984\n","Epoch 31 : Train Loss of 0.71817 ; Valid Loss of 0.71666 ; Accuracy of 0.58105\n","Epoch 32 : Train Loss of 0.71906 ; Valid Loss of 0.72144 ; Accuracy of 0.58301\n","Epoch 33 : Train Loss of 0.71255 ; Valid Loss of 0.71369 ; Accuracy of 0.58691\n","Epoch 34 : Train Loss of 0.70519 ; Valid Loss of 0.71669 ; Accuracy of 0.58105\n","Epoch 35 : Train Loss of 0.70552 ; Valid Loss of 0.70671 ; Accuracy of 0.59082\n","Epoch 36 : Train Loss of 0.70672 ; Valid Loss of 0.72281 ; Accuracy of 0.58203\n","Epoch 37 : Train Loss of 0.70292 ; Valid Loss of 0.70931 ; Accuracy of 0.59668\n","Epoch 38 : Train Loss of 0.70512 ; Valid Loss of 0.71582 ; Accuracy of 0.58496\n","Epoch 39 : Train Loss of 0.70094 ; Valid Loss of 0.70674 ; Accuracy of 0.59570\n","Epoch 40 : Train Loss of 0.69766 ; Valid Loss of 0.70972 ; Accuracy of 0.59082\n","Epoch 41 : Train Loss of 0.69182 ; Valid Loss of 0.71872 ; Accuracy of 0.58008\n","Epoch 42 : Train Loss of 0.69330 ; Valid Loss of 0.70883 ; Accuracy of 0.59375\n","Epoch 43 : Train Loss of 0.68878 ; Valid Loss of 0.71676 ; Accuracy of 0.58008\n","Epoch 44 : Train Loss of 0.68553 ; Valid Loss of 0.71311 ; Accuracy of 0.59082\n","Epoch 45 : Train Loss of 0.68472 ; Valid Loss of 0.71329 ; Accuracy of 0.58984\n","Epoch 46 : Train Loss of 0.68673 ; Valid Loss of 0.71459 ; Accuracy of 0.58496\n","Epoch 47 : Train Loss of 0.67973 ; Valid Loss of 0.70768 ; Accuracy of 0.59375\n","Epoch 48 : Train Loss of 0.68229 ; Valid Loss of 0.70922 ; Accuracy of 0.59277\n","Epoch 49 : Train Loss of 0.68350 ; Valid Loss of 0.71074 ; Accuracy of 0.58496\n","Epoch 50 : Train Loss of 0.68142 ; Valid Loss of 0.71830 ; Accuracy of 0.58496\n","Epoch 51 : Train Loss of 0.68005 ; Valid Loss of 0.70606 ; Accuracy of 0.59180\n","Epoch 52 : Train Loss of 0.67325 ; Valid Loss of 0.70648 ; Accuracy of 0.59180\n","Epoch 53 : Train Loss of 0.67474 ; Valid Loss of 0.70527 ; Accuracy of 0.59375\n","Epoch 54 : Train Loss of 0.67521 ; Valid Loss of 0.70615 ; Accuracy of 0.58496\n","Epoch 55 : Train Loss of 0.66954 ; Valid Loss of 0.71596 ; Accuracy of 0.57910\n","Epoch 56 : Train Loss of 0.67254 ; Valid Loss of 0.70501 ; Accuracy of 0.58984\n","Epoch 57 : Train Loss of 0.67133 ; Valid Loss of 0.70827 ; Accuracy of 0.58789\n","Epoch 58 : Train Loss of 0.67255 ; Valid Loss of 0.71068 ; Accuracy of 0.58203\n","Epoch 59 : Train Loss of 0.66717 ; Valid Loss of 0.70459 ; Accuracy of 0.58887\n","Epoch 60 : Train Loss of 0.66650 ; Valid Loss of 0.70460 ; Accuracy of 0.58594\n","Epoch 61 : Train Loss of 0.66475 ; Valid Loss of 0.70680 ; Accuracy of 0.58984\n","Epoch 62 : Train Loss of 0.66080 ; Valid Loss of 0.70734 ; Accuracy of 0.58691\n","Epoch 63 : Train Loss of 0.66348 ; Valid Loss of 0.70217 ; Accuracy of 0.58789\n","Epoch 64 : Train Loss of 0.66222 ; Valid Loss of 0.70028 ; Accuracy of 0.58789\n","Epoch 65 : Train Loss of 0.66285 ; Valid Loss of 0.70810 ; Accuracy of 0.59277\n","Epoch 66 : Train Loss of 0.66350 ; Valid Loss of 0.69773 ; Accuracy of 0.59082\n","Epoch 67 : Train Loss of 0.65919 ; Valid Loss of 0.70547 ; Accuracy of 0.58984\n","Epoch 68 : Train Loss of 0.65600 ; Valid Loss of 0.70168 ; Accuracy of 0.59082\n","Epoch 69 : Train Loss of 0.65827 ; Valid Loss of 0.70764 ; Accuracy of 0.58984\n","Epoch 70 : Train Loss of 0.65771 ; Valid Loss of 0.70144 ; Accuracy of 0.59766\n","Epoch 71 : Train Loss of 0.65288 ; Valid Loss of 0.70987 ; Accuracy of 0.58789\n","Epoch 72 : Train Loss of 0.65510 ; Valid Loss of 0.71078 ; Accuracy of 0.59082\n","Epoch 73 : Train Loss of 0.65476 ; Valid Loss of 0.70087 ; Accuracy of 0.59277\n","Epoch 74 : Train Loss of 0.64850 ; Valid Loss of 0.69895 ; Accuracy of 0.59668\n","Epoch 75 : Train Loss of 0.65433 ; Valid Loss of 0.70945 ; Accuracy of 0.58984\n","Epoch 76 : Train Loss of 0.65072 ; Valid Loss of 0.69649 ; Accuracy of 0.59180\n","Epoch 77 : Train Loss of 0.65246 ; Valid Loss of 0.70800 ; Accuracy of 0.59473\n","Epoch 78 : Train Loss of 0.64830 ; Valid Loss of 0.70452 ; Accuracy of 0.59180\n","Epoch 79 : Train Loss of 0.64513 ; Valid Loss of 0.69979 ; Accuracy of 0.59863\n","Epoch 80 : Train Loss of 0.64651 ; Valid Loss of 0.70252 ; Accuracy of 0.60059\n","Epoch 81 : Train Loss of 0.64551 ; Valid Loss of 0.70013 ; Accuracy of 0.59277\n","Epoch 82 : Train Loss of 0.64659 ; Valid Loss of 0.70512 ; Accuracy of 0.58984\n","Epoch 83 : Train Loss of 0.64106 ; Valid Loss of 0.69862 ; Accuracy of 0.59863\n","Epoch 84 : Train Loss of 0.64456 ; Valid Loss of 0.70704 ; Accuracy of 0.59863\n","Epoch 85 : Train Loss of 0.64336 ; Valid Loss of 0.70347 ; Accuracy of 0.59277\n","Epoch 86 : Train Loss of 0.64442 ; Valid Loss of 0.70237 ; Accuracy of 0.59961\n","Epoch 87 : Train Loss of 0.64574 ; Valid Loss of 0.70788 ; Accuracy of 0.59375\n","Epoch 88 : Train Loss of 0.64011 ; Valid Loss of 0.70381 ; Accuracy of 0.59082\n","Epoch 89 : Train Loss of 0.64071 ; Valid Loss of 0.70281 ; Accuracy of 0.59570\n","Epoch 90 : Train Loss of 0.63947 ; Valid Loss of 0.71055 ; Accuracy of 0.58887\n","Epoch 91 : Train Loss of 0.64138 ; Valid Loss of 0.69628 ; Accuracy of 0.59766\n","Epoch 92 : Train Loss of 0.63801 ; Valid Loss of 0.70023 ; Accuracy of 0.59961\n","Epoch 93 : Train Loss of 0.63766 ; Valid Loss of 0.70428 ; Accuracy of 0.59961\n","Epoch 94 : Train Loss of 0.63832 ; Valid Loss of 0.70845 ; Accuracy of 0.59570\n","Epoch 95 : Train Loss of 0.63798 ; Valid Loss of 0.70215 ; Accuracy of 0.59570\n","Epoch 96 : Train Loss of 0.63647 ; Valid Loss of 0.70367 ; Accuracy of 0.59961\n","Epoch 97 : Train Loss of 0.63675 ; Valid Loss of 0.69241 ; Accuracy of 0.60352\n","Epoch 98 : Train Loss of 0.63598 ; Valid Loss of 0.71176 ; Accuracy of 0.58594\n","Epoch 99 : Train Loss of 0.63480 ; Valid Loss of 0.69953 ; Accuracy of 0.59082\n","Epoch 100 : Train Loss of 0.63342 ; Valid Loss of 0.70395 ; Accuracy of 0.58984\n","Epoch 101 : Train Loss of 0.63567 ; Valid Loss of 0.70413 ; Accuracy of 0.58691\n","Epoch 102 : Train Loss of 0.63249 ; Valid Loss of 0.70203 ; Accuracy of 0.60059\n","Epoch 103 : Train Loss of 0.63484 ; Valid Loss of 0.70225 ; Accuracy of 0.59473\n","Epoch 104 : Train Loss of 0.63055 ; Valid Loss of 0.70443 ; Accuracy of 0.59375\n","Epoch 105 : Train Loss of 0.63289 ; Valid Loss of 0.70977 ; Accuracy of 0.59082\n","Epoch 106 : Train Loss of 0.62962 ; Valid Loss of 0.71042 ; Accuracy of 0.59082\n","Epoch 107 : Train Loss of 0.62789 ; Valid Loss of 0.69717 ; Accuracy of 0.59668\n","Epoch 108 : Train Loss of 0.62967 ; Valid Loss of 0.70908 ; Accuracy of 0.59375\n","Epoch 109 : Train Loss of 0.62836 ; Valid Loss of 0.70899 ; Accuracy of 0.58594\n","Epoch 110 : Train Loss of 0.62972 ; Valid Loss of 0.69892 ; Accuracy of 0.59180\n","Epoch 111 : Train Loss of 0.62685 ; Valid Loss of 0.70356 ; Accuracy of 0.59570\n","Epoch 112 : Train Loss of 0.62942 ; Valid Loss of 0.71367 ; Accuracy of 0.58887\n","Epoch 113 : Train Loss of 0.62598 ; Valid Loss of 0.70323 ; Accuracy of 0.59473\n","Epoch 114 : Train Loss of 0.62566 ; Valid Loss of 0.70182 ; Accuracy of 0.59473\n","Epoch 115 : Train Loss of 0.62387 ; Valid Loss of 0.70257 ; Accuracy of 0.59277\n","Epoch 116 : Train Loss of 0.62641 ; Valid Loss of 0.70890 ; Accuracy of 0.58789\n","Epoch 117 : Train Loss of 0.62616 ; Valid Loss of 0.70288 ; Accuracy of 0.59180\n","Epoch 118 : Train Loss of 0.62767 ; Valid Loss of 0.70419 ; Accuracy of 0.59473\n","Epoch 119 : Train Loss of 0.62331 ; Valid Loss of 0.70054 ; Accuracy of 0.59082\n","Epoch 120 : Train Loss of 0.62106 ; Valid Loss of 0.71023 ; Accuracy of 0.59180\n","Epoch 121 : Train Loss of 0.62347 ; Valid Loss of 0.70597 ; Accuracy of 0.59570\n","Epoch 122 : Train Loss of 0.62094 ; Valid Loss of 0.70373 ; Accuracy of 0.59473\n","Epoch 123 : Train Loss of 0.62072 ; Valid Loss of 0.71258 ; Accuracy of 0.58398\n","Epoch 124 : Train Loss of 0.61956 ; Valid Loss of 0.71010 ; Accuracy of 0.58691\n","Epoch 125 : Train Loss of 0.62043 ; Valid Loss of 0.70900 ; Accuracy of 0.58496\n","Epoch 126 : Train Loss of 0.62219 ; Valid Loss of 0.70113 ; Accuracy of 0.59082\n","Epoch 127 : Train Loss of 0.61861 ; Valid Loss of 0.70326 ; Accuracy of 0.59668\n","Epoch 128 : Train Loss of 0.61978 ; Valid Loss of 0.70213 ; Accuracy of 0.59473\n","Epoch 129 : Train Loss of 0.61652 ; Valid Loss of 0.71394 ; Accuracy of 0.59082\n","Epoch 130 : Train Loss of 0.61717 ; Valid Loss of 0.70678 ; Accuracy of 0.59863\n","Epoch 131 : Train Loss of 0.61661 ; Valid Loss of 0.70160 ; Accuracy of 0.59375\n","Epoch 132 : Train Loss of 0.61586 ; Valid Loss of 0.70590 ; Accuracy of 0.59570\n","Epoch 133 : Train Loss of 0.61779 ; Valid Loss of 0.70634 ; Accuracy of 0.58887\n","Epoch 134 : Train Loss of 0.61548 ; Valid Loss of 0.71261 ; Accuracy of 0.58984\n","Epoch 135 : Train Loss of 0.61542 ; Valid Loss of 0.70904 ; Accuracy of 0.58594\n","Epoch 136 : Train Loss of 0.61458 ; Valid Loss of 0.71134 ; Accuracy of 0.58984\n","Epoch 137 : Train Loss of 0.61586 ; Valid Loss of 0.70680 ; Accuracy of 0.60156\n","Epoch 138 : Train Loss of 0.61566 ; Valid Loss of 0.70201 ; Accuracy of 0.59180\n","Epoch 139 : Train Loss of 0.61407 ; Valid Loss of 0.71141 ; Accuracy of 0.58789\n","Epoch 140 : Train Loss of 0.61389 ; Valid Loss of 0.70784 ; Accuracy of 0.59570\n","Epoch 141 : Train Loss of 0.61215 ; Valid Loss of 0.71523 ; Accuracy of 0.58789\n","Epoch 142 : Train Loss of 0.61111 ; Valid Loss of 0.70023 ; Accuracy of 0.60352\n","Epoch 143 : Train Loss of 0.61100 ; Valid Loss of 0.70509 ; Accuracy of 0.59668\n","Epoch 144 : Train Loss of 0.61109 ; Valid Loss of 0.70943 ; Accuracy of 0.58789\n","Epoch 145 : Train Loss of 0.61037 ; Valid Loss of 0.70348 ; Accuracy of 0.60645\n","Epoch 146 : Train Loss of 0.60910 ; Valid Loss of 0.69841 ; Accuracy of 0.60645\n","Epoch 147 : Train Loss of 0.61106 ; Valid Loss of 0.70558 ; Accuracy of 0.59082\n","Early Stopping, Best Optimal Number of Epoch is 97\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d6a5eb8>\n","Training For Optimal Number of Epochs 97 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.05709\n","Epoch 1 : Entire Train Loss of 0.96014\n","Epoch 2 : Entire Train Loss of 0.88085\n","Epoch 3 : Entire Train Loss of 0.82200\n","Epoch 4 : Entire Train Loss of 0.77225\n","Epoch 5 : Entire Train Loss of 0.73955\n","Epoch 6 : Entire Train Loss of 0.71319\n","Epoch 7 : Entire Train Loss of 0.69095\n","Epoch 8 : Entire Train Loss of 0.67249\n","Epoch 9 : Entire Train Loss of 0.66143\n","Epoch 10 : Entire Train Loss of 0.64964\n","Epoch 11 : Entire Train Loss of 0.64083\n","Epoch 12 : Entire Train Loss of 0.63395\n","Epoch 13 : Entire Train Loss of 0.62711\n","Epoch 14 : Entire Train Loss of 0.62212\n","Epoch 15 : Entire Train Loss of 0.61551\n","Epoch 16 : Entire Train Loss of 0.61255\n","Epoch 17 : Entire Train Loss of 0.60933\n","Epoch 18 : Entire Train Loss of 0.60448\n","Epoch 19 : Entire Train Loss of 0.60339\n","Epoch 20 : Entire Train Loss of 0.60235\n","Epoch 21 : Entire Train Loss of 0.60087\n","Epoch 22 : Entire Train Loss of 0.59701\n","Epoch 23 : Entire Train Loss of 0.59592\n","Epoch 24 : Entire Train Loss of 0.59318\n","Epoch 25 : Entire Train Loss of 0.58982\n","Epoch 26 : Entire Train Loss of 0.58882\n","Epoch 27 : Entire Train Loss of 0.58610\n","Epoch 28 : Entire Train Loss of 0.58302\n","Epoch 29 : Entire Train Loss of 0.57925\n","Epoch 30 : Entire Train Loss of 0.57680\n","Epoch 31 : Entire Train Loss of 0.57292\n","Epoch 32 : Entire Train Loss of 0.56890\n","Epoch 33 : Entire Train Loss of 0.56662\n","Epoch 34 : Entire Train Loss of 0.56217\n","Epoch 35 : Entire Train Loss of 0.55712\n","Epoch 36 : Entire Train Loss of 0.55508\n","Epoch 37 : Entire Train Loss of 0.55128\n","Epoch 38 : Entire Train Loss of 0.54664\n","Epoch 39 : Entire Train Loss of 0.54073\n","Epoch 40 : Entire Train Loss of 0.53662\n","Epoch 41 : Entire Train Loss of 0.53303\n","Epoch 42 : Entire Train Loss of 0.52720\n","Epoch 43 : Entire Train Loss of 0.52393\n","Epoch 44 : Entire Train Loss of 0.51736\n","Epoch 45 : Entire Train Loss of 0.51325\n","Epoch 46 : Entire Train Loss of 0.50679\n","Epoch 47 : Entire Train Loss of 0.50161\n","Epoch 48 : Entire Train Loss of 0.49735\n","Epoch 49 : Entire Train Loss of 0.49327\n","Epoch 50 : Entire Train Loss of 0.48805\n","Epoch 51 : Entire Train Loss of 0.48132\n","Epoch 52 : Entire Train Loss of 0.47776\n","Epoch 53 : Entire Train Loss of 0.47311\n","Epoch 54 : Entire Train Loss of 0.46821\n","Epoch 55 : Entire Train Loss of 0.46192\n","Epoch 56 : Entire Train Loss of 0.45559\n","Epoch 57 : Entire Train Loss of 0.45577\n","Epoch 58 : Entire Train Loss of 0.44864\n","Epoch 59 : Entire Train Loss of 0.44357\n","Epoch 60 : Entire Train Loss of 0.44018\n","Epoch 61 : Entire Train Loss of 0.43047\n","Epoch 62 : Entire Train Loss of 0.42772\n","Epoch 63 : Entire Train Loss of 0.42329\n","Epoch 64 : Entire Train Loss of 0.42105\n","Epoch 65 : Entire Train Loss of 0.41696\n","Epoch 66 : Entire Train Loss of 0.41495\n","Epoch 67 : Entire Train Loss of 0.40904\n","Epoch 68 : Entire Train Loss of 0.40081\n","Epoch 69 : Entire Train Loss of 0.39916\n","Epoch 70 : Entire Train Loss of 0.39359\n","Epoch 71 : Entire Train Loss of 0.39479\n","Epoch 72 : Entire Train Loss of 0.38787\n","Epoch 73 : Entire Train Loss of 0.38444\n","Epoch 74 : Entire Train Loss of 0.38134\n","Epoch 75 : Entire Train Loss of 0.37541\n","Epoch 76 : Entire Train Loss of 0.37057\n","Epoch 77 : Entire Train Loss of 0.37274\n","Epoch 78 : Entire Train Loss of 0.36693\n","Epoch 79 : Entire Train Loss of 0.36311\n","Epoch 80 : Entire Train Loss of 0.35739\n","Epoch 81 : Entire Train Loss of 0.35585\n","Epoch 82 : Entire Train Loss of 0.35153\n","Epoch 83 : Entire Train Loss of 0.34873\n","Epoch 84 : Entire Train Loss of 0.34725\n","Epoch 85 : Entire Train Loss of 0.34700\n","Epoch 86 : Entire Train Loss of 0.34104\n","Epoch 87 : Entire Train Loss of 0.33666\n","Epoch 88 : Entire Train Loss of 0.33215\n","Epoch 89 : Entire Train Loss of 0.32982\n","Epoch 90 : Entire Train Loss of 0.33163\n","Epoch 91 : Entire Train Loss of 0.32398\n","Epoch 92 : Entire Train Loss of 0.32331\n","Epoch 93 : Entire Train Loss of 0.31831\n","Epoch 94 : Entire Train Loss of 0.31499\n","Epoch 95 : Entire Train Loss of 0.30982\n","Epoch 96 : Entire Train Loss of 0.30905\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d715c50>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.00589 ; Valid Loss of 0.76453 ; Accuracy of 0.50293\n","Epoch 2 : Train Loss of 0.95265 ; Valid Loss of 0.74137 ; Accuracy of 0.52930\n","Epoch 3 : Train Loss of 0.91742 ; Valid Loss of 0.73643 ; Accuracy of 0.53027\n","Epoch 4 : Train Loss of 0.89514 ; Valid Loss of 0.73178 ; Accuracy of 0.53223\n","Epoch 5 : Train Loss of 0.86985 ; Valid Loss of 0.72512 ; Accuracy of 0.54004\n","Epoch 6 : Train Loss of 0.86182 ; Valid Loss of 0.72118 ; Accuracy of 0.54590\n","Epoch 7 : Train Loss of 0.84299 ; Valid Loss of 0.70796 ; Accuracy of 0.55762\n","Epoch 8 : Train Loss of 0.83546 ; Valid Loss of 0.70735 ; Accuracy of 0.56055\n","Epoch 9 : Train Loss of 0.82352 ; Valid Loss of 0.70407 ; Accuracy of 0.56348\n","Epoch 10 : Train Loss of 0.80754 ; Valid Loss of 0.70886 ; Accuracy of 0.55664\n","Epoch 11 : Train Loss of 0.80432 ; Valid Loss of 0.69568 ; Accuracy of 0.57812\n","Epoch 12 : Train Loss of 0.79161 ; Valid Loss of 0.70250 ; Accuracy of 0.57324\n","Epoch 13 : Train Loss of 0.78554 ; Valid Loss of 0.70097 ; Accuracy of 0.57715\n","Epoch 14 : Train Loss of 0.78722 ; Valid Loss of 0.70297 ; Accuracy of 0.57910\n","Epoch 15 : Train Loss of 0.77095 ; Valid Loss of 0.69646 ; Accuracy of 0.58008\n","Epoch 16 : Train Loss of 0.77394 ; Valid Loss of 0.69135 ; Accuracy of 0.58594\n","Epoch 17 : Train Loss of 0.76518 ; Valid Loss of 0.68851 ; Accuracy of 0.58398\n","Epoch 18 : Train Loss of 0.76465 ; Valid Loss of 0.69573 ; Accuracy of 0.57715\n","Epoch 19 : Train Loss of 0.75490 ; Valid Loss of 0.69127 ; Accuracy of 0.58203\n","Epoch 20 : Train Loss of 0.74447 ; Valid Loss of 0.69514 ; Accuracy of 0.58203\n","Epoch 21 : Train Loss of 0.74862 ; Valid Loss of 0.69058 ; Accuracy of 0.58496\n","Epoch 22 : Train Loss of 0.74132 ; Valid Loss of 0.68870 ; Accuracy of 0.58398\n","Epoch 23 : Train Loss of 0.73938 ; Valid Loss of 0.69048 ; Accuracy of 0.58496\n","Epoch 24 : Train Loss of 0.73738 ; Valid Loss of 0.69631 ; Accuracy of 0.57812\n","Epoch 25 : Train Loss of 0.72853 ; Valid Loss of 0.68914 ; Accuracy of 0.58789\n","Epoch 26 : Train Loss of 0.72688 ; Valid Loss of 0.68658 ; Accuracy of 0.58887\n","Epoch 27 : Train Loss of 0.72509 ; Valid Loss of 0.68635 ; Accuracy of 0.57910\n","Epoch 28 : Train Loss of 0.71730 ; Valid Loss of 0.68901 ; Accuracy of 0.58789\n","Epoch 29 : Train Loss of 0.72013 ; Valid Loss of 0.69153 ; Accuracy of 0.58496\n","Epoch 30 : Train Loss of 0.71559 ; Valid Loss of 0.69231 ; Accuracy of 0.58105\n","Epoch 31 : Train Loss of 0.71639 ; Valid Loss of 0.69146 ; Accuracy of 0.57910\n","Epoch 32 : Train Loss of 0.71455 ; Valid Loss of 0.69545 ; Accuracy of 0.58301\n","Epoch 33 : Train Loss of 0.71331 ; Valid Loss of 0.69456 ; Accuracy of 0.57617\n","Epoch 34 : Train Loss of 0.70838 ; Valid Loss of 0.69351 ; Accuracy of 0.58203\n","Epoch 35 : Train Loss of 0.70330 ; Valid Loss of 0.69266 ; Accuracy of 0.58496\n","Epoch 36 : Train Loss of 0.70503 ; Valid Loss of 0.68609 ; Accuracy of 0.58789\n","Epoch 37 : Train Loss of 0.69492 ; Valid Loss of 0.69348 ; Accuracy of 0.58496\n","Epoch 38 : Train Loss of 0.69615 ; Valid Loss of 0.69810 ; Accuracy of 0.57812\n","Epoch 39 : Train Loss of 0.69580 ; Valid Loss of 0.69243 ; Accuracy of 0.57812\n","Epoch 40 : Train Loss of 0.69332 ; Valid Loss of 0.69239 ; Accuracy of 0.58398\n","Epoch 41 : Train Loss of 0.69121 ; Valid Loss of 0.68287 ; Accuracy of 0.58887\n","Epoch 42 : Train Loss of 0.69015 ; Valid Loss of 0.69276 ; Accuracy of 0.58789\n","Epoch 43 : Train Loss of 0.68915 ; Valid Loss of 0.68659 ; Accuracy of 0.59766\n","Epoch 44 : Train Loss of 0.68764 ; Valid Loss of 0.68878 ; Accuracy of 0.59473\n","Epoch 45 : Train Loss of 0.68604 ; Valid Loss of 0.69422 ; Accuracy of 0.57715\n","Epoch 46 : Train Loss of 0.67874 ; Valid Loss of 0.69230 ; Accuracy of 0.59180\n","Epoch 47 : Train Loss of 0.68008 ; Valid Loss of 0.69192 ; Accuracy of 0.58984\n","Epoch 48 : Train Loss of 0.67876 ; Valid Loss of 0.69548 ; Accuracy of 0.58691\n","Epoch 49 : Train Loss of 0.67746 ; Valid Loss of 0.69968 ; Accuracy of 0.58398\n","Epoch 50 : Train Loss of 0.67603 ; Valid Loss of 0.68538 ; Accuracy of 0.59766\n","Epoch 51 : Train Loss of 0.67628 ; Valid Loss of 0.69490 ; Accuracy of 0.58105\n","Epoch 52 : Train Loss of 0.67490 ; Valid Loss of 0.69196 ; Accuracy of 0.58984\n","Epoch 53 : Train Loss of 0.67036 ; Valid Loss of 0.68911 ; Accuracy of 0.58691\n","Epoch 54 : Train Loss of 0.67363 ; Valid Loss of 0.68730 ; Accuracy of 0.59180\n","Epoch 55 : Train Loss of 0.67064 ; Valid Loss of 0.69183 ; Accuracy of 0.58105\n","Epoch 56 : Train Loss of 0.66710 ; Valid Loss of 0.69058 ; Accuracy of 0.58594\n","Epoch 57 : Train Loss of 0.66728 ; Valid Loss of 0.69105 ; Accuracy of 0.58594\n","Epoch 58 : Train Loss of 0.66469 ; Valid Loss of 0.69145 ; Accuracy of 0.58398\n","Epoch 59 : Train Loss of 0.66258 ; Valid Loss of 0.69403 ; Accuracy of 0.58105\n","Epoch 60 : Train Loss of 0.66064 ; Valid Loss of 0.69140 ; Accuracy of 0.58105\n","Epoch 61 : Train Loss of 0.66397 ; Valid Loss of 0.69243 ; Accuracy of 0.58496\n","Epoch 62 : Train Loss of 0.65865 ; Valid Loss of 0.69060 ; Accuracy of 0.57910\n","Epoch 63 : Train Loss of 0.66337 ; Valid Loss of 0.69370 ; Accuracy of 0.59375\n","Epoch 64 : Train Loss of 0.66131 ; Valid Loss of 0.69021 ; Accuracy of 0.59180\n","Epoch 65 : Train Loss of 0.65864 ; Valid Loss of 0.68832 ; Accuracy of 0.58887\n","Epoch 66 : Train Loss of 0.65194 ; Valid Loss of 0.68648 ; Accuracy of 0.60254\n","Epoch 67 : Train Loss of 0.65663 ; Valid Loss of 0.69991 ; Accuracy of 0.58496\n","Epoch 68 : Train Loss of 0.65485 ; Valid Loss of 0.69097 ; Accuracy of 0.58496\n","Epoch 69 : Train Loss of 0.65280 ; Valid Loss of 0.69584 ; Accuracy of 0.58203\n","Epoch 70 : Train Loss of 0.65485 ; Valid Loss of 0.70127 ; Accuracy of 0.58398\n","Epoch 71 : Train Loss of 0.64984 ; Valid Loss of 0.68652 ; Accuracy of 0.59473\n","Epoch 72 : Train Loss of 0.65212 ; Valid Loss of 0.69099 ; Accuracy of 0.58203\n","Epoch 73 : Train Loss of 0.65086 ; Valid Loss of 0.69163 ; Accuracy of 0.59570\n","Epoch 74 : Train Loss of 0.65378 ; Valid Loss of 0.68727 ; Accuracy of 0.60352\n","Epoch 75 : Train Loss of 0.64597 ; Valid Loss of 0.69092 ; Accuracy of 0.58984\n","Epoch 76 : Train Loss of 0.64621 ; Valid Loss of 0.69328 ; Accuracy of 0.59082\n","Epoch 77 : Train Loss of 0.64602 ; Valid Loss of 0.69405 ; Accuracy of 0.59180\n","Epoch 78 : Train Loss of 0.64422 ; Valid Loss of 0.68928 ; Accuracy of 0.59668\n","Epoch 79 : Train Loss of 0.64304 ; Valid Loss of 0.70054 ; Accuracy of 0.58105\n","Epoch 80 : Train Loss of 0.64304 ; Valid Loss of 0.69796 ; Accuracy of 0.59082\n","Epoch 81 : Train Loss of 0.64579 ; Valid Loss of 0.68298 ; Accuracy of 0.59668\n","Epoch 82 : Train Loss of 0.64141 ; Valid Loss of 0.68885 ; Accuracy of 0.59668\n","Epoch 83 : Train Loss of 0.64241 ; Valid Loss of 0.69524 ; Accuracy of 0.58789\n","Epoch 84 : Train Loss of 0.64075 ; Valid Loss of 0.69330 ; Accuracy of 0.58887\n","Epoch 85 : Train Loss of 0.64103 ; Valid Loss of 0.70260 ; Accuracy of 0.58496\n","Epoch 86 : Train Loss of 0.64150 ; Valid Loss of 0.69533 ; Accuracy of 0.58398\n","Epoch 87 : Train Loss of 0.63788 ; Valid Loss of 0.70079 ; Accuracy of 0.59082\n","Epoch 88 : Train Loss of 0.63683 ; Valid Loss of 0.69339 ; Accuracy of 0.58789\n","Epoch 89 : Train Loss of 0.63674 ; Valid Loss of 0.69905 ; Accuracy of 0.58594\n","Epoch 90 : Train Loss of 0.63885 ; Valid Loss of 0.68405 ; Accuracy of 0.59668\n","Epoch 91 : Train Loss of 0.63661 ; Valid Loss of 0.69492 ; Accuracy of 0.59863\n","Early Stopping, Best Optimal Number of Epoch is 41\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d6a5588>\n","Training For Optimal Number of Epochs 41 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.03268\n","Epoch 1 : Entire Train Loss of 0.93931\n","Epoch 2 : Entire Train Loss of 0.86090\n","Epoch 3 : Entire Train Loss of 0.80420\n","Epoch 4 : Entire Train Loss of 0.76788\n","Epoch 5 : Entire Train Loss of 0.73450\n","Epoch 6 : Entire Train Loss of 0.70649\n","Epoch 7 : Entire Train Loss of 0.68579\n","Epoch 8 : Entire Train Loss of 0.66942\n","Epoch 9 : Entire Train Loss of 0.65714\n","Epoch 10 : Entire Train Loss of 0.64701\n","Epoch 11 : Entire Train Loss of 0.64108\n","Epoch 12 : Entire Train Loss of 0.63064\n","Epoch 13 : Entire Train Loss of 0.62679\n","Epoch 14 : Entire Train Loss of 0.61976\n","Epoch 15 : Entire Train Loss of 0.61535\n","Epoch 16 : Entire Train Loss of 0.60994\n","Epoch 17 : Entire Train Loss of 0.60759\n","Epoch 18 : Entire Train Loss of 0.60458\n","Epoch 19 : Entire Train Loss of 0.60297\n","Epoch 20 : Entire Train Loss of 0.60151\n","Epoch 21 : Entire Train Loss of 0.59947\n","Epoch 22 : Entire Train Loss of 0.59682\n","Epoch 23 : Entire Train Loss of 0.59270\n","Epoch 24 : Entire Train Loss of 0.59178\n","Epoch 25 : Entire Train Loss of 0.58909\n","Epoch 26 : Entire Train Loss of 0.58643\n","Epoch 27 : Entire Train Loss of 0.58321\n","Epoch 28 : Entire Train Loss of 0.58081\n","Epoch 29 : Entire Train Loss of 0.57631\n","Epoch 30 : Entire Train Loss of 0.57395\n","Epoch 31 : Entire Train Loss of 0.57066\n","Epoch 32 : Entire Train Loss of 0.56666\n","Epoch 33 : Entire Train Loss of 0.56477\n","Epoch 34 : Entire Train Loss of 0.55876\n","Epoch 35 : Entire Train Loss of 0.55495\n","Epoch 36 : Entire Train Loss of 0.55121\n","Epoch 37 : Entire Train Loss of 0.54719\n","Epoch 38 : Entire Train Loss of 0.54109\n","Epoch 39 : Entire Train Loss of 0.53807\n","Epoch 40 : Entire Train Loss of 0.53420\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d715198>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.04824 ; Valid Loss of 0.77186 ; Accuracy of 0.49707\n","Epoch 2 : Train Loss of 0.99417 ; Valid Loss of 0.73739 ; Accuracy of 0.53320\n","Epoch 3 : Train Loss of 0.95019 ; Valid Loss of 0.74859 ; Accuracy of 0.53516\n","Epoch 4 : Train Loss of 0.92931 ; Valid Loss of 0.73344 ; Accuracy of 0.54395\n","Epoch 5 : Train Loss of 0.90985 ; Valid Loss of 0.72934 ; Accuracy of 0.56348\n","Epoch 6 : Train Loss of 0.88489 ; Valid Loss of 0.72640 ; Accuracy of 0.57129\n","Epoch 7 : Train Loss of 0.86618 ; Valid Loss of 0.73170 ; Accuracy of 0.55664\n","Epoch 8 : Train Loss of 0.85575 ; Valid Loss of 0.71643 ; Accuracy of 0.57617\n","Epoch 9 : Train Loss of 0.84387 ; Valid Loss of 0.72521 ; Accuracy of 0.57129\n","Epoch 10 : Train Loss of 0.83402 ; Valid Loss of 0.73132 ; Accuracy of 0.56738\n","Epoch 11 : Train Loss of 0.82930 ; Valid Loss of 0.73262 ; Accuracy of 0.56836\n","Epoch 12 : Train Loss of 0.81259 ; Valid Loss of 0.73487 ; Accuracy of 0.55957\n","Epoch 13 : Train Loss of 0.80760 ; Valid Loss of 0.73068 ; Accuracy of 0.57129\n","Epoch 14 : Train Loss of 0.79970 ; Valid Loss of 0.72388 ; Accuracy of 0.58984\n","Epoch 15 : Train Loss of 0.79401 ; Valid Loss of 0.72662 ; Accuracy of 0.57520\n","Epoch 16 : Train Loss of 0.78864 ; Valid Loss of 0.71973 ; Accuracy of 0.57617\n","Epoch 17 : Train Loss of 0.78248 ; Valid Loss of 0.72822 ; Accuracy of 0.57324\n","Epoch 18 : Train Loss of 0.77896 ; Valid Loss of 0.72648 ; Accuracy of 0.56934\n","Epoch 19 : Train Loss of 0.77025 ; Valid Loss of 0.72861 ; Accuracy of 0.58203\n","Epoch 20 : Train Loss of 0.76859 ; Valid Loss of 0.73322 ; Accuracy of 0.57227\n","Epoch 21 : Train Loss of 0.76033 ; Valid Loss of 0.73270 ; Accuracy of 0.57129\n","Epoch 22 : Train Loss of 0.76035 ; Valid Loss of 0.73480 ; Accuracy of 0.57324\n","Epoch 23 : Train Loss of 0.75419 ; Valid Loss of 0.72352 ; Accuracy of 0.57812\n","Epoch 24 : Train Loss of 0.74740 ; Valid Loss of 0.73232 ; Accuracy of 0.57812\n","Epoch 25 : Train Loss of 0.74561 ; Valid Loss of 0.71580 ; Accuracy of 0.58301\n","Epoch 26 : Train Loss of 0.74301 ; Valid Loss of 0.73070 ; Accuracy of 0.57324\n","Epoch 27 : Train Loss of 0.73605 ; Valid Loss of 0.72739 ; Accuracy of 0.58301\n","Epoch 28 : Train Loss of 0.73382 ; Valid Loss of 0.72640 ; Accuracy of 0.57617\n","Epoch 29 : Train Loss of 0.73265 ; Valid Loss of 0.73170 ; Accuracy of 0.57324\n","Epoch 30 : Train Loss of 0.73066 ; Valid Loss of 0.72167 ; Accuracy of 0.57617\n","Epoch 31 : Train Loss of 0.73088 ; Valid Loss of 0.72917 ; Accuracy of 0.57617\n","Epoch 32 : Train Loss of 0.71955 ; Valid Loss of 0.72753 ; Accuracy of 0.57812\n","Epoch 33 : Train Loss of 0.72035 ; Valid Loss of 0.71849 ; Accuracy of 0.58984\n","Epoch 34 : Train Loss of 0.71706 ; Valid Loss of 0.73047 ; Accuracy of 0.57715\n","Epoch 35 : Train Loss of 0.72039 ; Valid Loss of 0.71801 ; Accuracy of 0.58398\n","Epoch 36 : Train Loss of 0.71709 ; Valid Loss of 0.71300 ; Accuracy of 0.58594\n","Epoch 37 : Train Loss of 0.71304 ; Valid Loss of 0.71949 ; Accuracy of 0.59082\n","Epoch 38 : Train Loss of 0.71008 ; Valid Loss of 0.71309 ; Accuracy of 0.58789\n","Epoch 39 : Train Loss of 0.70632 ; Valid Loss of 0.71829 ; Accuracy of 0.58008\n","Epoch 40 : Train Loss of 0.70568 ; Valid Loss of 0.71857 ; Accuracy of 0.58594\n","Epoch 41 : Train Loss of 0.70266 ; Valid Loss of 0.71446 ; Accuracy of 0.58789\n","Epoch 42 : Train Loss of 0.69621 ; Valid Loss of 0.71432 ; Accuracy of 0.58496\n","Epoch 43 : Train Loss of 0.69886 ; Valid Loss of 0.71309 ; Accuracy of 0.59082\n","Epoch 44 : Train Loss of 0.69369 ; Valid Loss of 0.71601 ; Accuracy of 0.57520\n","Epoch 45 : Train Loss of 0.69384 ; Valid Loss of 0.70765 ; Accuracy of 0.59180\n","Epoch 46 : Train Loss of 0.68781 ; Valid Loss of 0.71019 ; Accuracy of 0.59277\n","Epoch 47 : Train Loss of 0.69274 ; Valid Loss of 0.70918 ; Accuracy of 0.58984\n","Epoch 48 : Train Loss of 0.68696 ; Valid Loss of 0.71481 ; Accuracy of 0.58105\n","Epoch 49 : Train Loss of 0.68584 ; Valid Loss of 0.70828 ; Accuracy of 0.58691\n","Epoch 50 : Train Loss of 0.68329 ; Valid Loss of 0.71966 ; Accuracy of 0.57715\n","Epoch 51 : Train Loss of 0.68559 ; Valid Loss of 0.71027 ; Accuracy of 0.58105\n","Epoch 52 : Train Loss of 0.68222 ; Valid Loss of 0.70698 ; Accuracy of 0.58789\n","Epoch 53 : Train Loss of 0.67993 ; Valid Loss of 0.71098 ; Accuracy of 0.58691\n","Epoch 54 : Train Loss of 0.68323 ; Valid Loss of 0.71668 ; Accuracy of 0.57617\n","Epoch 55 : Train Loss of 0.67935 ; Valid Loss of 0.71144 ; Accuracy of 0.58887\n","Epoch 56 : Train Loss of 0.67548 ; Valid Loss of 0.71600 ; Accuracy of 0.58691\n","Epoch 57 : Train Loss of 0.67562 ; Valid Loss of 0.70892 ; Accuracy of 0.58887\n","Epoch 58 : Train Loss of 0.67125 ; Valid Loss of 0.71044 ; Accuracy of 0.59668\n","Epoch 59 : Train Loss of 0.66792 ; Valid Loss of 0.70677 ; Accuracy of 0.59375\n","Epoch 60 : Train Loss of 0.67055 ; Valid Loss of 0.70270 ; Accuracy of 0.59180\n","Epoch 61 : Train Loss of 0.67324 ; Valid Loss of 0.71005 ; Accuracy of 0.58594\n","Epoch 62 : Train Loss of 0.66962 ; Valid Loss of 0.70990 ; Accuracy of 0.58691\n","Epoch 63 : Train Loss of 0.67130 ; Valid Loss of 0.69929 ; Accuracy of 0.59961\n","Epoch 64 : Train Loss of 0.66470 ; Valid Loss of 0.69885 ; Accuracy of 0.58887\n","Epoch 65 : Train Loss of 0.66400 ; Valid Loss of 0.71236 ; Accuracy of 0.58398\n","Epoch 66 : Train Loss of 0.66709 ; Valid Loss of 0.70786 ; Accuracy of 0.59277\n","Epoch 67 : Train Loss of 0.66477 ; Valid Loss of 0.70775 ; Accuracy of 0.59082\n","Epoch 68 : Train Loss of 0.65885 ; Valid Loss of 0.70596 ; Accuracy of 0.58984\n","Epoch 69 : Train Loss of 0.66192 ; Valid Loss of 0.71351 ; Accuracy of 0.59863\n","Epoch 70 : Train Loss of 0.65627 ; Valid Loss of 0.71691 ; Accuracy of 0.59082\n","Epoch 71 : Train Loss of 0.65755 ; Valid Loss of 0.71685 ; Accuracy of 0.58301\n","Epoch 72 : Train Loss of 0.65779 ; Valid Loss of 0.70838 ; Accuracy of 0.59180\n","Epoch 73 : Train Loss of 0.65665 ; Valid Loss of 0.71379 ; Accuracy of 0.58496\n","Epoch 74 : Train Loss of 0.65647 ; Valid Loss of 0.70483 ; Accuracy of 0.59375\n","Epoch 75 : Train Loss of 0.65494 ; Valid Loss of 0.70637 ; Accuracy of 0.59180\n","Epoch 76 : Train Loss of 0.65661 ; Valid Loss of 0.70398 ; Accuracy of 0.59766\n","Epoch 77 : Train Loss of 0.65512 ; Valid Loss of 0.71424 ; Accuracy of 0.59180\n","Epoch 78 : Train Loss of 0.65474 ; Valid Loss of 0.71927 ; Accuracy of 0.58691\n","Epoch 79 : Train Loss of 0.65083 ; Valid Loss of 0.70459 ; Accuracy of 0.59766\n","Epoch 80 : Train Loss of 0.64886 ; Valid Loss of 0.70644 ; Accuracy of 0.59180\n","Epoch 81 : Train Loss of 0.64719 ; Valid Loss of 0.71281 ; Accuracy of 0.59473\n","Epoch 82 : Train Loss of 0.64885 ; Valid Loss of 0.70170 ; Accuracy of 0.59766\n","Epoch 83 : Train Loss of 0.64857 ; Valid Loss of 0.71822 ; Accuracy of 0.58398\n","Epoch 84 : Train Loss of 0.64562 ; Valid Loss of 0.70741 ; Accuracy of 0.59277\n","Epoch 85 : Train Loss of 0.64565 ; Valid Loss of 0.71131 ; Accuracy of 0.58301\n","Epoch 86 : Train Loss of 0.64500 ; Valid Loss of 0.70771 ; Accuracy of 0.59082\n","Epoch 87 : Train Loss of 0.64693 ; Valid Loss of 0.70729 ; Accuracy of 0.59180\n","Epoch 88 : Train Loss of 0.64302 ; Valid Loss of 0.70689 ; Accuracy of 0.58789\n","Epoch 89 : Train Loss of 0.64192 ; Valid Loss of 0.70871 ; Accuracy of 0.58887\n","Epoch 90 : Train Loss of 0.64188 ; Valid Loss of 0.71103 ; Accuracy of 0.59180\n","Epoch 91 : Train Loss of 0.64020 ; Valid Loss of 0.71133 ; Accuracy of 0.58789\n","Epoch 92 : Train Loss of 0.64217 ; Valid Loss of 0.69746 ; Accuracy of 0.59766\n","Epoch 93 : Train Loss of 0.64123 ; Valid Loss of 0.70132 ; Accuracy of 0.59766\n","Epoch 94 : Train Loss of 0.63538 ; Valid Loss of 0.71280 ; Accuracy of 0.58398\n","Epoch 95 : Train Loss of 0.64068 ; Valid Loss of 0.70624 ; Accuracy of 0.59375\n","Epoch 96 : Train Loss of 0.63529 ; Valid Loss of 0.70460 ; Accuracy of 0.58984\n","Epoch 97 : Train Loss of 0.63647 ; Valid Loss of 0.71339 ; Accuracy of 0.58301\n","Epoch 98 : Train Loss of 0.63692 ; Valid Loss of 0.71352 ; Accuracy of 0.58984\n","Epoch 99 : Train Loss of 0.63820 ; Valid Loss of 0.71176 ; Accuracy of 0.59375\n","Epoch 100 : Train Loss of 0.63602 ; Valid Loss of 0.70838 ; Accuracy of 0.59668\n","Epoch 101 : Train Loss of 0.63559 ; Valid Loss of 0.71075 ; Accuracy of 0.58789\n","Epoch 102 : Train Loss of 0.63547 ; Valid Loss of 0.71163 ; Accuracy of 0.59375\n","Epoch 103 : Train Loss of 0.63496 ; Valid Loss of 0.70799 ; Accuracy of 0.59277\n","Epoch 104 : Train Loss of 0.63369 ; Valid Loss of 0.71139 ; Accuracy of 0.59180\n","Epoch 105 : Train Loss of 0.63018 ; Valid Loss of 0.70500 ; Accuracy of 0.59668\n","Epoch 106 : Train Loss of 0.63175 ; Valid Loss of 0.70633 ; Accuracy of 0.59180\n","Epoch 107 : Train Loss of 0.63013 ; Valid Loss of 0.71180 ; Accuracy of 0.59375\n","Epoch 108 : Train Loss of 0.63466 ; Valid Loss of 0.70755 ; Accuracy of 0.59668\n","Epoch 109 : Train Loss of 0.62996 ; Valid Loss of 0.70571 ; Accuracy of 0.59375\n","Epoch 110 : Train Loss of 0.63281 ; Valid Loss of 0.70562 ; Accuracy of 0.59277\n","Epoch 111 : Train Loss of 0.62634 ; Valid Loss of 0.71295 ; Accuracy of 0.57617\n","Epoch 112 : Train Loss of 0.62901 ; Valid Loss of 0.70617 ; Accuracy of 0.59668\n","Epoch 113 : Train Loss of 0.62972 ; Valid Loss of 0.70783 ; Accuracy of 0.58594\n","Epoch 114 : Train Loss of 0.62927 ; Valid Loss of 0.70992 ; Accuracy of 0.58398\n","Epoch 115 : Train Loss of 0.62835 ; Valid Loss of 0.70900 ; Accuracy of 0.59082\n","Epoch 116 : Train Loss of 0.62492 ; Valid Loss of 0.70740 ; Accuracy of 0.58301\n","Epoch 117 : Train Loss of 0.62552 ; Valid Loss of 0.71664 ; Accuracy of 0.58008\n","Epoch 118 : Train Loss of 0.62491 ; Valid Loss of 0.71738 ; Accuracy of 0.58203\n","Epoch 119 : Train Loss of 0.62526 ; Valid Loss of 0.70569 ; Accuracy of 0.58594\n","Epoch 120 : Train Loss of 0.62549 ; Valid Loss of 0.71065 ; Accuracy of 0.59375\n","Epoch 121 : Train Loss of 0.62229 ; Valid Loss of 0.71896 ; Accuracy of 0.58984\n","Epoch 122 : Train Loss of 0.62391 ; Valid Loss of 0.71898 ; Accuracy of 0.58691\n","Epoch 123 : Train Loss of 0.62147 ; Valid Loss of 0.70833 ; Accuracy of 0.60840\n","Epoch 124 : Train Loss of 0.62097 ; Valid Loss of 0.70800 ; Accuracy of 0.59863\n","Epoch 125 : Train Loss of 0.61913 ; Valid Loss of 0.71900 ; Accuracy of 0.58984\n","Epoch 126 : Train Loss of 0.62052 ; Valid Loss of 0.70684 ; Accuracy of 0.59766\n","Epoch 127 : Train Loss of 0.62214 ; Valid Loss of 0.71416 ; Accuracy of 0.59863\n","Epoch 128 : Train Loss of 0.62163 ; Valid Loss of 0.70988 ; Accuracy of 0.60059\n","Epoch 129 : Train Loss of 0.61823 ; Valid Loss of 0.71355 ; Accuracy of 0.59180\n","Epoch 130 : Train Loss of 0.61955 ; Valid Loss of 0.71098 ; Accuracy of 0.59668\n","Epoch 131 : Train Loss of 0.61881 ; Valid Loss of 0.71328 ; Accuracy of 0.59570\n","Epoch 132 : Train Loss of 0.61806 ; Valid Loss of 0.70086 ; Accuracy of 0.60645\n","Epoch 133 : Train Loss of 0.61875 ; Valid Loss of 0.71084 ; Accuracy of 0.59473\n","Epoch 134 : Train Loss of 0.61710 ; Valid Loss of 0.71210 ; Accuracy of 0.59277\n","Epoch 135 : Train Loss of 0.61840 ; Valid Loss of 0.71461 ; Accuracy of 0.59375\n","Epoch 136 : Train Loss of 0.61716 ; Valid Loss of 0.70960 ; Accuracy of 0.59082\n","Epoch 137 : Train Loss of 0.61500 ; Valid Loss of 0.70919 ; Accuracy of 0.59570\n","Epoch 138 : Train Loss of 0.61577 ; Valid Loss of 0.71403 ; Accuracy of 0.60449\n","Epoch 139 : Train Loss of 0.61463 ; Valid Loss of 0.71563 ; Accuracy of 0.59082\n","Epoch 140 : Train Loss of 0.61401 ; Valid Loss of 0.71469 ; Accuracy of 0.59473\n","Epoch 141 : Train Loss of 0.61294 ; Valid Loss of 0.71709 ; Accuracy of 0.59473\n","Epoch 142 : Train Loss of 0.61270 ; Valid Loss of 0.71287 ; Accuracy of 0.59766\n","Early Stopping, Best Optimal Number of Epoch is 92\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea7128>\n","Training For Optimal Number of Epochs 92 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.00701\n","Epoch 1 : Entire Train Loss of 0.91215\n","Epoch 2 : Entire Train Loss of 0.84658\n","Epoch 3 : Entire Train Loss of 0.80432\n","Epoch 4 : Entire Train Loss of 0.76215\n","Epoch 5 : Entire Train Loss of 0.73208\n","Epoch 6 : Entire Train Loss of 0.70638\n","Epoch 7 : Entire Train Loss of 0.68284\n","Epoch 8 : Entire Train Loss of 0.66418\n","Epoch 9 : Entire Train Loss of 0.65421\n","Epoch 10 : Entire Train Loss of 0.64646\n","Epoch 11 : Entire Train Loss of 0.63856\n","Epoch 12 : Entire Train Loss of 0.62907\n","Epoch 13 : Entire Train Loss of 0.62126\n","Epoch 14 : Entire Train Loss of 0.61916\n","Epoch 15 : Entire Train Loss of 0.61570\n","Epoch 16 : Entire Train Loss of 0.60944\n","Epoch 17 : Entire Train Loss of 0.60578\n","Epoch 18 : Entire Train Loss of 0.60483\n","Epoch 19 : Entire Train Loss of 0.60218\n","Epoch 20 : Entire Train Loss of 0.59799\n","Epoch 21 : Entire Train Loss of 0.59755\n","Epoch 22 : Entire Train Loss of 0.59357\n","Epoch 23 : Entire Train Loss of 0.59157\n","Epoch 24 : Entire Train Loss of 0.58881\n","Epoch 25 : Entire Train Loss of 0.58718\n","Epoch 26 : Entire Train Loss of 0.58398\n","Epoch 27 : Entire Train Loss of 0.58057\n","Epoch 28 : Entire Train Loss of 0.57633\n","Epoch 29 : Entire Train Loss of 0.57375\n","Epoch 30 : Entire Train Loss of 0.57057\n","Epoch 31 : Entire Train Loss of 0.56880\n","Epoch 32 : Entire Train Loss of 0.56454\n","Epoch 33 : Entire Train Loss of 0.55841\n","Epoch 34 : Entire Train Loss of 0.55489\n","Epoch 35 : Entire Train Loss of 0.54916\n","Epoch 36 : Entire Train Loss of 0.54837\n","Epoch 37 : Entire Train Loss of 0.54254\n","Epoch 38 : Entire Train Loss of 0.53865\n","Epoch 39 : Entire Train Loss of 0.53126\n","Epoch 40 : Entire Train Loss of 0.52682\n","Epoch 41 : Entire Train Loss of 0.52393\n","Epoch 42 : Entire Train Loss of 0.51727\n","Epoch 43 : Entire Train Loss of 0.51293\n","Epoch 44 : Entire Train Loss of 0.50754\n","Epoch 45 : Entire Train Loss of 0.49988\n","Epoch 46 : Entire Train Loss of 0.49843\n","Epoch 47 : Entire Train Loss of 0.49349\n","Epoch 48 : Entire Train Loss of 0.48570\n","Epoch 49 : Entire Train Loss of 0.48217\n","Epoch 50 : Entire Train Loss of 0.47866\n","Epoch 51 : Entire Train Loss of 0.47371\n","Epoch 52 : Entire Train Loss of 0.46633\n","Epoch 53 : Entire Train Loss of 0.46172\n","Epoch 54 : Entire Train Loss of 0.45698\n","Epoch 55 : Entire Train Loss of 0.45489\n","Epoch 56 : Entire Train Loss of 0.44934\n","Epoch 57 : Entire Train Loss of 0.44404\n","Epoch 58 : Entire Train Loss of 0.43730\n","Epoch 59 : Entire Train Loss of 0.43619\n","Epoch 60 : Entire Train Loss of 0.42814\n","Epoch 61 : Entire Train Loss of 0.42725\n","Epoch 62 : Entire Train Loss of 0.42444\n","Epoch 63 : Entire Train Loss of 0.41841\n","Epoch 64 : Entire Train Loss of 0.40878\n","Epoch 65 : Entire Train Loss of 0.40738\n","Epoch 66 : Entire Train Loss of 0.40443\n","Epoch 67 : Entire Train Loss of 0.40214\n","Epoch 68 : Entire Train Loss of 0.39691\n","Epoch 69 : Entire Train Loss of 0.39008\n","Epoch 70 : Entire Train Loss of 0.38668\n","Epoch 71 : Entire Train Loss of 0.38449\n","Epoch 72 : Entire Train Loss of 0.37976\n","Epoch 73 : Entire Train Loss of 0.37436\n","Epoch 74 : Entire Train Loss of 0.37350\n","Epoch 75 : Entire Train Loss of 0.37074\n","Epoch 76 : Entire Train Loss of 0.36403\n","Epoch 77 : Entire Train Loss of 0.36563\n","Epoch 78 : Entire Train Loss of 0.36290\n","Epoch 79 : Entire Train Loss of 0.35683\n","Epoch 80 : Entire Train Loss of 0.35032\n","Epoch 81 : Entire Train Loss of 0.34911\n","Epoch 82 : Entire Train Loss of 0.34568\n","Epoch 83 : Entire Train Loss of 0.34183\n","Epoch 84 : Entire Train Loss of 0.33663\n","Epoch 85 : Entire Train Loss of 0.33634\n","Epoch 86 : Entire Train Loss of 0.33340\n","Epoch 87 : Entire Train Loss of 0.33306\n","Epoch 88 : Entire Train Loss of 0.32352\n","Epoch 89 : Entire Train Loss of 0.32439\n","Epoch 90 : Entire Train Loss of 0.32484\n","Epoch 91 : Entire Train Loss of 0.31714\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea7a20>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.00978 ; Valid Loss of 0.73486 ; Accuracy of 0.53711\n","Epoch 2 : Train Loss of 0.94744 ; Valid Loss of 0.72819 ; Accuracy of 0.55176\n","Epoch 3 : Train Loss of 0.91329 ; Valid Loss of 0.71485 ; Accuracy of 0.56445\n","Epoch 4 : Train Loss of 0.89414 ; Valid Loss of 0.71170 ; Accuracy of 0.57227\n","Epoch 5 : Train Loss of 0.87425 ; Valid Loss of 0.71364 ; Accuracy of 0.56738\n","Epoch 6 : Train Loss of 0.86167 ; Valid Loss of 0.71273 ; Accuracy of 0.56445\n","Epoch 7 : Train Loss of 0.84251 ; Valid Loss of 0.71780 ; Accuracy of 0.56836\n","Epoch 8 : Train Loss of 0.83260 ; Valid Loss of 0.70996 ; Accuracy of 0.57227\n","Epoch 9 : Train Loss of 0.82196 ; Valid Loss of 0.71429 ; Accuracy of 0.57129\n","Epoch 10 : Train Loss of 0.81369 ; Valid Loss of 0.70925 ; Accuracy of 0.57422\n","Epoch 11 : Train Loss of 0.80062 ; Valid Loss of 0.70648 ; Accuracy of 0.58008\n","Epoch 12 : Train Loss of 0.80181 ; Valid Loss of 0.70643 ; Accuracy of 0.58789\n","Epoch 13 : Train Loss of 0.78992 ; Valid Loss of 0.71196 ; Accuracy of 0.58594\n","Epoch 14 : Train Loss of 0.78235 ; Valid Loss of 0.71274 ; Accuracy of 0.58203\n","Epoch 15 : Train Loss of 0.78075 ; Valid Loss of 0.70357 ; Accuracy of 0.58496\n","Epoch 16 : Train Loss of 0.76856 ; Valid Loss of 0.70277 ; Accuracy of 0.58691\n","Epoch 17 : Train Loss of 0.76594 ; Valid Loss of 0.71256 ; Accuracy of 0.58691\n","Epoch 18 : Train Loss of 0.75953 ; Valid Loss of 0.71231 ; Accuracy of 0.58984\n","Epoch 19 : Train Loss of 0.75672 ; Valid Loss of 0.71237 ; Accuracy of 0.58984\n","Epoch 20 : Train Loss of 0.75145 ; Valid Loss of 0.69754 ; Accuracy of 0.58887\n","Epoch 21 : Train Loss of 0.74657 ; Valid Loss of 0.70778 ; Accuracy of 0.58398\n","Epoch 22 : Train Loss of 0.74764 ; Valid Loss of 0.70223 ; Accuracy of 0.58105\n","Epoch 23 : Train Loss of 0.73916 ; Valid Loss of 0.71594 ; Accuracy of 0.57031\n","Epoch 24 : Train Loss of 0.73604 ; Valid Loss of 0.70451 ; Accuracy of 0.59180\n","Epoch 25 : Train Loss of 0.73256 ; Valid Loss of 0.71014 ; Accuracy of 0.58496\n","Epoch 26 : Train Loss of 0.72798 ; Valid Loss of 0.70313 ; Accuracy of 0.57715\n","Epoch 27 : Train Loss of 0.72583 ; Valid Loss of 0.70953 ; Accuracy of 0.57812\n","Epoch 28 : Train Loss of 0.72378 ; Valid Loss of 0.71148 ; Accuracy of 0.58496\n","Epoch 29 : Train Loss of 0.72264 ; Valid Loss of 0.70428 ; Accuracy of 0.57910\n","Epoch 30 : Train Loss of 0.71763 ; Valid Loss of 0.70561 ; Accuracy of 0.59082\n","Epoch 31 : Train Loss of 0.71978 ; Valid Loss of 0.70325 ; Accuracy of 0.57520\n","Epoch 32 : Train Loss of 0.71464 ; Valid Loss of 0.70749 ; Accuracy of 0.57324\n","Epoch 33 : Train Loss of 0.70824 ; Valid Loss of 0.70574 ; Accuracy of 0.57422\n","Epoch 34 : Train Loss of 0.70482 ; Valid Loss of 0.70477 ; Accuracy of 0.58887\n","Epoch 35 : Train Loss of 0.70330 ; Valid Loss of 0.70764 ; Accuracy of 0.58398\n","Epoch 36 : Train Loss of 0.70772 ; Valid Loss of 0.71174 ; Accuracy of 0.56738\n","Epoch 37 : Train Loss of 0.70356 ; Valid Loss of 0.70198 ; Accuracy of 0.58594\n","Epoch 38 : Train Loss of 0.69963 ; Valid Loss of 0.70267 ; Accuracy of 0.58301\n","Epoch 39 : Train Loss of 0.69856 ; Valid Loss of 0.69427 ; Accuracy of 0.58887\n","Epoch 40 : Train Loss of 0.69767 ; Valid Loss of 0.70512 ; Accuracy of 0.58301\n","Epoch 41 : Train Loss of 0.69249 ; Valid Loss of 0.70226 ; Accuracy of 0.59473\n","Epoch 42 : Train Loss of 0.69234 ; Valid Loss of 0.69631 ; Accuracy of 0.58984\n","Epoch 43 : Train Loss of 0.68839 ; Valid Loss of 0.70603 ; Accuracy of 0.58105\n","Epoch 44 : Train Loss of 0.68732 ; Valid Loss of 0.69372 ; Accuracy of 0.59570\n","Epoch 45 : Train Loss of 0.68178 ; Valid Loss of 0.70205 ; Accuracy of 0.58789\n","Epoch 46 : Train Loss of 0.68029 ; Valid Loss of 0.70376 ; Accuracy of 0.58887\n","Epoch 47 : Train Loss of 0.68447 ; Valid Loss of 0.70669 ; Accuracy of 0.58594\n","Epoch 48 : Train Loss of 0.68268 ; Valid Loss of 0.69504 ; Accuracy of 0.58691\n","Epoch 49 : Train Loss of 0.67738 ; Valid Loss of 0.69708 ; Accuracy of 0.59082\n","Epoch 50 : Train Loss of 0.67292 ; Valid Loss of 0.68935 ; Accuracy of 0.58887\n","Epoch 51 : Train Loss of 0.67237 ; Valid Loss of 0.69948 ; Accuracy of 0.58105\n","Epoch 52 : Train Loss of 0.67627 ; Valid Loss of 0.69506 ; Accuracy of 0.59277\n","Epoch 53 : Train Loss of 0.67106 ; Valid Loss of 0.70362 ; Accuracy of 0.58594\n","Epoch 54 : Train Loss of 0.67027 ; Valid Loss of 0.70518 ; Accuracy of 0.58594\n","Epoch 55 : Train Loss of 0.66671 ; Valid Loss of 0.69238 ; Accuracy of 0.59668\n","Epoch 56 : Train Loss of 0.66964 ; Valid Loss of 0.69812 ; Accuracy of 0.59570\n","Epoch 57 : Train Loss of 0.66550 ; Valid Loss of 0.68026 ; Accuracy of 0.60449\n","Epoch 58 : Train Loss of 0.66494 ; Valid Loss of 0.70116 ; Accuracy of 0.59375\n","Epoch 59 : Train Loss of 0.66456 ; Valid Loss of 0.70246 ; Accuracy of 0.59082\n","Epoch 60 : Train Loss of 0.66574 ; Valid Loss of 0.69233 ; Accuracy of 0.59277\n","Epoch 61 : Train Loss of 0.65881 ; Valid Loss of 0.68840 ; Accuracy of 0.59961\n","Epoch 62 : Train Loss of 0.66491 ; Valid Loss of 0.69198 ; Accuracy of 0.59668\n","Epoch 63 : Train Loss of 0.66074 ; Valid Loss of 0.68884 ; Accuracy of 0.59668\n","Epoch 64 : Train Loss of 0.65933 ; Valid Loss of 0.69729 ; Accuracy of 0.59961\n","Epoch 65 : Train Loss of 0.65591 ; Valid Loss of 0.70301 ; Accuracy of 0.59082\n","Epoch 66 : Train Loss of 0.65754 ; Valid Loss of 0.68958 ; Accuracy of 0.60156\n","Epoch 67 : Train Loss of 0.65330 ; Valid Loss of 0.70037 ; Accuracy of 0.58691\n","Epoch 68 : Train Loss of 0.65322 ; Valid Loss of 0.69319 ; Accuracy of 0.59668\n","Epoch 69 : Train Loss of 0.65249 ; Valid Loss of 0.70122 ; Accuracy of 0.59180\n","Epoch 70 : Train Loss of 0.65156 ; Valid Loss of 0.70036 ; Accuracy of 0.59082\n","Epoch 71 : Train Loss of 0.64971 ; Valid Loss of 0.69301 ; Accuracy of 0.59766\n","Epoch 72 : Train Loss of 0.65279 ; Valid Loss of 0.69160 ; Accuracy of 0.59668\n","Epoch 73 : Train Loss of 0.65021 ; Valid Loss of 0.69502 ; Accuracy of 0.59277\n","Epoch 74 : Train Loss of 0.65118 ; Valid Loss of 0.69272 ; Accuracy of 0.59668\n","Epoch 75 : Train Loss of 0.64772 ; Valid Loss of 0.69588 ; Accuracy of 0.59180\n","Epoch 76 : Train Loss of 0.64825 ; Valid Loss of 0.69527 ; Accuracy of 0.58594\n","Epoch 77 : Train Loss of 0.64899 ; Valid Loss of 0.69170 ; Accuracy of 0.59668\n","Epoch 78 : Train Loss of 0.64671 ; Valid Loss of 0.70063 ; Accuracy of 0.58887\n","Epoch 79 : Train Loss of 0.64169 ; Valid Loss of 0.70123 ; Accuracy of 0.59375\n","Epoch 80 : Train Loss of 0.64250 ; Valid Loss of 0.68932 ; Accuracy of 0.60059\n","Epoch 81 : Train Loss of 0.64266 ; Valid Loss of 0.69294 ; Accuracy of 0.59668\n","Epoch 82 : Train Loss of 0.64142 ; Valid Loss of 0.69443 ; Accuracy of 0.59277\n","Epoch 83 : Train Loss of 0.64359 ; Valid Loss of 0.70504 ; Accuracy of 0.58398\n","Epoch 84 : Train Loss of 0.64032 ; Valid Loss of 0.69518 ; Accuracy of 0.58984\n","Epoch 85 : Train Loss of 0.63888 ; Valid Loss of 0.69065 ; Accuracy of 0.60352\n","Epoch 86 : Train Loss of 0.64131 ; Valid Loss of 0.69920 ; Accuracy of 0.59570\n","Epoch 87 : Train Loss of 0.63621 ; Valid Loss of 0.69219 ; Accuracy of 0.59473\n","Epoch 88 : Train Loss of 0.63888 ; Valid Loss of 0.69596 ; Accuracy of 0.59863\n","Epoch 89 : Train Loss of 0.63870 ; Valid Loss of 0.70084 ; Accuracy of 0.58594\n","Epoch 90 : Train Loss of 0.63667 ; Valid Loss of 0.70158 ; Accuracy of 0.59375\n","Epoch 91 : Train Loss of 0.63676 ; Valid Loss of 0.69799 ; Accuracy of 0.59375\n","Epoch 92 : Train Loss of 0.63763 ; Valid Loss of 0.69990 ; Accuracy of 0.59473\n","Epoch 93 : Train Loss of 0.63496 ; Valid Loss of 0.68695 ; Accuracy of 0.59766\n","Epoch 94 : Train Loss of 0.63570 ; Valid Loss of 0.69340 ; Accuracy of 0.60156\n","Epoch 95 : Train Loss of 0.63464 ; Valid Loss of 0.69488 ; Accuracy of 0.59570\n","Epoch 96 : Train Loss of 0.63298 ; Valid Loss of 0.69665 ; Accuracy of 0.59668\n","Epoch 97 : Train Loss of 0.62990 ; Valid Loss of 0.69467 ; Accuracy of 0.58887\n","Epoch 98 : Train Loss of 0.63092 ; Valid Loss of 0.69287 ; Accuracy of 0.59863\n","Epoch 99 : Train Loss of 0.63009 ; Valid Loss of 0.70462 ; Accuracy of 0.58984\n","Epoch 100 : Train Loss of 0.62898 ; Valid Loss of 0.69593 ; Accuracy of 0.59570\n","Epoch 101 : Train Loss of 0.63198 ; Valid Loss of 0.69317 ; Accuracy of 0.59961\n","Epoch 102 : Train Loss of 0.62989 ; Valid Loss of 0.68905 ; Accuracy of 0.60156\n","Epoch 103 : Train Loss of 0.62861 ; Valid Loss of 0.69690 ; Accuracy of 0.59668\n","Epoch 104 : Train Loss of 0.63056 ; Valid Loss of 0.68994 ; Accuracy of 0.60547\n","Epoch 105 : Train Loss of 0.62523 ; Valid Loss of 0.69821 ; Accuracy of 0.59961\n","Epoch 106 : Train Loss of 0.62648 ; Valid Loss of 0.69816 ; Accuracy of 0.59863\n","Epoch 107 : Train Loss of 0.62763 ; Valid Loss of 0.69961 ; Accuracy of 0.59863\n","Early Stopping, Best Optimal Number of Epoch is 57\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea7cc0>\n","Training For Optimal Number of Epochs 57 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.03673\n","Epoch 1 : Entire Train Loss of 0.94073\n","Epoch 2 : Entire Train Loss of 0.86177\n","Epoch 3 : Entire Train Loss of 0.80865\n","Epoch 4 : Entire Train Loss of 0.76311\n","Epoch 5 : Entire Train Loss of 0.73567\n","Epoch 6 : Entire Train Loss of 0.70578\n","Epoch 7 : Entire Train Loss of 0.69478\n","Epoch 8 : Entire Train Loss of 0.67274\n","Epoch 9 : Entire Train Loss of 0.66187\n","Epoch 10 : Entire Train Loss of 0.65045\n","Epoch 11 : Entire Train Loss of 0.64155\n","Epoch 12 : Entire Train Loss of 0.63406\n","Epoch 13 : Entire Train Loss of 0.63178\n","Epoch 14 : Entire Train Loss of 0.62393\n","Epoch 15 : Entire Train Loss of 0.61737\n","Epoch 16 : Entire Train Loss of 0.61229\n","Epoch 17 : Entire Train Loss of 0.60883\n","Epoch 18 : Entire Train Loss of 0.60839\n","Epoch 19 : Entire Train Loss of 0.60432\n","Epoch 20 : Entire Train Loss of 0.60208\n","Epoch 21 : Entire Train Loss of 0.59926\n","Epoch 22 : Entire Train Loss of 0.59931\n","Epoch 23 : Entire Train Loss of 0.59590\n","Epoch 24 : Entire Train Loss of 0.59231\n","Epoch 25 : Entire Train Loss of 0.59010\n","Epoch 26 : Entire Train Loss of 0.58861\n","Epoch 27 : Entire Train Loss of 0.58667\n","Epoch 28 : Entire Train Loss of 0.58257\n","Epoch 29 : Entire Train Loss of 0.57990\n","Epoch 30 : Entire Train Loss of 0.57731\n","Epoch 31 : Entire Train Loss of 0.57334\n","Epoch 32 : Entire Train Loss of 0.56984\n","Epoch 33 : Entire Train Loss of 0.56615\n","Epoch 34 : Entire Train Loss of 0.56186\n","Epoch 35 : Entire Train Loss of 0.55817\n","Epoch 36 : Entire Train Loss of 0.55190\n","Epoch 37 : Entire Train Loss of 0.55005\n","Epoch 38 : Entire Train Loss of 0.54348\n","Epoch 39 : Entire Train Loss of 0.53937\n","Epoch 40 : Entire Train Loss of 0.53525\n","Epoch 41 : Entire Train Loss of 0.52884\n","Epoch 42 : Entire Train Loss of 0.52698\n","Epoch 43 : Entire Train Loss of 0.51799\n","Epoch 44 : Entire Train Loss of 0.51358\n","Epoch 45 : Entire Train Loss of 0.50927\n","Epoch 46 : Entire Train Loss of 0.50206\n","Epoch 47 : Entire Train Loss of 0.50022\n","Epoch 48 : Entire Train Loss of 0.49514\n","Epoch 49 : Entire Train Loss of 0.48863\n","Epoch 50 : Entire Train Loss of 0.48452\n","Epoch 51 : Entire Train Loss of 0.48088\n","Epoch 52 : Entire Train Loss of 0.47509\n","Epoch 53 : Entire Train Loss of 0.46891\n","Epoch 54 : Entire Train Loss of 0.46578\n","Epoch 55 : Entire Train Loss of 0.45850\n","Epoch 56 : Entire Train Loss of 0.45268\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e6ea7e10>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.02639 ; Valid Loss of 0.73966 ; Accuracy of 0.52051\n","Epoch 2 : Train Loss of 0.95986 ; Valid Loss of 0.74014 ; Accuracy of 0.53613\n","Epoch 3 : Train Loss of 0.92615 ; Valid Loss of 0.72935 ; Accuracy of 0.53711\n","Epoch 4 : Train Loss of 0.89811 ; Valid Loss of 0.72939 ; Accuracy of 0.54297\n","Epoch 5 : Train Loss of 0.88571 ; Valid Loss of 0.73384 ; Accuracy of 0.54199\n","Epoch 6 : Train Loss of 0.85951 ; Valid Loss of 0.72735 ; Accuracy of 0.53906\n","Epoch 7 : Train Loss of 0.85153 ; Valid Loss of 0.71842 ; Accuracy of 0.54785\n","Epoch 8 : Train Loss of 0.83859 ; Valid Loss of 0.72516 ; Accuracy of 0.55273\n","Epoch 9 : Train Loss of 0.82801 ; Valid Loss of 0.73146 ; Accuracy of 0.53516\n","Epoch 10 : Train Loss of 0.81968 ; Valid Loss of 0.72446 ; Accuracy of 0.54492\n","Epoch 11 : Train Loss of 0.80543 ; Valid Loss of 0.72280 ; Accuracy of 0.54492\n","Epoch 12 : Train Loss of 0.79897 ; Valid Loss of 0.72935 ; Accuracy of 0.54102\n","Epoch 13 : Train Loss of 0.79872 ; Valid Loss of 0.73118 ; Accuracy of 0.54590\n","Epoch 14 : Train Loss of 0.78833 ; Valid Loss of 0.72211 ; Accuracy of 0.55273\n","Epoch 15 : Train Loss of 0.78053 ; Valid Loss of 0.72880 ; Accuracy of 0.55469\n","Epoch 16 : Train Loss of 0.77037 ; Valid Loss of 0.72686 ; Accuracy of 0.55371\n","Epoch 17 : Train Loss of 0.76766 ; Valid Loss of 0.71574 ; Accuracy of 0.56250\n","Epoch 18 : Train Loss of 0.75899 ; Valid Loss of 0.71510 ; Accuracy of 0.55664\n","Epoch 19 : Train Loss of 0.76261 ; Valid Loss of 0.72867 ; Accuracy of 0.55762\n","Epoch 20 : Train Loss of 0.75536 ; Valid Loss of 0.72234 ; Accuracy of 0.55469\n","Epoch 21 : Train Loss of 0.74954 ; Valid Loss of 0.72830 ; Accuracy of 0.55664\n","Epoch 22 : Train Loss of 0.74898 ; Valid Loss of 0.72585 ; Accuracy of 0.56348\n","Epoch 23 : Train Loss of 0.74680 ; Valid Loss of 0.72673 ; Accuracy of 0.56250\n","Epoch 24 : Train Loss of 0.73956 ; Valid Loss of 0.72478 ; Accuracy of 0.55762\n","Epoch 25 : Train Loss of 0.73617 ; Valid Loss of 0.72263 ; Accuracy of 0.56055\n","Epoch 26 : Train Loss of 0.72843 ; Valid Loss of 0.72124 ; Accuracy of 0.56738\n","Epoch 27 : Train Loss of 0.72620 ; Valid Loss of 0.73168 ; Accuracy of 0.55078\n","Epoch 28 : Train Loss of 0.72610 ; Valid Loss of 0.72848 ; Accuracy of 0.55957\n","Epoch 29 : Train Loss of 0.72270 ; Valid Loss of 0.72206 ; Accuracy of 0.56738\n","Epoch 30 : Train Loss of 0.72284 ; Valid Loss of 0.72529 ; Accuracy of 0.55762\n","Epoch 31 : Train Loss of 0.72045 ; Valid Loss of 0.71947 ; Accuracy of 0.56641\n","Epoch 32 : Train Loss of 0.71856 ; Valid Loss of 0.72895 ; Accuracy of 0.56348\n","Epoch 33 : Train Loss of 0.71017 ; Valid Loss of 0.71630 ; Accuracy of 0.57129\n","Epoch 34 : Train Loss of 0.70731 ; Valid Loss of 0.71301 ; Accuracy of 0.57520\n","Epoch 35 : Train Loss of 0.70645 ; Valid Loss of 0.72503 ; Accuracy of 0.56934\n","Epoch 36 : Train Loss of 0.71033 ; Valid Loss of 0.71830 ; Accuracy of 0.58203\n","Epoch 37 : Train Loss of 0.70087 ; Valid Loss of 0.72066 ; Accuracy of 0.58105\n","Epoch 38 : Train Loss of 0.70420 ; Valid Loss of 0.72130 ; Accuracy of 0.56641\n","Epoch 39 : Train Loss of 0.69754 ; Valid Loss of 0.70526 ; Accuracy of 0.58594\n","Epoch 40 : Train Loss of 0.69651 ; Valid Loss of 0.71254 ; Accuracy of 0.58496\n","Epoch 41 : Train Loss of 0.69657 ; Valid Loss of 0.71977 ; Accuracy of 0.57812\n","Epoch 42 : Train Loss of 0.69350 ; Valid Loss of 0.71035 ; Accuracy of 0.58203\n","Epoch 43 : Train Loss of 0.68981 ; Valid Loss of 0.70274 ; Accuracy of 0.58887\n","Epoch 44 : Train Loss of 0.69288 ; Valid Loss of 0.72234 ; Accuracy of 0.57617\n","Epoch 45 : Train Loss of 0.68599 ; Valid Loss of 0.70872 ; Accuracy of 0.59082\n","Epoch 46 : Train Loss of 0.68401 ; Valid Loss of 0.70769 ; Accuracy of 0.58203\n","Epoch 47 : Train Loss of 0.68393 ; Valid Loss of 0.71766 ; Accuracy of 0.57520\n","Epoch 48 : Train Loss of 0.68197 ; Valid Loss of 0.71583 ; Accuracy of 0.57617\n","Epoch 49 : Train Loss of 0.68146 ; Valid Loss of 0.70713 ; Accuracy of 0.58691\n","Epoch 50 : Train Loss of 0.68084 ; Valid Loss of 0.70881 ; Accuracy of 0.58301\n","Epoch 51 : Train Loss of 0.67960 ; Valid Loss of 0.70769 ; Accuracy of 0.58398\n","Epoch 52 : Train Loss of 0.67213 ; Valid Loss of 0.71839 ; Accuracy of 0.57520\n","Epoch 53 : Train Loss of 0.67482 ; Valid Loss of 0.70817 ; Accuracy of 0.58496\n","Epoch 54 : Train Loss of 0.67274 ; Valid Loss of 0.70842 ; Accuracy of 0.58984\n","Epoch 55 : Train Loss of 0.67451 ; Valid Loss of 0.71138 ; Accuracy of 0.58301\n","Epoch 56 : Train Loss of 0.66968 ; Valid Loss of 0.70684 ; Accuracy of 0.59180\n","Epoch 57 : Train Loss of 0.67015 ; Valid Loss of 0.70758 ; Accuracy of 0.59375\n","Epoch 58 : Train Loss of 0.66805 ; Valid Loss of 0.70978 ; Accuracy of 0.58496\n","Epoch 59 : Train Loss of 0.66589 ; Valid Loss of 0.71594 ; Accuracy of 0.58398\n","Epoch 60 : Train Loss of 0.66527 ; Valid Loss of 0.71259 ; Accuracy of 0.57617\n","Epoch 61 : Train Loss of 0.66445 ; Valid Loss of 0.70995 ; Accuracy of 0.58984\n","Epoch 62 : Train Loss of 0.66190 ; Valid Loss of 0.69723 ; Accuracy of 0.59180\n","Epoch 63 : Train Loss of 0.66059 ; Valid Loss of 0.71134 ; Accuracy of 0.57324\n","Epoch 64 : Train Loss of 0.66027 ; Valid Loss of 0.70686 ; Accuracy of 0.58496\n","Epoch 65 : Train Loss of 0.65742 ; Valid Loss of 0.70801 ; Accuracy of 0.58105\n","Epoch 66 : Train Loss of 0.65565 ; Valid Loss of 0.71343 ; Accuracy of 0.58301\n","Epoch 67 : Train Loss of 0.65927 ; Valid Loss of 0.70292 ; Accuracy of 0.58594\n","Epoch 68 : Train Loss of 0.65633 ; Valid Loss of 0.71141 ; Accuracy of 0.57812\n","Epoch 69 : Train Loss of 0.65551 ; Valid Loss of 0.71449 ; Accuracy of 0.58008\n","Epoch 70 : Train Loss of 0.65290 ; Valid Loss of 0.71564 ; Accuracy of 0.57812\n","Epoch 71 : Train Loss of 0.65262 ; Valid Loss of 0.71548 ; Accuracy of 0.58203\n","Epoch 72 : Train Loss of 0.65138 ; Valid Loss of 0.70437 ; Accuracy of 0.58691\n","Epoch 73 : Train Loss of 0.65042 ; Valid Loss of 0.70867 ; Accuracy of 0.58887\n","Epoch 74 : Train Loss of 0.65071 ; Valid Loss of 0.70848 ; Accuracy of 0.58203\n","Epoch 75 : Train Loss of 0.65126 ; Valid Loss of 0.71350 ; Accuracy of 0.58496\n","Epoch 76 : Train Loss of 0.64641 ; Valid Loss of 0.70704 ; Accuracy of 0.59766\n","Epoch 77 : Train Loss of 0.64720 ; Valid Loss of 0.71077 ; Accuracy of 0.59082\n","Epoch 78 : Train Loss of 0.64988 ; Valid Loss of 0.71450 ; Accuracy of 0.58984\n","Epoch 79 : Train Loss of 0.64436 ; Valid Loss of 0.70871 ; Accuracy of 0.59277\n","Epoch 80 : Train Loss of 0.64572 ; Valid Loss of 0.71102 ; Accuracy of 0.59375\n","Epoch 81 : Train Loss of 0.64488 ; Valid Loss of 0.71925 ; Accuracy of 0.59180\n","Epoch 82 : Train Loss of 0.64145 ; Valid Loss of 0.70182 ; Accuracy of 0.60547\n","Epoch 83 : Train Loss of 0.64244 ; Valid Loss of 0.70676 ; Accuracy of 0.59375\n","Epoch 84 : Train Loss of 0.64072 ; Valid Loss of 0.71227 ; Accuracy of 0.59082\n","Epoch 85 : Train Loss of 0.64016 ; Valid Loss of 0.71637 ; Accuracy of 0.58789\n","Epoch 86 : Train Loss of 0.64088 ; Valid Loss of 0.71156 ; Accuracy of 0.59180\n","Epoch 87 : Train Loss of 0.64008 ; Valid Loss of 0.70417 ; Accuracy of 0.59473\n","Epoch 88 : Train Loss of 0.63942 ; Valid Loss of 0.71901 ; Accuracy of 0.58496\n","Epoch 89 : Train Loss of 0.63646 ; Valid Loss of 0.71621 ; Accuracy of 0.59082\n","Epoch 90 : Train Loss of 0.63744 ; Valid Loss of 0.70527 ; Accuracy of 0.60352\n","Epoch 91 : Train Loss of 0.64024 ; Valid Loss of 0.70595 ; Accuracy of 0.59668\n","Epoch 92 : Train Loss of 0.63290 ; Valid Loss of 0.71612 ; Accuracy of 0.58984\n","Epoch 93 : Train Loss of 0.63384 ; Valid Loss of 0.71056 ; Accuracy of 0.58594\n","Epoch 94 : Train Loss of 0.63569 ; Valid Loss of 0.71003 ; Accuracy of 0.59375\n","Epoch 95 : Train Loss of 0.63326 ; Valid Loss of 0.70498 ; Accuracy of 0.60547\n","Epoch 96 : Train Loss of 0.63441 ; Valid Loss of 0.69792 ; Accuracy of 0.60254\n","Epoch 97 : Train Loss of 0.63051 ; Valid Loss of 0.70322 ; Accuracy of 0.59375\n","Epoch 98 : Train Loss of 0.63190 ; Valid Loss of 0.72146 ; Accuracy of 0.58984\n","Epoch 99 : Train Loss of 0.63259 ; Valid Loss of 0.71265 ; Accuracy of 0.58887\n","Epoch 100 : Train Loss of 0.63156 ; Valid Loss of 0.71495 ; Accuracy of 0.58984\n","Epoch 101 : Train Loss of 0.62927 ; Valid Loss of 0.72019 ; Accuracy of 0.58203\n","Epoch 102 : Train Loss of 0.63019 ; Valid Loss of 0.70867 ; Accuracy of 0.59766\n","Epoch 103 : Train Loss of 0.62629 ; Valid Loss of 0.71395 ; Accuracy of 0.59473\n","Epoch 104 : Train Loss of 0.62957 ; Valid Loss of 0.71464 ; Accuracy of 0.58789\n","Epoch 105 : Train Loss of 0.62791 ; Valid Loss of 0.70663 ; Accuracy of 0.59668\n","Epoch 106 : Train Loss of 0.62722 ; Valid Loss of 0.71820 ; Accuracy of 0.58594\n","Epoch 107 : Train Loss of 0.62537 ; Valid Loss of 0.70206 ; Accuracy of 0.59570\n","Epoch 108 : Train Loss of 0.62757 ; Valid Loss of 0.70794 ; Accuracy of 0.59668\n","Epoch 109 : Train Loss of 0.62722 ; Valid Loss of 0.71089 ; Accuracy of 0.59473\n","Epoch 110 : Train Loss of 0.62518 ; Valid Loss of 0.71274 ; Accuracy of 0.59375\n","Epoch 111 : Train Loss of 0.62366 ; Valid Loss of 0.70874 ; Accuracy of 0.59180\n","Epoch 112 : Train Loss of 0.62333 ; Valid Loss of 0.71404 ; Accuracy of 0.59180\n","Early Stopping, Best Optimal Number of Epoch is 62\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d715240>\n","Training For Optimal Number of Epochs 62 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.02633\n","Epoch 1 : Entire Train Loss of 0.94396\n","Epoch 2 : Entire Train Loss of 0.87109\n","Epoch 3 : Entire Train Loss of 0.81599\n","Epoch 4 : Entire Train Loss of 0.77506\n","Epoch 5 : Entire Train Loss of 0.74373\n","Epoch 6 : Entire Train Loss of 0.71471\n","Epoch 7 : Entire Train Loss of 0.69333\n","Epoch 8 : Entire Train Loss of 0.67199\n","Epoch 9 : Entire Train Loss of 0.65506\n","Epoch 10 : Entire Train Loss of 0.64579\n","Epoch 11 : Entire Train Loss of 0.63745\n","Epoch 12 : Entire Train Loss of 0.62764\n","Epoch 13 : Entire Train Loss of 0.62384\n","Epoch 14 : Entire Train Loss of 0.61913\n","Epoch 15 : Entire Train Loss of 0.61585\n","Epoch 16 : Entire Train Loss of 0.60822\n","Epoch 17 : Entire Train Loss of 0.60578\n","Epoch 18 : Entire Train Loss of 0.60474\n","Epoch 19 : Entire Train Loss of 0.60433\n","Epoch 20 : Entire Train Loss of 0.60042\n","Epoch 21 : Entire Train Loss of 0.59963\n","Epoch 22 : Entire Train Loss of 0.59550\n","Epoch 23 : Entire Train Loss of 0.59371\n","Epoch 24 : Entire Train Loss of 0.59177\n","Epoch 25 : Entire Train Loss of 0.58832\n","Epoch 26 : Entire Train Loss of 0.58672\n","Epoch 27 : Entire Train Loss of 0.58549\n","Epoch 28 : Entire Train Loss of 0.58161\n","Epoch 29 : Entire Train Loss of 0.57783\n","Epoch 30 : Entire Train Loss of 0.57421\n","Epoch 31 : Entire Train Loss of 0.56948\n","Epoch 32 : Entire Train Loss of 0.56681\n","Epoch 33 : Entire Train Loss of 0.56389\n","Epoch 34 : Entire Train Loss of 0.56048\n","Epoch 35 : Entire Train Loss of 0.55624\n","Epoch 36 : Entire Train Loss of 0.55072\n","Epoch 37 : Entire Train Loss of 0.54403\n","Epoch 38 : Entire Train Loss of 0.54060\n","Epoch 39 : Entire Train Loss of 0.53744\n","Epoch 40 : Entire Train Loss of 0.53127\n","Epoch 41 : Entire Train Loss of 0.52804\n","Epoch 42 : Entire Train Loss of 0.52019\n","Epoch 43 : Entire Train Loss of 0.51619\n","Epoch 44 : Entire Train Loss of 0.50830\n","Epoch 45 : Entire Train Loss of 0.50639\n","Epoch 46 : Entire Train Loss of 0.50384\n","Epoch 47 : Entire Train Loss of 0.49510\n","Epoch 48 : Entire Train Loss of 0.49367\n","Epoch 49 : Entire Train Loss of 0.48477\n","Epoch 50 : Entire Train Loss of 0.48055\n","Epoch 51 : Entire Train Loss of 0.47689\n","Epoch 52 : Entire Train Loss of 0.47223\n","Epoch 53 : Entire Train Loss of 0.46691\n","Epoch 54 : Entire Train Loss of 0.46204\n","Epoch 55 : Entire Train Loss of 0.45444\n","Epoch 56 : Entire Train Loss of 0.45223\n","Epoch 57 : Entire Train Loss of 0.44730\n","Epoch 58 : Entire Train Loss of 0.44165\n","Epoch 59 : Entire Train Loss of 0.43678\n","Epoch 60 : Entire Train Loss of 0.43120\n","Epoch 61 : Entire Train Loss of 0.42860\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d715668>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.08070 ; Valid Loss of 0.79039 ; Accuracy of 0.53223\n","Epoch 2 : Train Loss of 1.00632 ; Valid Loss of 0.77840 ; Accuracy of 0.54492\n","Epoch 3 : Train Loss of 0.96776 ; Valid Loss of 0.78119 ; Accuracy of 0.55762\n","Epoch 4 : Train Loss of 0.93882 ; Valid Loss of 0.75869 ; Accuracy of 0.56641\n","Epoch 5 : Train Loss of 0.91522 ; Valid Loss of 0.76554 ; Accuracy of 0.55859\n","Epoch 6 : Train Loss of 0.89620 ; Valid Loss of 0.75083 ; Accuracy of 0.56836\n","Epoch 7 : Train Loss of 0.87924 ; Valid Loss of 0.75064 ; Accuracy of 0.57910\n","Epoch 8 : Train Loss of 0.86023 ; Valid Loss of 0.74715 ; Accuracy of 0.56348\n","Epoch 9 : Train Loss of 0.85683 ; Valid Loss of 0.75132 ; Accuracy of 0.57129\n","Epoch 10 : Train Loss of 0.84390 ; Valid Loss of 0.73964 ; Accuracy of 0.56836\n","Epoch 11 : Train Loss of 0.83418 ; Valid Loss of 0.73298 ; Accuracy of 0.58496\n","Epoch 12 : Train Loss of 0.82130 ; Valid Loss of 0.73103 ; Accuracy of 0.57227\n","Epoch 13 : Train Loss of 0.82051 ; Valid Loss of 0.74376 ; Accuracy of 0.58789\n","Epoch 14 : Train Loss of 0.81535 ; Valid Loss of 0.73520 ; Accuracy of 0.57617\n","Epoch 15 : Train Loss of 0.80523 ; Valid Loss of 0.73716 ; Accuracy of 0.57031\n","Epoch 16 : Train Loss of 0.79851 ; Valid Loss of 0.74865 ; Accuracy of 0.56543\n","Epoch 17 : Train Loss of 0.79177 ; Valid Loss of 0.73548 ; Accuracy of 0.57812\n","Epoch 18 : Train Loss of 0.78951 ; Valid Loss of 0.74289 ; Accuracy of 0.57715\n","Epoch 19 : Train Loss of 0.78858 ; Valid Loss of 0.73611 ; Accuracy of 0.58398\n","Epoch 20 : Train Loss of 0.77388 ; Valid Loss of 0.73395 ; Accuracy of 0.58691\n","Epoch 21 : Train Loss of 0.77360 ; Valid Loss of 0.72788 ; Accuracy of 0.58789\n","Epoch 22 : Train Loss of 0.77141 ; Valid Loss of 0.72523 ; Accuracy of 0.58984\n","Epoch 23 : Train Loss of 0.75994 ; Valid Loss of 0.73571 ; Accuracy of 0.57520\n","Epoch 24 : Train Loss of 0.75543 ; Valid Loss of 0.72732 ; Accuracy of 0.58008\n","Epoch 25 : Train Loss of 0.75041 ; Valid Loss of 0.72960 ; Accuracy of 0.57617\n","Epoch 26 : Train Loss of 0.75452 ; Valid Loss of 0.72428 ; Accuracy of 0.57812\n","Epoch 27 : Train Loss of 0.74485 ; Valid Loss of 0.71787 ; Accuracy of 0.58594\n","Epoch 28 : Train Loss of 0.74595 ; Valid Loss of 0.73191 ; Accuracy of 0.57715\n","Epoch 29 : Train Loss of 0.73700 ; Valid Loss of 0.70817 ; Accuracy of 0.59180\n","Epoch 30 : Train Loss of 0.74040 ; Valid Loss of 0.72261 ; Accuracy of 0.58691\n","Epoch 31 : Train Loss of 0.73150 ; Valid Loss of 0.72241 ; Accuracy of 0.58398\n","Epoch 32 : Train Loss of 0.73493 ; Valid Loss of 0.71865 ; Accuracy of 0.57520\n","Epoch 33 : Train Loss of 0.72687 ; Valid Loss of 0.72804 ; Accuracy of 0.56836\n","Epoch 34 : Train Loss of 0.72481 ; Valid Loss of 0.71868 ; Accuracy of 0.58203\n","Epoch 35 : Train Loss of 0.72774 ; Valid Loss of 0.72497 ; Accuracy of 0.57520\n","Epoch 36 : Train Loss of 0.72157 ; Valid Loss of 0.71770 ; Accuracy of 0.58008\n","Epoch 37 : Train Loss of 0.72041 ; Valid Loss of 0.72059 ; Accuracy of 0.57812\n","Epoch 38 : Train Loss of 0.71530 ; Valid Loss of 0.71619 ; Accuracy of 0.57812\n","Epoch 39 : Train Loss of 0.71797 ; Valid Loss of 0.71531 ; Accuracy of 0.57422\n","Epoch 40 : Train Loss of 0.71174 ; Valid Loss of 0.72556 ; Accuracy of 0.56738\n","Epoch 41 : Train Loss of 0.70970 ; Valid Loss of 0.71399 ; Accuracy of 0.57910\n","Epoch 42 : Train Loss of 0.70713 ; Valid Loss of 0.70644 ; Accuracy of 0.59277\n","Epoch 43 : Train Loss of 0.70142 ; Valid Loss of 0.70455 ; Accuracy of 0.58984\n","Epoch 44 : Train Loss of 0.70339 ; Valid Loss of 0.71636 ; Accuracy of 0.58203\n","Epoch 45 : Train Loss of 0.69992 ; Valid Loss of 0.70471 ; Accuracy of 0.58789\n","Epoch 46 : Train Loss of 0.70230 ; Valid Loss of 0.71394 ; Accuracy of 0.58105\n","Epoch 47 : Train Loss of 0.69657 ; Valid Loss of 0.70684 ; Accuracy of 0.58789\n","Epoch 48 : Train Loss of 0.70010 ; Valid Loss of 0.71416 ; Accuracy of 0.58008\n","Epoch 49 : Train Loss of 0.69302 ; Valid Loss of 0.70139 ; Accuracy of 0.58301\n","Epoch 50 : Train Loss of 0.68932 ; Valid Loss of 0.70311 ; Accuracy of 0.58301\n","Epoch 51 : Train Loss of 0.69185 ; Valid Loss of 0.69838 ; Accuracy of 0.59570\n","Epoch 52 : Train Loss of 0.68878 ; Valid Loss of 0.70013 ; Accuracy of 0.58789\n","Epoch 53 : Train Loss of 0.68509 ; Valid Loss of 0.69992 ; Accuracy of 0.58984\n","Epoch 54 : Train Loss of 0.67892 ; Valid Loss of 0.71370 ; Accuracy of 0.57617\n","Epoch 55 : Train Loss of 0.68105 ; Valid Loss of 0.70727 ; Accuracy of 0.59766\n","Epoch 56 : Train Loss of 0.67963 ; Valid Loss of 0.70983 ; Accuracy of 0.59375\n","Epoch 57 : Train Loss of 0.68147 ; Valid Loss of 0.69559 ; Accuracy of 0.60156\n","Epoch 58 : Train Loss of 0.68015 ; Valid Loss of 0.71499 ; Accuracy of 0.58203\n","Epoch 59 : Train Loss of 0.67592 ; Valid Loss of 0.70135 ; Accuracy of 0.59961\n","Epoch 60 : Train Loss of 0.67702 ; Valid Loss of 0.70893 ; Accuracy of 0.59277\n","Epoch 61 : Train Loss of 0.67529 ; Valid Loss of 0.70163 ; Accuracy of 0.59277\n","Epoch 62 : Train Loss of 0.67423 ; Valid Loss of 0.69932 ; Accuracy of 0.60547\n","Epoch 63 : Train Loss of 0.67535 ; Valid Loss of 0.70234 ; Accuracy of 0.59082\n","Epoch 64 : Train Loss of 0.67156 ; Valid Loss of 0.69935 ; Accuracy of 0.59473\n","Epoch 65 : Train Loss of 0.67452 ; Valid Loss of 0.70005 ; Accuracy of 0.59375\n","Epoch 66 : Train Loss of 0.67307 ; Valid Loss of 0.70093 ; Accuracy of 0.58984\n","Epoch 67 : Train Loss of 0.66529 ; Valid Loss of 0.69709 ; Accuracy of 0.60547\n","Epoch 68 : Train Loss of 0.67424 ; Valid Loss of 0.70073 ; Accuracy of 0.59375\n","Epoch 69 : Train Loss of 0.66698 ; Valid Loss of 0.70596 ; Accuracy of 0.58887\n","Epoch 70 : Train Loss of 0.66470 ; Valid Loss of 0.69776 ; Accuracy of 0.59277\n","Epoch 71 : Train Loss of 0.66656 ; Valid Loss of 0.69716 ; Accuracy of 0.59180\n","Epoch 72 : Train Loss of 0.66395 ; Valid Loss of 0.70180 ; Accuracy of 0.58887\n","Epoch 73 : Train Loss of 0.66142 ; Valid Loss of 0.69831 ; Accuracy of 0.60254\n","Epoch 74 : Train Loss of 0.66266 ; Valid Loss of 0.69364 ; Accuracy of 0.60254\n","Epoch 75 : Train Loss of 0.66072 ; Valid Loss of 0.70295 ; Accuracy of 0.58691\n","Epoch 76 : Train Loss of 0.65927 ; Valid Loss of 0.69883 ; Accuracy of 0.58887\n","Epoch 77 : Train Loss of 0.65426 ; Valid Loss of 0.70679 ; Accuracy of 0.57910\n","Epoch 78 : Train Loss of 0.65640 ; Valid Loss of 0.70406 ; Accuracy of 0.58789\n","Epoch 79 : Train Loss of 0.66114 ; Valid Loss of 0.69571 ; Accuracy of 0.59961\n","Epoch 80 : Train Loss of 0.65794 ; Valid Loss of 0.70024 ; Accuracy of 0.59082\n","Epoch 81 : Train Loss of 0.65685 ; Valid Loss of 0.70028 ; Accuracy of 0.58496\n","Epoch 82 : Train Loss of 0.64950 ; Valid Loss of 0.70646 ; Accuracy of 0.58594\n","Epoch 83 : Train Loss of 0.65323 ; Valid Loss of 0.69944 ; Accuracy of 0.59277\n","Epoch 84 : Train Loss of 0.64844 ; Valid Loss of 0.70018 ; Accuracy of 0.59473\n","Epoch 85 : Train Loss of 0.65115 ; Valid Loss of 0.70205 ; Accuracy of 0.59668\n","Epoch 86 : Train Loss of 0.64997 ; Valid Loss of 0.70873 ; Accuracy of 0.58496\n","Epoch 87 : Train Loss of 0.65102 ; Valid Loss of 0.69567 ; Accuracy of 0.59277\n","Epoch 88 : Train Loss of 0.65192 ; Valid Loss of 0.69737 ; Accuracy of 0.59180\n","Epoch 89 : Train Loss of 0.65150 ; Valid Loss of 0.70812 ; Accuracy of 0.58789\n","Epoch 90 : Train Loss of 0.64807 ; Valid Loss of 0.69013 ; Accuracy of 0.59570\n","Epoch 91 : Train Loss of 0.64803 ; Valid Loss of 0.69690 ; Accuracy of 0.59082\n","Epoch 92 : Train Loss of 0.64559 ; Valid Loss of 0.69585 ; Accuracy of 0.59766\n","Epoch 93 : Train Loss of 0.64617 ; Valid Loss of 0.69294 ; Accuracy of 0.59863\n","Epoch 94 : Train Loss of 0.64605 ; Valid Loss of 0.69675 ; Accuracy of 0.60352\n","Epoch 95 : Train Loss of 0.64454 ; Valid Loss of 0.70111 ; Accuracy of 0.60449\n","Epoch 96 : Train Loss of 0.63778 ; Valid Loss of 0.70506 ; Accuracy of 0.58984\n","Epoch 97 : Train Loss of 0.64347 ; Valid Loss of 0.70836 ; Accuracy of 0.59277\n","Epoch 98 : Train Loss of 0.64045 ; Valid Loss of 0.69771 ; Accuracy of 0.59668\n","Epoch 99 : Train Loss of 0.63905 ; Valid Loss of 0.69462 ; Accuracy of 0.58887\n","Epoch 100 : Train Loss of 0.64148 ; Valid Loss of 0.68772 ; Accuracy of 0.60156\n","Epoch 101 : Train Loss of 0.64122 ; Valid Loss of 0.68929 ; Accuracy of 0.60254\n","Epoch 102 : Train Loss of 0.64041 ; Valid Loss of 0.69370 ; Accuracy of 0.59668\n","Epoch 103 : Train Loss of 0.63967 ; Valid Loss of 0.69882 ; Accuracy of 0.60156\n","Epoch 104 : Train Loss of 0.63872 ; Valid Loss of 0.69489 ; Accuracy of 0.60449\n","Epoch 105 : Train Loss of 0.63648 ; Valid Loss of 0.70064 ; Accuracy of 0.59766\n","Epoch 106 : Train Loss of 0.63885 ; Valid Loss of 0.69388 ; Accuracy of 0.60254\n","Epoch 107 : Train Loss of 0.63701 ; Valid Loss of 0.70988 ; Accuracy of 0.59570\n","Epoch 108 : Train Loss of 0.63457 ; Valid Loss of 0.70029 ; Accuracy of 0.59180\n","Epoch 109 : Train Loss of 0.63692 ; Valid Loss of 0.69076 ; Accuracy of 0.60938\n","Epoch 110 : Train Loss of 0.63615 ; Valid Loss of 0.70402 ; Accuracy of 0.59668\n","Epoch 111 : Train Loss of 0.63453 ; Valid Loss of 0.70746 ; Accuracy of 0.59863\n","Epoch 112 : Train Loss of 0.63323 ; Valid Loss of 0.70115 ; Accuracy of 0.59863\n","Epoch 113 : Train Loss of 0.63514 ; Valid Loss of 0.69055 ; Accuracy of 0.60742\n","Epoch 114 : Train Loss of 0.63645 ; Valid Loss of 0.71236 ; Accuracy of 0.59668\n","Epoch 115 : Train Loss of 0.63436 ; Valid Loss of 0.71019 ; Accuracy of 0.59082\n","Epoch 116 : Train Loss of 0.62713 ; Valid Loss of 0.69900 ; Accuracy of 0.60059\n","Epoch 117 : Train Loss of 0.63118 ; Valid Loss of 0.70221 ; Accuracy of 0.58789\n","Epoch 118 : Train Loss of 0.63255 ; Valid Loss of 0.70435 ; Accuracy of 0.59277\n","Epoch 119 : Train Loss of 0.63105 ; Valid Loss of 0.69888 ; Accuracy of 0.59863\n","Epoch 120 : Train Loss of 0.63156 ; Valid Loss of 0.68804 ; Accuracy of 0.60938\n","Epoch 121 : Train Loss of 0.62875 ; Valid Loss of 0.71104 ; Accuracy of 0.59961\n","Epoch 122 : Train Loss of 0.62887 ; Valid Loss of 0.70636 ; Accuracy of 0.59570\n","Epoch 123 : Train Loss of 0.63059 ; Valid Loss of 0.69684 ; Accuracy of 0.59863\n","Epoch 124 : Train Loss of 0.62550 ; Valid Loss of 0.69738 ; Accuracy of 0.60059\n","Epoch 125 : Train Loss of 0.62659 ; Valid Loss of 0.70057 ; Accuracy of 0.60742\n","Epoch 126 : Train Loss of 0.62622 ; Valid Loss of 0.70184 ; Accuracy of 0.59277\n","Epoch 127 : Train Loss of 0.62534 ; Valid Loss of 0.70027 ; Accuracy of 0.60742\n","Epoch 128 : Train Loss of 0.62486 ; Valid Loss of 0.70137 ; Accuracy of 0.59863\n","Epoch 129 : Train Loss of 0.62581 ; Valid Loss of 0.70213 ; Accuracy of 0.60352\n","Epoch 130 : Train Loss of 0.62356 ; Valid Loss of 0.69451 ; Accuracy of 0.60742\n","Epoch 131 : Train Loss of 0.62358 ; Valid Loss of 0.70682 ; Accuracy of 0.59961\n","Epoch 132 : Train Loss of 0.62493 ; Valid Loss of 0.70683 ; Accuracy of 0.59570\n","Epoch 133 : Train Loss of 0.62042 ; Valid Loss of 0.70180 ; Accuracy of 0.59863\n","Epoch 134 : Train Loss of 0.62153 ; Valid Loss of 0.70008 ; Accuracy of 0.59766\n","Epoch 135 : Train Loss of 0.62268 ; Valid Loss of 0.70211 ; Accuracy of 0.60352\n","Epoch 136 : Train Loss of 0.62010 ; Valid Loss of 0.70586 ; Accuracy of 0.60156\n","Epoch 137 : Train Loss of 0.62274 ; Valid Loss of 0.70078 ; Accuracy of 0.59180\n","Epoch 138 : Train Loss of 0.61875 ; Valid Loss of 0.69359 ; Accuracy of 0.60547\n","Epoch 139 : Train Loss of 0.62104 ; Valid Loss of 0.70617 ; Accuracy of 0.59180\n","Epoch 140 : Train Loss of 0.61765 ; Valid Loss of 0.69142 ; Accuracy of 0.60156\n","Epoch 141 : Train Loss of 0.61676 ; Valid Loss of 0.70774 ; Accuracy of 0.59375\n","Epoch 142 : Train Loss of 0.61761 ; Valid Loss of 0.69687 ; Accuracy of 0.60059\n","Epoch 143 : Train Loss of 0.61537 ; Valid Loss of 0.70991 ; Accuracy of 0.59473\n","Epoch 144 : Train Loss of 0.61641 ; Valid Loss of 0.70930 ; Accuracy of 0.59375\n","Epoch 145 : Train Loss of 0.61676 ; Valid Loss of 0.70900 ; Accuracy of 0.60254\n","Epoch 146 : Train Loss of 0.62086 ; Valid Loss of 0.71650 ; Accuracy of 0.59082\n","Epoch 147 : Train Loss of 0.61787 ; Valid Loss of 0.70127 ; Accuracy of 0.59863\n","Epoch 148 : Train Loss of 0.61141 ; Valid Loss of 0.69798 ; Accuracy of 0.60156\n","Epoch 149 : Train Loss of 0.61704 ; Valid Loss of 0.69972 ; Accuracy of 0.60156\n","Epoch 150 : Train Loss of 0.61491 ; Valid Loss of 0.69746 ; Accuracy of 0.60547\n","Early Stopping, Best Optimal Number of Epoch is 100\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d715b70>\n","Training For Optimal Number of Epochs 100 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.99350\n","Epoch 1 : Entire Train Loss of 0.90100\n","Epoch 2 : Entire Train Loss of 0.83710\n","Epoch 3 : Entire Train Loss of 0.78234\n","Epoch 4 : Entire Train Loss of 0.75082\n","Epoch 5 : Entire Train Loss of 0.72100\n","Epoch 6 : Entire Train Loss of 0.69761\n","Epoch 7 : Entire Train Loss of 0.67991\n","Epoch 8 : Entire Train Loss of 0.66447\n","Epoch 9 : Entire Train Loss of 0.65288\n","Epoch 10 : Entire Train Loss of 0.64065\n","Epoch 11 : Entire Train Loss of 0.63313\n","Epoch 12 : Entire Train Loss of 0.62800\n","Epoch 13 : Entire Train Loss of 0.62303\n","Epoch 14 : Entire Train Loss of 0.61862\n","Epoch 15 : Entire Train Loss of 0.61325\n","Epoch 16 : Entire Train Loss of 0.60863\n","Epoch 17 : Entire Train Loss of 0.60519\n","Epoch 18 : Entire Train Loss of 0.60304\n","Epoch 19 : Entire Train Loss of 0.60103\n","Epoch 20 : Entire Train Loss of 0.59990\n","Epoch 21 : Entire Train Loss of 0.59884\n","Epoch 22 : Entire Train Loss of 0.59564\n","Epoch 23 : Entire Train Loss of 0.59291\n","Epoch 24 : Entire Train Loss of 0.59101\n","Epoch 25 : Entire Train Loss of 0.58613\n","Epoch 26 : Entire Train Loss of 0.58565\n","Epoch 27 : Entire Train Loss of 0.58366\n","Epoch 28 : Entire Train Loss of 0.58089\n","Epoch 29 : Entire Train Loss of 0.57548\n","Epoch 30 : Entire Train Loss of 0.57180\n","Epoch 31 : Entire Train Loss of 0.57073\n","Epoch 32 : Entire Train Loss of 0.56627\n","Epoch 33 : Entire Train Loss of 0.56036\n","Epoch 34 : Entire Train Loss of 0.55745\n","Epoch 35 : Entire Train Loss of 0.55236\n","Epoch 36 : Entire Train Loss of 0.55171\n","Epoch 37 : Entire Train Loss of 0.54310\n","Epoch 38 : Entire Train Loss of 0.53830\n","Epoch 39 : Entire Train Loss of 0.53652\n","Epoch 40 : Entire Train Loss of 0.53228\n","Epoch 41 : Entire Train Loss of 0.52397\n","Epoch 42 : Entire Train Loss of 0.52119\n","Epoch 43 : Entire Train Loss of 0.51407\n","Epoch 44 : Entire Train Loss of 0.51147\n","Epoch 45 : Entire Train Loss of 0.50933\n","Epoch 46 : Entire Train Loss of 0.49924\n","Epoch 47 : Entire Train Loss of 0.49465\n","Epoch 48 : Entire Train Loss of 0.48956\n","Epoch 49 : Entire Train Loss of 0.48857\n","Epoch 50 : Entire Train Loss of 0.48273\n","Epoch 51 : Entire Train Loss of 0.47388\n","Epoch 52 : Entire Train Loss of 0.47222\n","Epoch 53 : Entire Train Loss of 0.46704\n","Epoch 54 : Entire Train Loss of 0.45881\n","Epoch 55 : Entire Train Loss of 0.45789\n","Epoch 56 : Entire Train Loss of 0.45351\n","Epoch 57 : Entire Train Loss of 0.44775\n","Epoch 58 : Entire Train Loss of 0.44113\n","Epoch 59 : Entire Train Loss of 0.43645\n","Epoch 60 : Entire Train Loss of 0.43408\n","Epoch 61 : Entire Train Loss of 0.42829\n","Epoch 62 : Entire Train Loss of 0.42691\n","Epoch 63 : Entire Train Loss of 0.42448\n","Epoch 64 : Entire Train Loss of 0.41544\n","Epoch 65 : Entire Train Loss of 0.41187\n","Epoch 66 : Entire Train Loss of 0.40785\n","Epoch 67 : Entire Train Loss of 0.40524\n","Epoch 68 : Entire Train Loss of 0.39824\n","Epoch 69 : Entire Train Loss of 0.39533\n","Epoch 70 : Entire Train Loss of 0.39005\n","Epoch 71 : Entire Train Loss of 0.38653\n","Epoch 72 : Entire Train Loss of 0.38442\n","Epoch 73 : Entire Train Loss of 0.37690\n","Epoch 74 : Entire Train Loss of 0.37445\n","Epoch 75 : Entire Train Loss of 0.37198\n","Epoch 76 : Entire Train Loss of 0.37217\n","Epoch 77 : Entire Train Loss of 0.36442\n","Epoch 78 : Entire Train Loss of 0.36064\n","Epoch 79 : Entire Train Loss of 0.35657\n","Epoch 80 : Entire Train Loss of 0.35415\n","Epoch 81 : Entire Train Loss of 0.35298\n","Epoch 82 : Entire Train Loss of 0.34638\n","Epoch 83 : Entire Train Loss of 0.34691\n","Epoch 84 : Entire Train Loss of 0.34017\n","Epoch 85 : Entire Train Loss of 0.33723\n","Epoch 86 : Entire Train Loss of 0.33628\n","Epoch 87 : Entire Train Loss of 0.33617\n","Epoch 88 : Entire Train Loss of 0.32630\n","Epoch 89 : Entire Train Loss of 0.33053\n","Epoch 90 : Entire Train Loss of 0.32073\n","Epoch 91 : Entire Train Loss of 0.32222\n","Epoch 92 : Entire Train Loss of 0.31739\n","Epoch 93 : Entire Train Loss of 0.31888\n","Epoch 94 : Entire Train Loss of 0.31319\n","Epoch 95 : Entire Train Loss of 0.31110\n","Epoch 96 : Entire Train Loss of 0.30516\n","Epoch 97 : Entire Train Loss of 0.30691\n","Epoch 98 : Entire Train Loss of 0.30268\n","Epoch 99 : Entire Train Loss of 0.29787\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NgMON2CNp55T","executionInfo":{"status":"error","timestamp":1602922981039,"user_tz":420,"elapsed":598,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"02080aaa-edb6-42ed-f47d-ff91ad2ab242","colab":{"base_uri":"https://localhost:8080/","height":164}},"source":[""],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-2337d7da5ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","metadata":{"id":"HOFqTiOJceev","executionInfo":{"status":"ok","timestamp":1602047065372,"user_tz":420,"elapsed":380,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"8d801f41-aa5f-4446-93f1-67ab2b006b67","colab":{"base_uri":"https://localhost:8080/"}},"source":["pr.mean(axis = 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.556083\n","dtype: float32"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"lcEb2JrCVF4Q","outputId":"da8e0a39-4b8a-4ae1-b253-e64b104e0885","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = 'moneyline'\n","date = '2020-10-06'\n","predictions_moneyline = {}\n","save_processed_data = 0\n","load_processed_data = 1\n","threshold = 216\n","date = '2020-10-06'\n","log_dir_folder = 'moneyline_10-06-20_512_256_lr_5e-3'\n","%run 'player_model.py' -lin_layer_size 512 256 -lin_layer_dropout 0.5 0.5 -early_stopping 50 -swa 0 -lr 5e-4 '-date={date}' '-model={model}' '-threshold={threshold}' '-save_processed_data={save_processed_data}' '-load_processed_data={load_processed_data}' '-log_dir_folder={log_dir_folder}'\n","ppp = {k : v.ravel() for k,v in predictions.items()}\n","pr = pd.DataFrame(ppp)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='moneyline_10-06-20_512_256_lr_5e-3', lr=0.0005, model='moneyline', production=1, save_processed_data=0, swa=0, threshold=216)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.82306 ; Valid Loss of 0.70471 ; Accuracy of 0.59375\n","Epoch 2 : Train Loss of 0.70726 ; Valid Loss of 0.69311 ; Accuracy of 0.58887\n","Epoch 3 : Train Loss of 0.67458 ; Valid Loss of 0.68948 ; Accuracy of 0.59570\n","Epoch 4 : Train Loss of 0.65273 ; Valid Loss of 0.68247 ; Accuracy of 0.60254\n","Epoch 5 : Train Loss of 0.63786 ; Valid Loss of 0.68714 ; Accuracy of 0.60156\n","Epoch 6 : Train Loss of 0.63011 ; Valid Loss of 0.68966 ; Accuracy of 0.60059\n","Epoch 7 : Train Loss of 0.62322 ; Valid Loss of 0.70021 ; Accuracy of 0.61133\n","Epoch 8 : Train Loss of 0.61863 ; Valid Loss of 0.69539 ; Accuracy of 0.60938\n","Epoch 9 : Train Loss of 0.61226 ; Valid Loss of 0.70168 ; Accuracy of 0.60352\n","Epoch 10 : Train Loss of 0.61000 ; Valid Loss of 0.70254 ; Accuracy of 0.59766\n","Epoch 11 : Train Loss of 0.60569 ; Valid Loss of 0.70544 ; Accuracy of 0.60449\n","Epoch 12 : Train Loss of 0.60191 ; Valid Loss of 0.71312 ; Accuracy of 0.58398\n","Epoch 13 : Train Loss of 0.60019 ; Valid Loss of 0.70018 ; Accuracy of 0.59082\n","Epoch 14 : Train Loss of 0.59609 ; Valid Loss of 0.71211 ; Accuracy of 0.59570\n","Epoch 15 : Train Loss of 0.59399 ; Valid Loss of 0.70308 ; Accuracy of 0.59473\n","Epoch 16 : Train Loss of 0.58978 ; Valid Loss of 0.72378 ; Accuracy of 0.58594\n","Epoch 17 : Train Loss of 0.58600 ; Valid Loss of 0.72256 ; Accuracy of 0.59961\n","Epoch 18 : Train Loss of 0.58222 ; Valid Loss of 0.73240 ; Accuracy of 0.59766\n","Epoch 19 : Train Loss of 0.57709 ; Valid Loss of 0.73871 ; Accuracy of 0.58887\n","Epoch 20 : Train Loss of 0.57191 ; Valid Loss of 0.73663 ; Accuracy of 0.58887\n","Epoch 21 : Train Loss of 0.56871 ; Valid Loss of 0.73221 ; Accuracy of 0.60938\n","Epoch 22 : Train Loss of 0.56357 ; Valid Loss of 0.73187 ; Accuracy of 0.60840\n","Epoch 23 : Train Loss of 0.55658 ; Valid Loss of 0.74832 ; Accuracy of 0.59082\n","Epoch 24 : Train Loss of 0.55241 ; Valid Loss of 0.75024 ; Accuracy of 0.58887\n","Epoch 25 : Train Loss of 0.54562 ; Valid Loss of 0.78799 ; Accuracy of 0.57520\n","Epoch 26 : Train Loss of 0.53864 ; Valid Loss of 0.79724 ; Accuracy of 0.58594\n","Epoch 27 : Train Loss of 0.53296 ; Valid Loss of 0.80369 ; Accuracy of 0.58887\n","Epoch 28 : Train Loss of 0.52820 ; Valid Loss of 0.81375 ; Accuracy of 0.58984\n","Epoch 29 : Train Loss of 0.51308 ; Valid Loss of 0.83436 ; Accuracy of 0.56641\n","Epoch 30 : Train Loss of 0.51037 ; Valid Loss of 0.80528 ; Accuracy of 0.59375\n","Epoch 31 : Train Loss of 0.50538 ; Valid Loss of 0.82818 ; Accuracy of 0.56543\n","Epoch 32 : Train Loss of 0.49668 ; Valid Loss of 0.83951 ; Accuracy of 0.56738\n","Epoch 33 : Train Loss of 0.48648 ; Valid Loss of 0.86992 ; Accuracy of 0.56836\n","Epoch 34 : Train Loss of 0.48293 ; Valid Loss of 0.84796 ; Accuracy of 0.59668\n","Epoch 35 : Train Loss of 0.47420 ; Valid Loss of 0.84989 ; Accuracy of 0.58105\n","Epoch 36 : Train Loss of 0.46531 ; Valid Loss of 0.85927 ; Accuracy of 0.56836\n","Epoch 37 : Train Loss of 0.45813 ; Valid Loss of 0.88475 ; Accuracy of 0.57715\n","Epoch 38 : Train Loss of 0.44997 ; Valid Loss of 0.87362 ; Accuracy of 0.59082\n","Epoch 39 : Train Loss of 0.44518 ; Valid Loss of 0.91623 ; Accuracy of 0.59082\n","Epoch 40 : Train Loss of 0.44196 ; Valid Loss of 0.92071 ; Accuracy of 0.56738\n","Epoch 41 : Train Loss of 0.43381 ; Valid Loss of 0.92084 ; Accuracy of 0.57812\n","Epoch 42 : Train Loss of 0.42345 ; Valid Loss of 0.93763 ; Accuracy of 0.59277\n","Epoch 43 : Train Loss of 0.42061 ; Valid Loss of 0.94583 ; Accuracy of 0.57812\n","Epoch 44 : Train Loss of 0.41732 ; Valid Loss of 0.96037 ; Accuracy of 0.57715\n","Epoch 45 : Train Loss of 0.40787 ; Valid Loss of 0.96867 ; Accuracy of 0.58105\n","Epoch 46 : Train Loss of 0.40153 ; Valid Loss of 1.00044 ; Accuracy of 0.57910\n","Epoch 47 : Train Loss of 0.39817 ; Valid Loss of 0.99461 ; Accuracy of 0.58105\n","Epoch 48 : Train Loss of 0.39128 ; Valid Loss of 0.98025 ; Accuracy of 0.58887\n","Epoch 49 : Train Loss of 0.38490 ; Valid Loss of 1.04317 ; Accuracy of 0.57129\n","Epoch 50 : Train Loss of 0.38115 ; Valid Loss of 1.06092 ; Accuracy of 0.56836\n","Epoch 51 : Train Loss of 0.37219 ; Valid Loss of 1.02919 ; Accuracy of 0.56934\n","Epoch 52 : Train Loss of 0.36632 ; Valid Loss of 1.11578 ; Accuracy of 0.56738\n","Epoch 53 : Train Loss of 0.36236 ; Valid Loss of 1.07584 ; Accuracy of 0.57324\n","Epoch 54 : Train Loss of 0.35965 ; Valid Loss of 1.11709 ; Accuracy of 0.57227\n","Early Stopping, Best Optimal Number of Epoch is 4\n","Training For Optimal Number of Epochs 4 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.81915\n","Epoch 1 : Entire Train Loss of 0.70709\n","Epoch 2 : Entire Train Loss of 0.67284\n","Epoch 3 : Entire Train Loss of 0.65361\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.80565 ; Valid Loss of 0.71192 ; Accuracy of 0.57422\n","Epoch 2 : Train Loss of 0.69932 ; Valid Loss of 0.70018 ; Accuracy of 0.57227\n","Epoch 3 : Train Loss of 0.66442 ; Valid Loss of 0.69383 ; Accuracy of 0.58203\n","Epoch 4 : Train Loss of 0.64670 ; Valid Loss of 0.68752 ; Accuracy of 0.58887\n","Epoch 5 : Train Loss of 0.63794 ; Valid Loss of 0.69157 ; Accuracy of 0.58984\n","Epoch 6 : Train Loss of 0.62834 ; Valid Loss of 0.68169 ; Accuracy of 0.59082\n","Epoch 7 : Train Loss of 0.61866 ; Valid Loss of 0.68802 ; Accuracy of 0.60449\n","Epoch 8 : Train Loss of 0.61427 ; Valid Loss of 0.68701 ; Accuracy of 0.59668\n","Epoch 9 : Train Loss of 0.61150 ; Valid Loss of 0.69626 ; Accuracy of 0.60938\n","Epoch 10 : Train Loss of 0.60757 ; Valid Loss of 0.69604 ; Accuracy of 0.59766\n","Epoch 11 : Train Loss of 0.60448 ; Valid Loss of 0.69392 ; Accuracy of 0.59863\n","Epoch 12 : Train Loss of 0.60270 ; Valid Loss of 0.68667 ; Accuracy of 0.61816\n","Epoch 13 : Train Loss of 0.59896 ; Valid Loss of 0.72123 ; Accuracy of 0.58984\n","Epoch 14 : Train Loss of 0.59541 ; Valid Loss of 0.70672 ; Accuracy of 0.60840\n","Epoch 15 : Train Loss of 0.59156 ; Valid Loss of 0.70635 ; Accuracy of 0.60352\n","Epoch 16 : Train Loss of 0.59029 ; Valid Loss of 0.71182 ; Accuracy of 0.60938\n","Epoch 17 : Train Loss of 0.58514 ; Valid Loss of 0.72858 ; Accuracy of 0.60156\n","Epoch 18 : Train Loss of 0.58097 ; Valid Loss of 0.72350 ; Accuracy of 0.60645\n","Epoch 19 : Train Loss of 0.57865 ; Valid Loss of 0.72702 ; Accuracy of 0.59766\n","Epoch 20 : Train Loss of 0.57257 ; Valid Loss of 0.75828 ; Accuracy of 0.60352\n","Epoch 21 : Train Loss of 0.56595 ; Valid Loss of 0.76543 ; Accuracy of 0.58984\n","Epoch 22 : Train Loss of 0.56504 ; Valid Loss of 0.75629 ; Accuracy of 0.59863\n","Epoch 23 : Train Loss of 0.55726 ; Valid Loss of 0.76763 ; Accuracy of 0.60352\n","Epoch 24 : Train Loss of 0.55086 ; Valid Loss of 0.76224 ; Accuracy of 0.59863\n","Epoch 25 : Train Loss of 0.54627 ; Valid Loss of 0.78710 ; Accuracy of 0.58887\n","Epoch 26 : Train Loss of 0.53987 ; Valid Loss of 0.79287 ; Accuracy of 0.59570\n","Epoch 27 : Train Loss of 0.53281 ; Valid Loss of 0.78909 ; Accuracy of 0.59668\n","Epoch 28 : Train Loss of 0.52582 ; Valid Loss of 0.78556 ; Accuracy of 0.59766\n","Epoch 29 : Train Loss of 0.52052 ; Valid Loss of 0.80188 ; Accuracy of 0.58496\n","Epoch 30 : Train Loss of 0.51104 ; Valid Loss of 0.80899 ; Accuracy of 0.60352\n","Epoch 31 : Train Loss of 0.50384 ; Valid Loss of 0.78228 ; Accuracy of 0.60352\n","Epoch 32 : Train Loss of 0.49783 ; Valid Loss of 0.84017 ; Accuracy of 0.58984\n","Epoch 33 : Train Loss of 0.49015 ; Valid Loss of 0.84325 ; Accuracy of 0.58301\n","Epoch 34 : Train Loss of 0.48308 ; Valid Loss of 0.85868 ; Accuracy of 0.58496\n","Epoch 35 : Train Loss of 0.47609 ; Valid Loss of 0.84803 ; Accuracy of 0.58301\n","Epoch 36 : Train Loss of 0.46900 ; Valid Loss of 0.86234 ; Accuracy of 0.58203\n","Epoch 37 : Train Loss of 0.45999 ; Valid Loss of 0.87321 ; Accuracy of 0.58984\n","Epoch 38 : Train Loss of 0.45663 ; Valid Loss of 0.88577 ; Accuracy of 0.57715\n","Epoch 39 : Train Loss of 0.44356 ; Valid Loss of 0.85017 ; Accuracy of 0.60449\n","Epoch 40 : Train Loss of 0.44306 ; Valid Loss of 0.89359 ; Accuracy of 0.59961\n","Epoch 41 : Train Loss of 0.43113 ; Valid Loss of 0.94246 ; Accuracy of 0.58594\n","Epoch 42 : Train Loss of 0.42616 ; Valid Loss of 0.93213 ; Accuracy of 0.59961\n","Epoch 43 : Train Loss of 0.42207 ; Valid Loss of 0.93963 ; Accuracy of 0.58691\n","Epoch 44 : Train Loss of 0.41304 ; Valid Loss of 0.96593 ; Accuracy of 0.57324\n","Epoch 45 : Train Loss of 0.40798 ; Valid Loss of 0.94540 ; Accuracy of 0.59375\n","Epoch 46 : Train Loss of 0.40353 ; Valid Loss of 0.95585 ; Accuracy of 0.58301\n","Epoch 47 : Train Loss of 0.39758 ; Valid Loss of 0.93792 ; Accuracy of 0.59473\n","Epoch 48 : Train Loss of 0.39112 ; Valid Loss of 0.94826 ; Accuracy of 0.60547\n","Epoch 49 : Train Loss of 0.38373 ; Valid Loss of 0.96804 ; Accuracy of 0.58594\n","Epoch 50 : Train Loss of 0.37722 ; Valid Loss of 1.01005 ; Accuracy of 0.57617\n","Epoch 51 : Train Loss of 0.37338 ; Valid Loss of 1.03391 ; Accuracy of 0.58594\n","Epoch 52 : Train Loss of 0.37184 ; Valid Loss of 1.03372 ; Accuracy of 0.58887\n","Epoch 53 : Train Loss of 0.36729 ; Valid Loss of 1.02499 ; Accuracy of 0.57812\n","Epoch 54 : Train Loss of 0.36109 ; Valid Loss of 1.02570 ; Accuracy of 0.58984\n","Epoch 55 : Train Loss of 0.35366 ; Valid Loss of 1.02400 ; Accuracy of 0.58594\n","Epoch 56 : Train Loss of 0.35269 ; Valid Loss of 1.04029 ; Accuracy of 0.58203\n","Early Stopping, Best Optimal Number of Epoch is 6\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.80121\n","Epoch 1 : Entire Train Loss of 0.69709\n","Epoch 2 : Entire Train Loss of 0.66080\n","Epoch 3 : Entire Train Loss of 0.64640\n","Epoch 4 : Entire Train Loss of 0.63447\n","Epoch 5 : Entire Train Loss of 0.62611\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.78691 ; Valid Loss of 0.70987 ; Accuracy of 0.56934\n","Epoch 2 : Train Loss of 0.69530 ; Valid Loss of 0.69201 ; Accuracy of 0.58789\n","Epoch 3 : Train Loss of 0.66044 ; Valid Loss of 0.70089 ; Accuracy of 0.58105\n","Epoch 4 : Train Loss of 0.64216 ; Valid Loss of 0.68840 ; Accuracy of 0.58691\n","Epoch 5 : Train Loss of 0.63350 ; Valid Loss of 0.68895 ; Accuracy of 0.58789\n","Epoch 6 : Train Loss of 0.62620 ; Valid Loss of 0.68558 ; Accuracy of 0.58984\n","Epoch 7 : Train Loss of 0.61800 ; Valid Loss of 0.69392 ; Accuracy of 0.59277\n","Epoch 8 : Train Loss of 0.61396 ; Valid Loss of 0.69288 ; Accuracy of 0.59180\n","Epoch 9 : Train Loss of 0.61015 ; Valid Loss of 0.69145 ; Accuracy of 0.59180\n","Epoch 10 : Train Loss of 0.60593 ; Valid Loss of 0.70534 ; Accuracy of 0.58594\n","Epoch 11 : Train Loss of 0.60409 ; Valid Loss of 0.69748 ; Accuracy of 0.59473\n","Epoch 12 : Train Loss of 0.60116 ; Valid Loss of 0.70532 ; Accuracy of 0.59375\n","Epoch 13 : Train Loss of 0.59812 ; Valid Loss of 0.70471 ; Accuracy of 0.58789\n","Epoch 14 : Train Loss of 0.59596 ; Valid Loss of 0.69950 ; Accuracy of 0.61328\n","Epoch 15 : Train Loss of 0.59180 ; Valid Loss of 0.70330 ; Accuracy of 0.60840\n","Epoch 16 : Train Loss of 0.58573 ; Valid Loss of 0.71591 ; Accuracy of 0.59766\n","Epoch 17 : Train Loss of 0.58277 ; Valid Loss of 0.71386 ; Accuracy of 0.60645\n","Epoch 18 : Train Loss of 0.57997 ; Valid Loss of 0.72153 ; Accuracy of 0.60059\n","Epoch 19 : Train Loss of 0.57498 ; Valid Loss of 0.72807 ; Accuracy of 0.60352\n","Epoch 20 : Train Loss of 0.57028 ; Valid Loss of 0.73453 ; Accuracy of 0.60059\n","Epoch 21 : Train Loss of 0.56608 ; Valid Loss of 0.74280 ; Accuracy of 0.60254\n","Epoch 22 : Train Loss of 0.55967 ; Valid Loss of 0.73466 ; Accuracy of 0.60059\n","Epoch 23 : Train Loss of 0.55211 ; Valid Loss of 0.76905 ; Accuracy of 0.58691\n","Epoch 24 : Train Loss of 0.54636 ; Valid Loss of 0.76486 ; Accuracy of 0.58887\n","Epoch 25 : Train Loss of 0.54045 ; Valid Loss of 0.76979 ; Accuracy of 0.59766\n","Epoch 26 : Train Loss of 0.53548 ; Valid Loss of 0.75980 ; Accuracy of 0.59473\n","Epoch 27 : Train Loss of 0.52854 ; Valid Loss of 0.79157 ; Accuracy of 0.58398\n","Epoch 28 : Train Loss of 0.52084 ; Valid Loss of 0.77735 ; Accuracy of 0.59668\n","Epoch 29 : Train Loss of 0.51269 ; Valid Loss of 0.79179 ; Accuracy of 0.59570\n","Epoch 30 : Train Loss of 0.50374 ; Valid Loss of 0.82538 ; Accuracy of 0.58887\n","Epoch 31 : Train Loss of 0.49818 ; Valid Loss of 0.79395 ; Accuracy of 0.60352\n","Epoch 32 : Train Loss of 0.49189 ; Valid Loss of 0.81865 ; Accuracy of 0.60352\n","Epoch 33 : Train Loss of 0.48346 ; Valid Loss of 0.82594 ; Accuracy of 0.59277\n","Epoch 34 : Train Loss of 0.47546 ; Valid Loss of 0.82703 ; Accuracy of 0.59668\n","Epoch 35 : Train Loss of 0.46957 ; Valid Loss of 0.83149 ; Accuracy of 0.59570\n","Epoch 36 : Train Loss of 0.46272 ; Valid Loss of 0.85619 ; Accuracy of 0.59180\n","Epoch 37 : Train Loss of 0.45745 ; Valid Loss of 0.84431 ; Accuracy of 0.58496\n","Epoch 38 : Train Loss of 0.44775 ; Valid Loss of 0.86165 ; Accuracy of 0.59473\n","Epoch 39 : Train Loss of 0.44156 ; Valid Loss of 0.85614 ; Accuracy of 0.58496\n","Epoch 40 : Train Loss of 0.43524 ; Valid Loss of 0.85920 ; Accuracy of 0.58789\n","Epoch 41 : Train Loss of 0.42821 ; Valid Loss of 0.88326 ; Accuracy of 0.58301\n","Epoch 42 : Train Loss of 0.42451 ; Valid Loss of 0.86960 ; Accuracy of 0.59766\n","Epoch 43 : Train Loss of 0.41568 ; Valid Loss of 0.91892 ; Accuracy of 0.59277\n","Epoch 44 : Train Loss of 0.41359 ; Valid Loss of 0.92437 ; Accuracy of 0.58105\n","Epoch 45 : Train Loss of 0.40650 ; Valid Loss of 0.90425 ; Accuracy of 0.59375\n","Epoch 46 : Train Loss of 0.39751 ; Valid Loss of 0.94882 ; Accuracy of 0.58984\n","Epoch 47 : Train Loss of 0.39403 ; Valid Loss of 0.96512 ; Accuracy of 0.58594\n","Epoch 48 : Train Loss of 0.38674 ; Valid Loss of 0.98700 ; Accuracy of 0.58203\n","Epoch 49 : Train Loss of 0.37998 ; Valid Loss of 0.96371 ; Accuracy of 0.58691\n","Epoch 50 : Train Loss of 0.37395 ; Valid Loss of 0.98351 ; Accuracy of 0.58496\n","Epoch 51 : Train Loss of 0.36867 ; Valid Loss of 0.97995 ; Accuracy of 0.58691\n","Epoch 52 : Train Loss of 0.36854 ; Valid Loss of 0.99732 ; Accuracy of 0.59570\n","Epoch 53 : Train Loss of 0.35672 ; Valid Loss of 1.00696 ; Accuracy of 0.57715\n","Epoch 54 : Train Loss of 0.35672 ; Valid Loss of 1.05043 ; Accuracy of 0.58301\n","Epoch 55 : Train Loss of 0.35364 ; Valid Loss of 1.04322 ; Accuracy of 0.58594\n","Epoch 56 : Train Loss of 0.35100 ; Valid Loss of 1.05944 ; Accuracy of 0.57715\n","Early Stopping, Best Optimal Number of Epoch is 6\n","Training For Optimal Number of Epochs 6 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.79114\n","Epoch 1 : Entire Train Loss of 0.69293\n","Epoch 2 : Entire Train Loss of 0.66251\n","Epoch 3 : Entire Train Loss of 0.64654\n","Epoch 4 : Entire Train Loss of 0.63138\n","Epoch 5 : Entire Train Loss of 0.62428\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.81189 ; Valid Loss of 0.71748 ; Accuracy of 0.57324\n","Epoch 2 : Train Loss of 0.70477 ; Valid Loss of 0.68579 ; Accuracy of 0.58691\n","Epoch 3 : Train Loss of 0.66564 ; Valid Loss of 0.69357 ; Accuracy of 0.59375\n","Epoch 4 : Train Loss of 0.64612 ; Valid Loss of 0.69419 ; Accuracy of 0.57324\n","Epoch 5 : Train Loss of 0.63380 ; Valid Loss of 0.68338 ; Accuracy of 0.59473\n","Epoch 6 : Train Loss of 0.62767 ; Valid Loss of 0.68996 ; Accuracy of 0.59863\n","Epoch 7 : Train Loss of 0.62215 ; Valid Loss of 0.69226 ; Accuracy of 0.59180\n","Epoch 8 : Train Loss of 0.61622 ; Valid Loss of 0.68175 ; Accuracy of 0.59180\n","Epoch 9 : Train Loss of 0.61291 ; Valid Loss of 0.69404 ; Accuracy of 0.59082\n","Epoch 10 : Train Loss of 0.60738 ; Valid Loss of 0.68473 ; Accuracy of 0.60449\n","Epoch 11 : Train Loss of 0.60427 ; Valid Loss of 0.69563 ; Accuracy of 0.59082\n","Epoch 12 : Train Loss of 0.60150 ; Valid Loss of 0.68613 ; Accuracy of 0.61035\n","Epoch 13 : Train Loss of 0.59980 ; Valid Loss of 0.69646 ; Accuracy of 0.60645\n","Epoch 14 : Train Loss of 0.59627 ; Valid Loss of 0.70565 ; Accuracy of 0.59375\n","Epoch 15 : Train Loss of 0.59267 ; Valid Loss of 0.71880 ; Accuracy of 0.60156\n","Epoch 16 : Train Loss of 0.58934 ; Valid Loss of 0.70763 ; Accuracy of 0.60059\n","Epoch 17 : Train Loss of 0.58558 ; Valid Loss of 0.71629 ; Accuracy of 0.60254\n","Epoch 18 : Train Loss of 0.58035 ; Valid Loss of 0.72492 ; Accuracy of 0.59473\n","Epoch 19 : Train Loss of 0.57764 ; Valid Loss of 0.73032 ; Accuracy of 0.59863\n","Epoch 20 : Train Loss of 0.57465 ; Valid Loss of 0.70812 ; Accuracy of 0.60840\n","Epoch 21 : Train Loss of 0.56738 ; Valid Loss of 0.73721 ; Accuracy of 0.60742\n","Epoch 22 : Train Loss of 0.56253 ; Valid Loss of 0.74083 ; Accuracy of 0.59473\n","Epoch 23 : Train Loss of 0.55798 ; Valid Loss of 0.74901 ; Accuracy of 0.59766\n","Epoch 24 : Train Loss of 0.55143 ; Valid Loss of 0.74737 ; Accuracy of 0.58789\n","Epoch 25 : Train Loss of 0.54577 ; Valid Loss of 0.74216 ; Accuracy of 0.59961\n","Epoch 26 : Train Loss of 0.53903 ; Valid Loss of 0.77415 ; Accuracy of 0.58887\n","Epoch 27 : Train Loss of 0.53289 ; Valid Loss of 0.75259 ; Accuracy of 0.60449\n","Epoch 28 : Train Loss of 0.52674 ; Valid Loss of 0.78431 ; Accuracy of 0.57715\n","Epoch 29 : Train Loss of 0.51952 ; Valid Loss of 0.78905 ; Accuracy of 0.58984\n","Epoch 30 : Train Loss of 0.51156 ; Valid Loss of 0.78615 ; Accuracy of 0.58887\n","Epoch 31 : Train Loss of 0.50503 ; Valid Loss of 0.78576 ; Accuracy of 0.59082\n","Epoch 32 : Train Loss of 0.49857 ; Valid Loss of 0.80246 ; Accuracy of 0.57520\n","Epoch 33 : Train Loss of 0.49122 ; Valid Loss of 0.79948 ; Accuracy of 0.59375\n","Epoch 34 : Train Loss of 0.48541 ; Valid Loss of 0.80102 ; Accuracy of 0.59277\n","Epoch 35 : Train Loss of 0.47741 ; Valid Loss of 0.83021 ; Accuracy of 0.57812\n","Epoch 36 : Train Loss of 0.46626 ; Valid Loss of 0.83054 ; Accuracy of 0.57227\n","Epoch 37 : Train Loss of 0.46097 ; Valid Loss of 0.85302 ; Accuracy of 0.58496\n","Epoch 38 : Train Loss of 0.45577 ; Valid Loss of 0.86094 ; Accuracy of 0.56348\n","Epoch 39 : Train Loss of 0.44875 ; Valid Loss of 0.86434 ; Accuracy of 0.57227\n","Epoch 40 : Train Loss of 0.44077 ; Valid Loss of 0.85409 ; Accuracy of 0.57617\n","Epoch 41 : Train Loss of 0.43679 ; Valid Loss of 0.89068 ; Accuracy of 0.56738\n","Epoch 42 : Train Loss of 0.43044 ; Valid Loss of 0.87402 ; Accuracy of 0.58691\n","Epoch 43 : Train Loss of 0.42227 ; Valid Loss of 0.88325 ; Accuracy of 0.57227\n","Epoch 44 : Train Loss of 0.41580 ; Valid Loss of 0.90717 ; Accuracy of 0.57031\n","Epoch 45 : Train Loss of 0.40923 ; Valid Loss of 0.90790 ; Accuracy of 0.57617\n","Epoch 46 : Train Loss of 0.40377 ; Valid Loss of 0.93066 ; Accuracy of 0.56738\n","Epoch 47 : Train Loss of 0.39844 ; Valid Loss of 0.93383 ; Accuracy of 0.56836\n","Epoch 48 : Train Loss of 0.39680 ; Valid Loss of 0.93324 ; Accuracy of 0.56348\n","Epoch 49 : Train Loss of 0.38813 ; Valid Loss of 0.95439 ; Accuracy of 0.56348\n","Epoch 50 : Train Loss of 0.38590 ; Valid Loss of 0.96765 ; Accuracy of 0.56348\n","Epoch 51 : Train Loss of 0.37444 ; Valid Loss of 0.96926 ; Accuracy of 0.59180\n","Epoch 52 : Train Loss of 0.37581 ; Valid Loss of 0.95981 ; Accuracy of 0.57129\n","Epoch 53 : Train Loss of 0.36592 ; Valid Loss of 0.95864 ; Accuracy of 0.57715\n","Epoch 54 : Train Loss of 0.36395 ; Valid Loss of 1.00149 ; Accuracy of 0.56836\n","Epoch 55 : Train Loss of 0.35992 ; Valid Loss of 1.00660 ; Accuracy of 0.56055\n","Epoch 56 : Train Loss of 0.35261 ; Valid Loss of 1.00437 ; Accuracy of 0.56934\n","Epoch 57 : Train Loss of 0.35090 ; Valid Loss of 1.03009 ; Accuracy of 0.56445\n","Epoch 58 : Train Loss of 0.34321 ; Valid Loss of 1.06208 ; Accuracy of 0.57129\n","Early Stopping, Best Optimal Number of Epoch is 8\n","Training For Optimal Number of Epochs 8 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 0.81217\n","Epoch 1 : Entire Train Loss of 0.70524\n","Epoch 2 : Entire Train Loss of 0.66720\n","Epoch 3 : Entire Train Loss of 0.64669\n","Epoch 4 : Entire Train Loss of 0.63740\n","Epoch 5 : Entire Train Loss of 0.62774\n","Epoch 6 : Entire Train Loss of 0.62216\n","Epoch 7 : Entire Train Loss of 0.61641\n","Proportion of 1 is for train set is : 0.610204335908298\n","Proportion of 1 is for valid set is : 0.5473684210526316\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 0.80669 ; Valid Loss of 0.69053 ; Accuracy of 0.57324\n","Epoch 2 : Train Loss of 0.70281 ; Valid Loss of 0.68479 ; Accuracy of 0.59668\n","Epoch 3 : Train Loss of 0.66525 ; Valid Loss of 0.68883 ; Accuracy of 0.59180\n","Epoch 4 : Train Loss of 0.64947 ; Valid Loss of 0.68419 ; Accuracy of 0.59180\n","Epoch 5 : Train Loss of 0.63424 ; Valid Loss of 0.68936 ; Accuracy of 0.59668\n","Epoch 6 : Train Loss of 0.62660 ; Valid Loss of 0.68497 ; Accuracy of 0.60547\n","Epoch 7 : Train Loss of 0.61736 ; Valid Loss of 0.69674 ; Accuracy of 0.60449\n","Epoch 8 : Train Loss of 0.61548 ; Valid Loss of 0.69336 ; Accuracy of 0.59961\n","Epoch 9 : Train Loss of 0.60998 ; Valid Loss of 0.69408 ; Accuracy of 0.61230\n","Epoch 10 : Train Loss of 0.60742 ; Valid Loss of 0.69644 ; Accuracy of 0.60156\n","Epoch 11 : Train Loss of 0.60464 ; Valid Loss of 0.69570 ; Accuracy of 0.61426\n","Epoch 12 : Train Loss of 0.60064 ; Valid Loss of 0.70554 ; Accuracy of 0.60645\n","Epoch 13 : Train Loss of 0.59741 ; Valid Loss of 0.71759 ; Accuracy of 0.62109\n","Epoch 14 : Train Loss of 0.59530 ; Valid Loss of 0.70842 ; Accuracy of 0.61719\n","Epoch 15 : Train Loss of 0.59106 ; Valid Loss of 0.72303 ; Accuracy of 0.60938\n","Epoch 16 : Train Loss of 0.58906 ; Valid Loss of 0.71605 ; Accuracy of 0.60645\n","Epoch 17 : Train Loss of 0.58570 ; Valid Loss of 0.70571 ; Accuracy of 0.61914\n","Epoch 18 : Train Loss of 0.57966 ; Valid Loss of 0.74225 ; Accuracy of 0.60645\n","Epoch 19 : Train Loss of 0.57691 ; Valid Loss of 0.72870 ; Accuracy of 0.61133\n","Epoch 20 : Train Loss of 0.57012 ; Valid Loss of 0.73541 ; Accuracy of 0.59863\n","Epoch 21 : Train Loss of 0.56615 ; Valid Loss of 0.74340 ; Accuracy of 0.59961\n","Epoch 22 : Train Loss of 0.56074 ; Valid Loss of 0.75892 ; Accuracy of 0.60352\n","Epoch 23 : Train Loss of 0.55702 ; Valid Loss of 0.75530 ; Accuracy of 0.59570\n","Epoch 24 : Train Loss of 0.54881 ; Valid Loss of 0.76987 ; Accuracy of 0.59766\n","Epoch 25 : Train Loss of 0.54506 ; Valid Loss of 0.77328 ; Accuracy of 0.59863\n","Epoch 26 : Train Loss of 0.53680 ; Valid Loss of 0.76401 ; Accuracy of 0.59863\n","Epoch 27 : Train Loss of 0.53154 ; Valid Loss of 0.78341 ; Accuracy of 0.59473\n","Epoch 28 : Train Loss of 0.52194 ; Valid Loss of 0.78611 ; Accuracy of 0.58691\n","Epoch 29 : Train Loss of 0.51511 ; Valid Loss of 0.78935 ; Accuracy of 0.58496\n","Epoch 30 : Train Loss of 0.50657 ; Valid Loss of 0.82346 ; Accuracy of 0.58008\n","Epoch 31 : Train Loss of 0.50235 ; Valid Loss of 0.82588 ; Accuracy of 0.59473\n","Epoch 32 : Train Loss of 0.49103 ; Valid Loss of 0.83317 ; Accuracy of 0.58496\n","Epoch 33 : Train Loss of 0.48527 ; Valid Loss of 0.85242 ; Accuracy of 0.57715\n","Epoch 34 : Train Loss of 0.48042 ; Valid Loss of 0.87506 ; Accuracy of 0.57715\n","Epoch 35 : Train Loss of 0.47378 ; Valid Loss of 0.85159 ; Accuracy of 0.58008\n","Epoch 36 : Train Loss of 0.46553 ; Valid Loss of 0.86422 ; Accuracy of 0.59375\n","Epoch 37 : Train Loss of 0.45464 ; Valid Loss of 0.86577 ; Accuracy of 0.58984\n","Epoch 38 : Train Loss of 0.45157 ; Valid Loss of 0.90485 ; Accuracy of 0.58203\n","Epoch 39 : Train Loss of 0.44505 ; Valid Loss of 0.92319 ; Accuracy of 0.56934\n","Epoch 40 : Train Loss of 0.43889 ; Valid Loss of 0.91502 ; Accuracy of 0.57227\n","Epoch 41 : Train Loss of 0.43385 ; Valid Loss of 0.89342 ; Accuracy of 0.58691\n","Epoch 42 : Train Loss of 0.42048 ; Valid Loss of 0.95574 ; Accuracy of 0.57812\n","Epoch 43 : Train Loss of 0.42158 ; Valid Loss of 0.94937 ; Accuracy of 0.59180\n","Epoch 44 : Train Loss of 0.41375 ; Valid Loss of 0.93215 ; Accuracy of 0.58203\n","Epoch 45 : Train Loss of 0.40484 ; Valid Loss of 0.98513 ; Accuracy of 0.56738\n","Epoch 46 : Train Loss of 0.40065 ; Valid Loss of 1.03087 ; Accuracy of 0.57227\n","Epoch 47 : Train Loss of 0.39207 ; Valid Loss of 0.98907 ; Accuracy of 0.58301\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hcTt1K1_ndSW","executionInfo":{"status":"ok","timestamp":1602033150643,"user_tz":420,"elapsed":362,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"7b61740d-d05c-48cf-ca84-6ef54ab49e24","colab":{"base_uri":"https://localhost:8080/"}},"source":["pr.mean(axis = 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.569522\n","dtype: float32"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"uCluqFq5Uf92","outputId":"74262781-3b5c-4fd2-a4c4-0ce242008418","colab":{"base_uri":"https://localhost:8080/"}},"source":["model = 'total'\n","date = '2020-10-11'\n","thresholds = [212, 213, 215, 216, 217]\n","all_predictions = {}\n","for i, threshold in enumerate(thresholds):\n","  print(f'Running Threshold {threshold}')\n","  if i >= 1:\n","    save_processed_data = 0\n","    load_processed_data = 1\n","  else:\n","    save_processed_data = 1\n","    load_processed_data = 0\n","  model = 'total'\n","  date = '2020-10-11'\n","  log_dir_folder = 'total_10-11-20_512_256_lr_6e-4'\n","  %run 'player_model.py' -weighted_sampler 1 -lin_layer_size 512 256 -lin_layer_dropout 0.5 0.5 -early_stopping 50 -swa 0 -lr 5e-4 '-date={date}' '-model={model}' '-threshold={threshold}' '-save_processed_data={save_processed_data}' '-load_processed_data={load_processed_data}' '-log_dir_folder={log_dir_folder}'\n","  ppp = {k : v.ravel() for k,v in predictions.items()}\n","  pr = pd.DataFrame(ppp)\n","  all_predictions[threshold] = pr.copy()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running Threshold 216\n","Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='total_10-06-20_512_256_lr_6e-4', lr=0.0005, model='total', production=1, save_processed_data=0, swa=0, threshold=216)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c2860>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.47292 ; Valid Loss of 1.70878 ; Accuracy of 0.50391\n","Epoch 2 : Train Loss of 1.32812 ; Valid Loss of 1.77993 ; Accuracy of 0.49219\n","Epoch 3 : Train Loss of 1.26808 ; Valid Loss of 1.83803 ; Accuracy of 0.48633\n","Epoch 4 : Train Loss of 1.23019 ; Valid Loss of 1.85926 ; Accuracy of 0.49414\n","Epoch 5 : Train Loss of 1.22049 ; Valid Loss of 1.85871 ; Accuracy of 0.48926\n","Epoch 6 : Train Loss of 1.19924 ; Valid Loss of 1.87208 ; Accuracy of 0.49121\n","Epoch 7 : Train Loss of 1.17725 ; Valid Loss of 1.89992 ; Accuracy of 0.48828\n","Epoch 8 : Train Loss of 1.17352 ; Valid Loss of 1.87968 ; Accuracy of 0.48633\n","Epoch 9 : Train Loss of 1.15279 ; Valid Loss of 1.88387 ; Accuracy of 0.49512\n","Epoch 10 : Train Loss of 1.15263 ; Valid Loss of 1.87976 ; Accuracy of 0.49219\n","Epoch 11 : Train Loss of 1.12369 ; Valid Loss of 1.89896 ; Accuracy of 0.49902\n","Epoch 12 : Train Loss of 1.12066 ; Valid Loss of 1.91875 ; Accuracy of 0.48633\n","Epoch 13 : Train Loss of 1.10789 ; Valid Loss of 1.89929 ; Accuracy of 0.49512\n","Epoch 14 : Train Loss of 1.10044 ; Valid Loss of 1.88513 ; Accuracy of 0.50098\n","Epoch 15 : Train Loss of 1.09570 ; Valid Loss of 1.94609 ; Accuracy of 0.48242\n","Epoch 16 : Train Loss of 1.08956 ; Valid Loss of 1.89444 ; Accuracy of 0.49707\n","Epoch 17 : Train Loss of 1.07226 ; Valid Loss of 1.93811 ; Accuracy of 0.49121\n","Epoch 18 : Train Loss of 1.06316 ; Valid Loss of 1.90559 ; Accuracy of 0.49805\n","Epoch 19 : Train Loss of 1.07286 ; Valid Loss of 1.91651 ; Accuracy of 0.50098\n","Epoch 20 : Train Loss of 1.06601 ; Valid Loss of 1.92754 ; Accuracy of 0.50098\n","Epoch 21 : Train Loss of 1.04027 ; Valid Loss of 1.92749 ; Accuracy of 0.50488\n","Epoch 22 : Train Loss of 1.04998 ; Valid Loss of 1.91711 ; Accuracy of 0.50293\n","Epoch 23 : Train Loss of 1.04444 ; Valid Loss of 1.92127 ; Accuracy of 0.50195\n","Epoch 24 : Train Loss of 1.03667 ; Valid Loss of 1.88931 ; Accuracy of 0.49902\n","Epoch 25 : Train Loss of 1.03475 ; Valid Loss of 1.90908 ; Accuracy of 0.50781\n","Epoch 26 : Train Loss of 1.02953 ; Valid Loss of 1.86083 ; Accuracy of 0.49902\n","Epoch 27 : Train Loss of 1.02663 ; Valid Loss of 1.89479 ; Accuracy of 0.50098\n","Epoch 28 : Train Loss of 1.01218 ; Valid Loss of 1.91553 ; Accuracy of 0.49121\n","Epoch 29 : Train Loss of 1.00656 ; Valid Loss of 1.93274 ; Accuracy of 0.49023\n","Epoch 30 : Train Loss of 0.99923 ; Valid Loss of 1.93238 ; Accuracy of 0.49414\n","Epoch 31 : Train Loss of 1.00630 ; Valid Loss of 1.94246 ; Accuracy of 0.49023\n","Epoch 32 : Train Loss of 0.99980 ; Valid Loss of 1.93590 ; Accuracy of 0.50488\n","Epoch 33 : Train Loss of 0.98616 ; Valid Loss of 1.89305 ; Accuracy of 0.51465\n","Epoch 34 : Train Loss of 0.98498 ; Valid Loss of 1.91940 ; Accuracy of 0.49902\n","Epoch 35 : Train Loss of 0.99549 ; Valid Loss of 1.94061 ; Accuracy of 0.50098\n","Epoch 36 : Train Loss of 0.99579 ; Valid Loss of 1.91266 ; Accuracy of 0.50781\n","Epoch 37 : Train Loss of 0.97723 ; Valid Loss of 1.96048 ; Accuracy of 0.49902\n","Epoch 38 : Train Loss of 0.98268 ; Valid Loss of 1.94683 ; Accuracy of 0.49805\n","Epoch 39 : Train Loss of 0.96578 ; Valid Loss of 1.96029 ; Accuracy of 0.50000\n","Epoch 40 : Train Loss of 0.96864 ; Valid Loss of 1.95873 ; Accuracy of 0.49023\n","Epoch 41 : Train Loss of 0.96482 ; Valid Loss of 1.92503 ; Accuracy of 0.49902\n","Epoch 42 : Train Loss of 0.96831 ; Valid Loss of 1.96186 ; Accuracy of 0.49805\n","Epoch 43 : Train Loss of 0.95297 ; Valid Loss of 1.98724 ; Accuracy of 0.49902\n","Epoch 44 : Train Loss of 0.95185 ; Valid Loss of 1.90732 ; Accuracy of 0.49414\n","Epoch 45 : Train Loss of 0.95654 ; Valid Loss of 1.94481 ; Accuracy of 0.49707\n","Epoch 46 : Train Loss of 0.94806 ; Valid Loss of 1.97055 ; Accuracy of 0.48828\n","Epoch 47 : Train Loss of 0.95202 ; Valid Loss of 1.92209 ; Accuracy of 0.49902\n","Epoch 48 : Train Loss of 0.94000 ; Valid Loss of 1.93368 ; Accuracy of 0.50293\n","Epoch 49 : Train Loss of 0.94225 ; Valid Loss of 1.91553 ; Accuracy of 0.50000\n","Epoch 50 : Train Loss of 0.93945 ; Valid Loss of 1.93439 ; Accuracy of 0.50391\n","Epoch 51 : Train Loss of 0.94291 ; Valid Loss of 1.98359 ; Accuracy of 0.48828\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d777898>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.52546\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c2f60>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.49316 ; Valid Loss of 1.71192 ; Accuracy of 0.50098\n","Epoch 2 : Train Loss of 1.31589 ; Valid Loss of 1.78979 ; Accuracy of 0.50293\n","Epoch 3 : Train Loss of 1.26656 ; Valid Loss of 1.87934 ; Accuracy of 0.48145\n","Epoch 4 : Train Loss of 1.22046 ; Valid Loss of 1.91373 ; Accuracy of 0.49805\n","Epoch 5 : Train Loss of 1.20518 ; Valid Loss of 1.91870 ; Accuracy of 0.49805\n","Epoch 6 : Train Loss of 1.17991 ; Valid Loss of 1.94988 ; Accuracy of 0.49219\n","Epoch 7 : Train Loss of 1.16733 ; Valid Loss of 1.95450 ; Accuracy of 0.48730\n","Epoch 8 : Train Loss of 1.15184 ; Valid Loss of 1.97727 ; Accuracy of 0.47559\n","Epoch 9 : Train Loss of 1.13599 ; Valid Loss of 1.99954 ; Accuracy of 0.48633\n","Epoch 10 : Train Loss of 1.12429 ; Valid Loss of 1.99761 ; Accuracy of 0.48242\n","Epoch 11 : Train Loss of 1.12064 ; Valid Loss of 1.99970 ; Accuracy of 0.48047\n","Epoch 12 : Train Loss of 1.11095 ; Valid Loss of 2.05277 ; Accuracy of 0.48047\n","Epoch 13 : Train Loss of 1.10219 ; Valid Loss of 1.98621 ; Accuracy of 0.48047\n","Epoch 14 : Train Loss of 1.09573 ; Valid Loss of 1.99415 ; Accuracy of 0.48047\n","Epoch 15 : Train Loss of 1.07600 ; Valid Loss of 2.07308 ; Accuracy of 0.47656\n","Epoch 16 : Train Loss of 1.07591 ; Valid Loss of 2.00264 ; Accuracy of 0.48438\n","Epoch 17 : Train Loss of 1.05930 ; Valid Loss of 2.04428 ; Accuracy of 0.47461\n","Epoch 18 : Train Loss of 1.05988 ; Valid Loss of 2.02826 ; Accuracy of 0.46582\n","Epoch 19 : Train Loss of 1.03860 ; Valid Loss of 2.07769 ; Accuracy of 0.46289\n","Epoch 20 : Train Loss of 1.04447 ; Valid Loss of 2.09344 ; Accuracy of 0.46875\n","Epoch 21 : Train Loss of 1.04538 ; Valid Loss of 2.06003 ; Accuracy of 0.46973\n","Epoch 22 : Train Loss of 1.02828 ; Valid Loss of 2.08299 ; Accuracy of 0.47168\n","Epoch 23 : Train Loss of 1.02910 ; Valid Loss of 2.06832 ; Accuracy of 0.47461\n","Epoch 24 : Train Loss of 1.01667 ; Valid Loss of 2.11534 ; Accuracy of 0.45996\n","Epoch 25 : Train Loss of 1.02453 ; Valid Loss of 2.04363 ; Accuracy of 0.47168\n","Epoch 26 : Train Loss of 1.02113 ; Valid Loss of 2.09071 ; Accuracy of 0.47168\n","Epoch 27 : Train Loss of 1.00211 ; Valid Loss of 2.06010 ; Accuracy of 0.47754\n","Epoch 28 : Train Loss of 1.00350 ; Valid Loss of 2.07612 ; Accuracy of 0.46973\n","Epoch 29 : Train Loss of 0.98886 ; Valid Loss of 2.07071 ; Accuracy of 0.47070\n","Epoch 30 : Train Loss of 0.97961 ; Valid Loss of 2.08128 ; Accuracy of 0.48633\n","Epoch 31 : Train Loss of 0.99435 ; Valid Loss of 2.07070 ; Accuracy of 0.47852\n","Epoch 32 : Train Loss of 0.98601 ; Valid Loss of 2.10170 ; Accuracy of 0.47266\n","Epoch 33 : Train Loss of 0.98643 ; Valid Loss of 2.06508 ; Accuracy of 0.47852\n","Epoch 34 : Train Loss of 0.98308 ; Valid Loss of 2.05134 ; Accuracy of 0.47461\n","Epoch 35 : Train Loss of 0.96972 ; Valid Loss of 2.02127 ; Accuracy of 0.47949\n","Epoch 36 : Train Loss of 0.95919 ; Valid Loss of 2.05607 ; Accuracy of 0.47656\n","Epoch 37 : Train Loss of 0.97329 ; Valid Loss of 2.03040 ; Accuracy of 0.48633\n","Epoch 38 : Train Loss of 0.96717 ; Valid Loss of 2.06524 ; Accuracy of 0.48535\n","Epoch 39 : Train Loss of 0.96484 ; Valid Loss of 2.01876 ; Accuracy of 0.49023\n","Epoch 40 : Train Loss of 0.96329 ; Valid Loss of 2.02037 ; Accuracy of 0.48340\n","Epoch 41 : Train Loss of 0.95546 ; Valid Loss of 1.99885 ; Accuracy of 0.48730\n","Epoch 42 : Train Loss of 0.94825 ; Valid Loss of 2.01983 ; Accuracy of 0.49316\n","Epoch 43 : Train Loss of 0.94382 ; Valid Loss of 2.02579 ; Accuracy of 0.48535\n","Epoch 44 : Train Loss of 0.94445 ; Valid Loss of 2.04120 ; Accuracy of 0.48730\n","Epoch 45 : Train Loss of 0.94206 ; Valid Loss of 2.02976 ; Accuracy of 0.48926\n","Epoch 46 : Train Loss of 0.93278 ; Valid Loss of 1.98931 ; Accuracy of 0.48828\n","Epoch 47 : Train Loss of 0.93959 ; Valid Loss of 2.00918 ; Accuracy of 0.49707\n","Epoch 48 : Train Loss of 0.93844 ; Valid Loss of 2.03144 ; Accuracy of 0.49023\n","Epoch 49 : Train Loss of 0.92905 ; Valid Loss of 2.04391 ; Accuracy of 0.48828\n","Epoch 50 : Train Loss of 0.92801 ; Valid Loss of 2.00097 ; Accuracy of 0.50195\n","Epoch 51 : Train Loss of 0.92864 ; Valid Loss of 2.03913 ; Accuracy of 0.49316\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c25c0>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.43713\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c2390>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.41277 ; Valid Loss of 1.66251 ; Accuracy of 0.50684\n","Epoch 2 : Train Loss of 1.27421 ; Valid Loss of 1.74505 ; Accuracy of 0.49609\n","Epoch 3 : Train Loss of 1.22261 ; Valid Loss of 1.78901 ; Accuracy of 0.49805\n","Epoch 4 : Train Loss of 1.18400 ; Valid Loss of 1.80523 ; Accuracy of 0.49805\n","Epoch 5 : Train Loss of 1.16716 ; Valid Loss of 1.83397 ; Accuracy of 0.49121\n","Epoch 6 : Train Loss of 1.14483 ; Valid Loss of 1.83591 ; Accuracy of 0.49902\n","Epoch 7 : Train Loss of 1.13222 ; Valid Loss of 1.83848 ; Accuracy of 0.50488\n","Epoch 8 : Train Loss of 1.10432 ; Valid Loss of 1.89054 ; Accuracy of 0.49902\n","Epoch 9 : Train Loss of 1.10345 ; Valid Loss of 1.85134 ; Accuracy of 0.50293\n","Epoch 10 : Train Loss of 1.09417 ; Valid Loss of 1.86622 ; Accuracy of 0.50977\n","Epoch 11 : Train Loss of 1.07637 ; Valid Loss of 1.91186 ; Accuracy of 0.49902\n","Epoch 12 : Train Loss of 1.07569 ; Valid Loss of 1.88125 ; Accuracy of 0.51172\n","Epoch 13 : Train Loss of 1.06152 ; Valid Loss of 1.89157 ; Accuracy of 0.50488\n","Epoch 14 : Train Loss of 1.05692 ; Valid Loss of 1.88311 ; Accuracy of 0.50391\n","Epoch 15 : Train Loss of 1.04573 ; Valid Loss of 1.90500 ; Accuracy of 0.49902\n","Epoch 16 : Train Loss of 1.03305 ; Valid Loss of 1.89859 ; Accuracy of 0.50977\n","Epoch 17 : Train Loss of 1.03629 ; Valid Loss of 1.89565 ; Accuracy of 0.50195\n","Epoch 18 : Train Loss of 1.02135 ; Valid Loss of 1.92683 ; Accuracy of 0.49316\n","Epoch 19 : Train Loss of 1.01647 ; Valid Loss of 1.91542 ; Accuracy of 0.49902\n","Epoch 20 : Train Loss of 1.02247 ; Valid Loss of 1.90568 ; Accuracy of 0.50488\n","Epoch 21 : Train Loss of 1.01497 ; Valid Loss of 1.94865 ; Accuracy of 0.50000\n","Epoch 22 : Train Loss of 1.00460 ; Valid Loss of 1.88524 ; Accuracy of 0.50684\n","Epoch 23 : Train Loss of 1.00277 ; Valid Loss of 1.94103 ; Accuracy of 0.49902\n","Epoch 24 : Train Loss of 0.98640 ; Valid Loss of 1.88956 ; Accuracy of 0.50000\n","Epoch 25 : Train Loss of 0.99257 ; Valid Loss of 1.89758 ; Accuracy of 0.49902\n","Epoch 26 : Train Loss of 0.98668 ; Valid Loss of 1.92358 ; Accuracy of 0.50098\n","Epoch 27 : Train Loss of 0.97769 ; Valid Loss of 1.91796 ; Accuracy of 0.49512\n","Epoch 28 : Train Loss of 0.98622 ; Valid Loss of 1.87261 ; Accuracy of 0.50098\n","Epoch 29 : Train Loss of 0.97325 ; Valid Loss of 1.92568 ; Accuracy of 0.49121\n","Epoch 30 : Train Loss of 0.96645 ; Valid Loss of 1.90091 ; Accuracy of 0.49414\n","Epoch 31 : Train Loss of 0.96687 ; Valid Loss of 1.88125 ; Accuracy of 0.50293\n","Epoch 32 : Train Loss of 0.96219 ; Valid Loss of 1.93411 ; Accuracy of 0.50488\n","Epoch 33 : Train Loss of 0.95958 ; Valid Loss of 1.92963 ; Accuracy of 0.49805\n","Epoch 34 : Train Loss of 0.96879 ; Valid Loss of 1.89078 ; Accuracy of 0.49902\n","Epoch 35 : Train Loss of 0.94986 ; Valid Loss of 1.94672 ; Accuracy of 0.48828\n","Epoch 36 : Train Loss of 0.95076 ; Valid Loss of 1.89165 ; Accuracy of 0.50391\n","Epoch 37 : Train Loss of 0.94846 ; Valid Loss of 1.92694 ; Accuracy of 0.49512\n","Epoch 38 : Train Loss of 0.95291 ; Valid Loss of 1.90265 ; Accuracy of 0.50293\n","Epoch 39 : Train Loss of 0.94849 ; Valid Loss of 1.90996 ; Accuracy of 0.49121\n","Epoch 40 : Train Loss of 0.94294 ; Valid Loss of 1.92661 ; Accuracy of 0.50000\n","Epoch 41 : Train Loss of 0.93982 ; Valid Loss of 1.96981 ; Accuracy of 0.48047\n","Epoch 42 : Train Loss of 0.93828 ; Valid Loss of 1.91345 ; Accuracy of 0.49609\n","Epoch 43 : Train Loss of 0.93722 ; Valid Loss of 1.93081 ; Accuracy of 0.49219\n","Epoch 44 : Train Loss of 0.92961 ; Valid Loss of 1.88364 ; Accuracy of 0.49512\n","Epoch 45 : Train Loss of 0.92601 ; Valid Loss of 1.93462 ; Accuracy of 0.49414\n","Epoch 46 : Train Loss of 0.92510 ; Valid Loss of 1.94230 ; Accuracy of 0.48633\n","Epoch 47 : Train Loss of 0.92486 ; Valid Loss of 1.93886 ; Accuracy of 0.48926\n","Epoch 48 : Train Loss of 0.91986 ; Valid Loss of 1.96315 ; Accuracy of 0.49414\n","Epoch 49 : Train Loss of 0.92145 ; Valid Loss of 1.97365 ; Accuracy of 0.47754\n","Epoch 50 : Train Loss of 0.92331 ; Valid Loss of 1.92289 ; Accuracy of 0.48633\n","Epoch 51 : Train Loss of 0.91434 ; Valid Loss of 1.93065 ; Accuracy of 0.48340\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0eca58>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.46480\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c2898>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.43899 ; Valid Loss of 1.57955 ; Accuracy of 0.54492\n","Epoch 2 : Train Loss of 1.30065 ; Valid Loss of 1.60832 ; Accuracy of 0.54395\n","Epoch 3 : Train Loss of 1.26359 ; Valid Loss of 1.67033 ; Accuracy of 0.52734\n","Epoch 4 : Train Loss of 1.22252 ; Valid Loss of 1.63518 ; Accuracy of 0.54102\n","Epoch 5 : Train Loss of 1.20290 ; Valid Loss of 1.66706 ; Accuracy of 0.54199\n","Epoch 6 : Train Loss of 1.19015 ; Valid Loss of 1.72330 ; Accuracy of 0.52441\n","Epoch 7 : Train Loss of 1.17451 ; Valid Loss of 1.69638 ; Accuracy of 0.53516\n","Epoch 8 : Train Loss of 1.15800 ; Valid Loss of 1.74040 ; Accuracy of 0.52539\n","Epoch 9 : Train Loss of 1.14642 ; Valid Loss of 1.70706 ; Accuracy of 0.53516\n","Epoch 10 : Train Loss of 1.12339 ; Valid Loss of 1.75200 ; Accuracy of 0.51855\n","Epoch 11 : Train Loss of 1.13132 ; Valid Loss of 1.74395 ; Accuracy of 0.53223\n","Epoch 12 : Train Loss of 1.10512 ; Valid Loss of 1.75010 ; Accuracy of 0.52734\n","Epoch 13 : Train Loss of 1.08945 ; Valid Loss of 1.78218 ; Accuracy of 0.52148\n","Epoch 14 : Train Loss of 1.08626 ; Valid Loss of 1.72581 ; Accuracy of 0.53223\n","Epoch 15 : Train Loss of 1.08220 ; Valid Loss of 1.74393 ; Accuracy of 0.52637\n","Epoch 16 : Train Loss of 1.07305 ; Valid Loss of 1.75213 ; Accuracy of 0.52832\n","Epoch 17 : Train Loss of 1.06084 ; Valid Loss of 1.83063 ; Accuracy of 0.50488\n","Epoch 18 : Train Loss of 1.07227 ; Valid Loss of 1.78822 ; Accuracy of 0.51953\n","Epoch 19 : Train Loss of 1.05468 ; Valid Loss of 1.79958 ; Accuracy of 0.51367\n","Epoch 20 : Train Loss of 1.04190 ; Valid Loss of 1.78920 ; Accuracy of 0.52344\n","Epoch 21 : Train Loss of 1.03401 ; Valid Loss of 1.77431 ; Accuracy of 0.52344\n","Epoch 22 : Train Loss of 1.04240 ; Valid Loss of 1.79146 ; Accuracy of 0.51074\n","Epoch 23 : Train Loss of 1.02573 ; Valid Loss of 1.75302 ; Accuracy of 0.52246\n","Epoch 24 : Train Loss of 1.02752 ; Valid Loss of 1.77600 ; Accuracy of 0.51465\n","Epoch 25 : Train Loss of 1.01848 ; Valid Loss of 1.80144 ; Accuracy of 0.51660\n","Epoch 26 : Train Loss of 1.00685 ; Valid Loss of 1.77570 ; Accuracy of 0.52441\n","Epoch 27 : Train Loss of 1.00532 ; Valid Loss of 1.77586 ; Accuracy of 0.52051\n","Epoch 28 : Train Loss of 0.99697 ; Valid Loss of 1.80791 ; Accuracy of 0.51562\n","Epoch 29 : Train Loss of 0.99833 ; Valid Loss of 1.84288 ; Accuracy of 0.49707\n","Epoch 30 : Train Loss of 0.99211 ; Valid Loss of 1.80577 ; Accuracy of 0.51953\n","Epoch 31 : Train Loss of 0.98760 ; Valid Loss of 1.80509 ; Accuracy of 0.51367\n","Epoch 32 : Train Loss of 0.97963 ; Valid Loss of 1.83325 ; Accuracy of 0.51172\n","Epoch 33 : Train Loss of 0.98909 ; Valid Loss of 1.81407 ; Accuracy of 0.51855\n","Epoch 34 : Train Loss of 0.98246 ; Valid Loss of 1.84171 ; Accuracy of 0.51270\n","Epoch 35 : Train Loss of 0.97301 ; Valid Loss of 1.81636 ; Accuracy of 0.50977\n","Epoch 36 : Train Loss of 0.96847 ; Valid Loss of 1.78512 ; Accuracy of 0.52148\n","Epoch 37 : Train Loss of 0.96739 ; Valid Loss of 1.82787 ; Accuracy of 0.50684\n","Epoch 38 : Train Loss of 0.97268 ; Valid Loss of 1.81315 ; Accuracy of 0.52148\n","Epoch 39 : Train Loss of 0.95860 ; Valid Loss of 1.78499 ; Accuracy of 0.52637\n","Epoch 40 : Train Loss of 0.95207 ; Valid Loss of 1.82269 ; Accuracy of 0.51855\n","Epoch 41 : Train Loss of 0.95725 ; Valid Loss of 1.77596 ; Accuracy of 0.52441\n","Epoch 42 : Train Loss of 0.94315 ; Valid Loss of 1.83779 ; Accuracy of 0.52441\n","Epoch 43 : Train Loss of 0.94721 ; Valid Loss of 1.83173 ; Accuracy of 0.51270\n","Epoch 44 : Train Loss of 0.94549 ; Valid Loss of 1.79445 ; Accuracy of 0.52246\n","Epoch 45 : Train Loss of 0.93714 ; Valid Loss of 1.77439 ; Accuracy of 0.52051\n","Epoch 46 : Train Loss of 0.94366 ; Valid Loss of 1.81485 ; Accuracy of 0.52246\n","Epoch 47 : Train Loss of 0.94075 ; Valid Loss of 1.79802 ; Accuracy of 0.52441\n","Epoch 48 : Train Loss of 0.93167 ; Valid Loss of 1.77562 ; Accuracy of 0.52148\n","Epoch 49 : Train Loss of 0.92900 ; Valid Loss of 1.84477 ; Accuracy of 0.51660\n","Epoch 50 : Train Loss of 0.92449 ; Valid Loss of 1.80812 ; Accuracy of 0.51465\n","Epoch 51 : Train Loss of 0.92922 ; Valid Loss of 1.84543 ; Accuracy of 0.51172\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f26c1795e80>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.54855\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d779320>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.49935 ; Valid Loss of 1.97969 ; Accuracy of 0.48047\n","Epoch 2 : Train Loss of 1.31325 ; Valid Loss of 2.01454 ; Accuracy of 0.47266\n","Epoch 3 : Train Loss of 1.24414 ; Valid Loss of 2.00237 ; Accuracy of 0.47949\n","Epoch 4 : Train Loss of 1.21270 ; Valid Loss of 2.10351 ; Accuracy of 0.46484\n","Epoch 5 : Train Loss of 1.19196 ; Valid Loss of 2.10919 ; Accuracy of 0.46387\n","Epoch 6 : Train Loss of 1.17376 ; Valid Loss of 2.11712 ; Accuracy of 0.47852\n","Epoch 7 : Train Loss of 1.15051 ; Valid Loss of 2.12982 ; Accuracy of 0.47168\n","Epoch 8 : Train Loss of 1.14768 ; Valid Loss of 2.17062 ; Accuracy of 0.45996\n","Epoch 9 : Train Loss of 1.12936 ; Valid Loss of 2.13688 ; Accuracy of 0.47559\n","Epoch 10 : Train Loss of 1.11883 ; Valid Loss of 2.19351 ; Accuracy of 0.46094\n","Epoch 11 : Train Loss of 1.11854 ; Valid Loss of 2.15762 ; Accuracy of 0.46875\n","Epoch 12 : Train Loss of 1.10531 ; Valid Loss of 2.14955 ; Accuracy of 0.46973\n","Epoch 13 : Train Loss of 1.09164 ; Valid Loss of 2.13610 ; Accuracy of 0.46777\n","Epoch 14 : Train Loss of 1.07682 ; Valid Loss of 2.16829 ; Accuracy of 0.46484\n","Epoch 15 : Train Loss of 1.07460 ; Valid Loss of 2.16708 ; Accuracy of 0.46875\n","Epoch 16 : Train Loss of 1.06419 ; Valid Loss of 2.14293 ; Accuracy of 0.46777\n","Epoch 17 : Train Loss of 1.05253 ; Valid Loss of 2.14276 ; Accuracy of 0.46289\n","Epoch 18 : Train Loss of 1.05709 ; Valid Loss of 2.13062 ; Accuracy of 0.47754\n","Epoch 19 : Train Loss of 1.04632 ; Valid Loss of 2.13517 ; Accuracy of 0.47168\n","Epoch 20 : Train Loss of 1.03246 ; Valid Loss of 2.12131 ; Accuracy of 0.47461\n","Epoch 21 : Train Loss of 1.03784 ; Valid Loss of 2.15741 ; Accuracy of 0.46973\n","Epoch 22 : Train Loss of 1.02053 ; Valid Loss of 2.11960 ; Accuracy of 0.47559\n","Epoch 23 : Train Loss of 1.02592 ; Valid Loss of 2.13849 ; Accuracy of 0.46777\n","Epoch 24 : Train Loss of 1.01911 ; Valid Loss of 2.13647 ; Accuracy of 0.47656\n","Epoch 25 : Train Loss of 1.00330 ; Valid Loss of 2.13166 ; Accuracy of 0.47168\n","Epoch 26 : Train Loss of 1.00898 ; Valid Loss of 2.10992 ; Accuracy of 0.48340\n","Epoch 27 : Train Loss of 1.00470 ; Valid Loss of 2.11878 ; Accuracy of 0.47949\n","Epoch 28 : Train Loss of 0.99591 ; Valid Loss of 2.06297 ; Accuracy of 0.47363\n","Epoch 29 : Train Loss of 0.99489 ; Valid Loss of 2.14848 ; Accuracy of 0.46191\n","Epoch 30 : Train Loss of 0.99275 ; Valid Loss of 2.09176 ; Accuracy of 0.47852\n","Epoch 31 : Train Loss of 0.98223 ; Valid Loss of 2.14727 ; Accuracy of 0.47461\n","Epoch 32 : Train Loss of 0.98079 ; Valid Loss of 2.09074 ; Accuracy of 0.48926\n","Epoch 33 : Train Loss of 0.97848 ; Valid Loss of 2.10523 ; Accuracy of 0.49121\n","Epoch 34 : Train Loss of 0.97786 ; Valid Loss of 2.07889 ; Accuracy of 0.48633\n","Epoch 35 : Train Loss of 0.97157 ; Valid Loss of 2.07915 ; Accuracy of 0.48242\n","Epoch 36 : Train Loss of 0.96880 ; Valid Loss of 2.12633 ; Accuracy of 0.47949\n","Epoch 37 : Train Loss of 0.96475 ; Valid Loss of 2.13046 ; Accuracy of 0.48438\n","Epoch 38 : Train Loss of 0.95897 ; Valid Loss of 2.11985 ; Accuracy of 0.48633\n","Epoch 39 : Train Loss of 0.95043 ; Valid Loss of 2.14763 ; Accuracy of 0.47168\n","Epoch 40 : Train Loss of 0.95182 ; Valid Loss of 2.09285 ; Accuracy of 0.49707\n","Epoch 41 : Train Loss of 0.95264 ; Valid Loss of 2.11883 ; Accuracy of 0.48340\n","Epoch 42 : Train Loss of 0.94604 ; Valid Loss of 2.04333 ; Accuracy of 0.49219\n","Epoch 43 : Train Loss of 0.94102 ; Valid Loss of 2.10445 ; Accuracy of 0.48926\n","Epoch 44 : Train Loss of 0.93980 ; Valid Loss of 2.08922 ; Accuracy of 0.48730\n","Epoch 45 : Train Loss of 0.95038 ; Valid Loss of 2.12575 ; Accuracy of 0.48242\n","Epoch 46 : Train Loss of 0.92762 ; Valid Loss of 2.06868 ; Accuracy of 0.49316\n","Epoch 47 : Train Loss of 0.93030 ; Valid Loss of 2.09620 ; Accuracy of 0.48535\n","Epoch 48 : Train Loss of 0.93310 ; Valid Loss of 2.11542 ; Accuracy of 0.48730\n","Epoch 49 : Train Loss of 0.93107 ; Valid Loss of 2.14657 ; Accuracy of 0.48633\n","Epoch 50 : Train Loss of 0.93050 ; Valid Loss of 2.10815 ; Accuracy of 0.50098\n","Epoch 51 : Train Loss of 0.92249 ; Valid Loss of 2.13002 ; Accuracy of 0.48828\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0ece80>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.49905\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0ec4e0>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.50443 ; Valid Loss of 1.69723 ; Accuracy of 0.55566\n","Epoch 2 : Train Loss of 1.33354 ; Valid Loss of 1.76140 ; Accuracy of 0.52930\n","Epoch 3 : Train Loss of 1.26419 ; Valid Loss of 1.75499 ; Accuracy of 0.52637\n","Epoch 4 : Train Loss of 1.24701 ; Valid Loss of 1.73221 ; Accuracy of 0.52734\n","Epoch 5 : Train Loss of 1.22542 ; Valid Loss of 1.80278 ; Accuracy of 0.50781\n","Epoch 6 : Train Loss of 1.20172 ; Valid Loss of 1.82098 ; Accuracy of 0.50879\n","Epoch 7 : Train Loss of 1.18987 ; Valid Loss of 1.80743 ; Accuracy of 0.52051\n","Epoch 8 : Train Loss of 1.17587 ; Valid Loss of 1.81605 ; Accuracy of 0.50098\n","Epoch 9 : Train Loss of 1.15480 ; Valid Loss of 1.84175 ; Accuracy of 0.51172\n","Epoch 10 : Train Loss of 1.13848 ; Valid Loss of 1.80943 ; Accuracy of 0.50879\n","Epoch 11 : Train Loss of 1.12555 ; Valid Loss of 1.83551 ; Accuracy of 0.50195\n","Epoch 12 : Train Loss of 1.11885 ; Valid Loss of 1.82568 ; Accuracy of 0.50977\n","Epoch 13 : Train Loss of 1.10790 ; Valid Loss of 1.83979 ; Accuracy of 0.50000\n","Epoch 14 : Train Loss of 1.09961 ; Valid Loss of 1.82466 ; Accuracy of 0.50879\n","Epoch 15 : Train Loss of 1.09496 ; Valid Loss of 1.85026 ; Accuracy of 0.50684\n","Epoch 16 : Train Loss of 1.09234 ; Valid Loss of 1.85330 ; Accuracy of 0.51367\n","Epoch 17 : Train Loss of 1.07667 ; Valid Loss of 1.87624 ; Accuracy of 0.50488\n","Epoch 18 : Train Loss of 1.07049 ; Valid Loss of 1.89528 ; Accuracy of 0.49805\n","Epoch 19 : Train Loss of 1.07363 ; Valid Loss of 1.87760 ; Accuracy of 0.49902\n","Epoch 20 : Train Loss of 1.05895 ; Valid Loss of 1.89309 ; Accuracy of 0.49609\n","Epoch 21 : Train Loss of 1.06178 ; Valid Loss of 1.80870 ; Accuracy of 0.51074\n","Epoch 22 : Train Loss of 1.04813 ; Valid Loss of 1.82717 ; Accuracy of 0.50977\n","Epoch 23 : Train Loss of 1.03350 ; Valid Loss of 1.86053 ; Accuracy of 0.51172\n","Epoch 24 : Train Loss of 1.03435 ; Valid Loss of 1.84069 ; Accuracy of 0.50977\n","Epoch 25 : Train Loss of 1.03126 ; Valid Loss of 1.85683 ; Accuracy of 0.51270\n","Epoch 26 : Train Loss of 1.02784 ; Valid Loss of 1.89090 ; Accuracy of 0.51660\n","Epoch 27 : Train Loss of 1.01715 ; Valid Loss of 1.88888 ; Accuracy of 0.51172\n","Epoch 28 : Train Loss of 1.01799 ; Valid Loss of 1.88631 ; Accuracy of 0.51562\n","Epoch 29 : Train Loss of 1.01597 ; Valid Loss of 1.89014 ; Accuracy of 0.51172\n","Epoch 30 : Train Loss of 1.01162 ; Valid Loss of 1.91616 ; Accuracy of 0.50488\n","Epoch 31 : Train Loss of 1.00514 ; Valid Loss of 1.87541 ; Accuracy of 0.51465\n","Epoch 32 : Train Loss of 0.99706 ; Valid Loss of 1.85690 ; Accuracy of 0.51758\n","Epoch 33 : Train Loss of 0.98741 ; Valid Loss of 1.89435 ; Accuracy of 0.51367\n","Epoch 34 : Train Loss of 0.98987 ; Valid Loss of 1.84104 ; Accuracy of 0.51172\n","Epoch 35 : Train Loss of 0.99155 ; Valid Loss of 1.86749 ; Accuracy of 0.52246\n","Epoch 36 : Train Loss of 0.99339 ; Valid Loss of 1.91278 ; Accuracy of 0.51074\n","Epoch 37 : Train Loss of 0.98067 ; Valid Loss of 1.91785 ; Accuracy of 0.50879\n","Epoch 38 : Train Loss of 0.97713 ; Valid Loss of 1.90051 ; Accuracy of 0.51660\n","Epoch 39 : Train Loss of 0.95856 ; Valid Loss of 1.91290 ; Accuracy of 0.51465\n","Epoch 40 : Train Loss of 0.97433 ; Valid Loss of 1.86098 ; Accuracy of 0.52051\n","Epoch 41 : Train Loss of 0.97359 ; Valid Loss of 1.91507 ; Accuracy of 0.51367\n","Epoch 42 : Train Loss of 0.96938 ; Valid Loss of 1.90327 ; Accuracy of 0.50391\n","Epoch 43 : Train Loss of 0.96426 ; Valid Loss of 1.94852 ; Accuracy of 0.51660\n","Epoch 44 : Train Loss of 0.95918 ; Valid Loss of 1.89401 ; Accuracy of 0.50879\n","Epoch 45 : Train Loss of 0.95835 ; Valid Loss of 1.94422 ; Accuracy of 0.50781\n","Epoch 46 : Train Loss of 0.94771 ; Valid Loss of 1.91867 ; Accuracy of 0.51855\n","Epoch 47 : Train Loss of 0.94685 ; Valid Loss of 1.90523 ; Accuracy of 0.52539\n","Epoch 48 : Train Loss of 0.94724 ; Valid Loss of 1.93640 ; Accuracy of 0.50977\n","Epoch 49 : Train Loss of 0.93997 ; Valid Loss of 1.89045 ; Accuracy of 0.51270\n","Epoch 50 : Train Loss of 0.94542 ; Valid Loss of 1.89726 ; Accuracy of 0.50098\n","Epoch 51 : Train Loss of 0.93954 ; Valid Loss of 1.90361 ; Accuracy of 0.52051\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0eca58>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.42742\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d779710>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.52929 ; Valid Loss of 1.57161 ; Accuracy of 0.50781\n","Epoch 2 : Train Loss of 1.32607 ; Valid Loss of 1.67397 ; Accuracy of 0.51855\n","Epoch 3 : Train Loss of 1.25219 ; Valid Loss of 1.69966 ; Accuracy of 0.51562\n","Epoch 4 : Train Loss of 1.22825 ; Valid Loss of 1.72219 ; Accuracy of 0.50195\n","Epoch 5 : Train Loss of 1.20137 ; Valid Loss of 1.71022 ; Accuracy of 0.51270\n","Epoch 6 : Train Loss of 1.19342 ; Valid Loss of 1.78601 ; Accuracy of 0.49512\n","Epoch 7 : Train Loss of 1.15856 ; Valid Loss of 1.76460 ; Accuracy of 0.50781\n","Epoch 8 : Train Loss of 1.14465 ; Valid Loss of 1.78739 ; Accuracy of 0.50488\n","Epoch 9 : Train Loss of 1.14038 ; Valid Loss of 1.84374 ; Accuracy of 0.48633\n","Epoch 10 : Train Loss of 1.12547 ; Valid Loss of 1.82032 ; Accuracy of 0.50488\n","Epoch 11 : Train Loss of 1.12082 ; Valid Loss of 1.83518 ; Accuracy of 0.49414\n","Epoch 12 : Train Loss of 1.09767 ; Valid Loss of 1.80693 ; Accuracy of 0.49316\n","Epoch 13 : Train Loss of 1.09070 ; Valid Loss of 1.83567 ; Accuracy of 0.50293\n","Epoch 14 : Train Loss of 1.09124 ; Valid Loss of 1.82998 ; Accuracy of 0.50781\n","Epoch 15 : Train Loss of 1.06943 ; Valid Loss of 1.86145 ; Accuracy of 0.48730\n","Epoch 16 : Train Loss of 1.07206 ; Valid Loss of 1.87570 ; Accuracy of 0.49219\n","Epoch 17 : Train Loss of 1.05704 ; Valid Loss of 1.83898 ; Accuracy of 0.50098\n","Epoch 18 : Train Loss of 1.05531 ; Valid Loss of 1.84743 ; Accuracy of 0.50293\n","Epoch 19 : Train Loss of 1.04552 ; Valid Loss of 1.86538 ; Accuracy of 0.49316\n","Epoch 20 : Train Loss of 1.03883 ; Valid Loss of 1.84924 ; Accuracy of 0.49707\n","Epoch 21 : Train Loss of 1.04276 ; Valid Loss of 1.89514 ; Accuracy of 0.48730\n","Epoch 22 : Train Loss of 1.03189 ; Valid Loss of 1.85056 ; Accuracy of 0.49316\n","Epoch 23 : Train Loss of 1.02542 ; Valid Loss of 1.86192 ; Accuracy of 0.49023\n","Epoch 24 : Train Loss of 1.01462 ; Valid Loss of 1.89110 ; Accuracy of 0.49609\n","Epoch 25 : Train Loss of 1.01942 ; Valid Loss of 1.81582 ; Accuracy of 0.49609\n","Epoch 26 : Train Loss of 1.00991 ; Valid Loss of 1.87558 ; Accuracy of 0.49707\n","Epoch 27 : Train Loss of 1.00699 ; Valid Loss of 1.86772 ; Accuracy of 0.50195\n","Epoch 28 : Train Loss of 1.00170 ; Valid Loss of 1.89774 ; Accuracy of 0.48633\n","Epoch 29 : Train Loss of 0.99807 ; Valid Loss of 1.87822 ; Accuracy of 0.49902\n","Epoch 30 : Train Loss of 0.99868 ; Valid Loss of 1.86546 ; Accuracy of 0.49512\n","Epoch 31 : Train Loss of 0.98883 ; Valid Loss of 1.84882 ; Accuracy of 0.50293\n","Epoch 32 : Train Loss of 0.98556 ; Valid Loss of 1.87601 ; Accuracy of 0.49023\n","Epoch 33 : Train Loss of 0.97920 ; Valid Loss of 1.86682 ; Accuracy of 0.50195\n","Epoch 34 : Train Loss of 0.98088 ; Valid Loss of 1.85779 ; Accuracy of 0.49609\n","Epoch 35 : Train Loss of 0.97132 ; Valid Loss of 1.90554 ; Accuracy of 0.48926\n","Epoch 36 : Train Loss of 0.97035 ; Valid Loss of 1.88653 ; Accuracy of 0.50000\n","Epoch 37 : Train Loss of 0.96616 ; Valid Loss of 1.89083 ; Accuracy of 0.49512\n","Epoch 38 : Train Loss of 0.95652 ; Valid Loss of 1.87083 ; Accuracy of 0.50293\n","Epoch 39 : Train Loss of 0.95905 ; Valid Loss of 1.91616 ; Accuracy of 0.48926\n","Epoch 40 : Train Loss of 0.95713 ; Valid Loss of 1.87303 ; Accuracy of 0.50098\n","Epoch 41 : Train Loss of 0.95227 ; Valid Loss of 1.87501 ; Accuracy of 0.50195\n","Epoch 42 : Train Loss of 0.95754 ; Valid Loss of 1.90013 ; Accuracy of 0.48828\n","Epoch 43 : Train Loss of 0.94583 ; Valid Loss of 1.91493 ; Accuracy of 0.49609\n","Epoch 44 : Train Loss of 0.94876 ; Valid Loss of 1.90093 ; Accuracy of 0.49219\n","Epoch 45 : Train Loss of 0.94180 ; Valid Loss of 1.90941 ; Accuracy of 0.50195\n","Epoch 46 : Train Loss of 0.93312 ; Valid Loss of 1.90633 ; Accuracy of 0.49805\n","Epoch 47 : Train Loss of 0.94098 ; Valid Loss of 1.91346 ; Accuracy of 0.49707\n","Epoch 48 : Train Loss of 0.93385 ; Valid Loss of 1.93577 ; Accuracy of 0.48730\n","Epoch 49 : Train Loss of 0.93414 ; Valid Loss of 1.90051 ; Accuracy of 0.49512\n","Epoch 50 : Train Loss of 0.92709 ; Valid Loss of 1.89666 ; Accuracy of 0.50195\n","Epoch 51 : Train Loss of 0.92874 ; Valid Loss of 1.94418 ; Accuracy of 0.48633\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d779908>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.44723\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c2080>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.49522 ; Valid Loss of 1.64035 ; Accuracy of 0.52539\n","Epoch 2 : Train Loss of 1.32033 ; Valid Loss of 1.68281 ; Accuracy of 0.52637\n","Epoch 3 : Train Loss of 1.26295 ; Valid Loss of 1.75409 ; Accuracy of 0.52051\n","Epoch 4 : Train Loss of 1.22079 ; Valid Loss of 1.73578 ; Accuracy of 0.51465\n","Epoch 5 : Train Loss of 1.19459 ; Valid Loss of 1.78460 ; Accuracy of 0.51758\n","Epoch 6 : Train Loss of 1.17826 ; Valid Loss of 1.75656 ; Accuracy of 0.51465\n","Epoch 7 : Train Loss of 1.15560 ; Valid Loss of 1.76880 ; Accuracy of 0.51660\n","Epoch 8 : Train Loss of 1.14433 ; Valid Loss of 1.77031 ; Accuracy of 0.50391\n","Epoch 9 : Train Loss of 1.14092 ; Valid Loss of 1.80220 ; Accuracy of 0.52148\n","Epoch 10 : Train Loss of 1.13041 ; Valid Loss of 1.78861 ; Accuracy of 0.52344\n","Epoch 11 : Train Loss of 1.11214 ; Valid Loss of 1.76828 ; Accuracy of 0.52246\n","Epoch 12 : Train Loss of 1.09822 ; Valid Loss of 1.78628 ; Accuracy of 0.52051\n","Epoch 13 : Train Loss of 1.09605 ; Valid Loss of 1.77440 ; Accuracy of 0.52148\n","Epoch 14 : Train Loss of 1.07741 ; Valid Loss of 1.77319 ; Accuracy of 0.51465\n","Epoch 15 : Train Loss of 1.07995 ; Valid Loss of 1.78496 ; Accuracy of 0.51172\n","Epoch 16 : Train Loss of 1.06688 ; Valid Loss of 1.77609 ; Accuracy of 0.51465\n","Epoch 17 : Train Loss of 1.05963 ; Valid Loss of 1.79120 ; Accuracy of 0.50977\n","Epoch 18 : Train Loss of 1.04637 ; Valid Loss of 1.79298 ; Accuracy of 0.50391\n","Epoch 19 : Train Loss of 1.04861 ; Valid Loss of 1.78275 ; Accuracy of 0.51660\n","Epoch 20 : Train Loss of 1.04323 ; Valid Loss of 1.82221 ; Accuracy of 0.50488\n","Epoch 21 : Train Loss of 1.02929 ; Valid Loss of 1.81711 ; Accuracy of 0.50879\n","Epoch 22 : Train Loss of 1.02998 ; Valid Loss of 1.81355 ; Accuracy of 0.50977\n","Epoch 23 : Train Loss of 1.02973 ; Valid Loss of 1.78838 ; Accuracy of 0.51367\n","Epoch 24 : Train Loss of 1.02076 ; Valid Loss of 1.80854 ; Accuracy of 0.51465\n","Epoch 25 : Train Loss of 1.01123 ; Valid Loss of 1.77865 ; Accuracy of 0.51562\n","Epoch 26 : Train Loss of 1.00735 ; Valid Loss of 1.79946 ; Accuracy of 0.52539\n","Epoch 27 : Train Loss of 1.00700 ; Valid Loss of 1.76192 ; Accuracy of 0.51660\n","Epoch 28 : Train Loss of 1.00537 ; Valid Loss of 1.78695 ; Accuracy of 0.52637\n","Epoch 29 : Train Loss of 0.99999 ; Valid Loss of 1.84102 ; Accuracy of 0.49902\n","Epoch 30 : Train Loss of 0.98583 ; Valid Loss of 1.79985 ; Accuracy of 0.51270\n","Epoch 31 : Train Loss of 0.98554 ; Valid Loss of 1.84277 ; Accuracy of 0.50781\n","Epoch 32 : Train Loss of 0.98225 ; Valid Loss of 1.78675 ; Accuracy of 0.51562\n","Epoch 33 : Train Loss of 0.96688 ; Valid Loss of 1.78495 ; Accuracy of 0.51270\n","Epoch 34 : Train Loss of 0.98242 ; Valid Loss of 1.83370 ; Accuracy of 0.50879\n","Epoch 35 : Train Loss of 0.96685 ; Valid Loss of 1.84924 ; Accuracy of 0.49902\n","Epoch 36 : Train Loss of 0.97193 ; Valid Loss of 1.83559 ; Accuracy of 0.50098\n","Epoch 37 : Train Loss of 0.97098 ; Valid Loss of 1.81363 ; Accuracy of 0.50391\n","Epoch 38 : Train Loss of 0.96174 ; Valid Loss of 1.83495 ; Accuracy of 0.50586\n","Epoch 39 : Train Loss of 0.96430 ; Valid Loss of 1.79454 ; Accuracy of 0.51562\n","Epoch 40 : Train Loss of 0.95644 ; Valid Loss of 1.82414 ; Accuracy of 0.50684\n","Epoch 41 : Train Loss of 0.94530 ; Valid Loss of 1.85822 ; Accuracy of 0.50195\n","Epoch 42 : Train Loss of 0.94392 ; Valid Loss of 1.82130 ; Accuracy of 0.50977\n","Epoch 43 : Train Loss of 0.94593 ; Valid Loss of 1.79544 ; Accuracy of 0.51953\n","Epoch 44 : Train Loss of 0.93588 ; Valid Loss of 1.83561 ; Accuracy of 0.51074\n","Epoch 45 : Train Loss of 0.94214 ; Valid Loss of 1.79876 ; Accuracy of 0.51172\n","Epoch 46 : Train Loss of 0.93948 ; Valid Loss of 1.85569 ; Accuracy of 0.50684\n","Epoch 47 : Train Loss of 0.94129 ; Valid Loss of 1.80558 ; Accuracy of 0.51074\n","Epoch 48 : Train Loss of 0.93237 ; Valid Loss of 1.81582 ; Accuracy of 0.52539\n","Epoch 49 : Train Loss of 0.92777 ; Valid Loss of 1.86643 ; Accuracy of 0.50781\n","Epoch 50 : Train Loss of 0.92497 ; Valid Loss of 1.86082 ; Accuracy of 0.50977\n","Epoch 51 : Train Loss of 0.92234 ; Valid Loss of 1.81346 ; Accuracy of 0.52539\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e9080>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.50596\n","Proportion of 1 is for train set is : 0.25541988537253923\n","Proportion of 1 is for valid set is : 0.618421052631579\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e9588>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.61257 ; Valid Loss of 1.45511 ; Accuracy of 0.52832\n","Epoch 2 : Train Loss of 1.39624 ; Valid Loss of 1.49180 ; Accuracy of 0.53516\n","Epoch 3 : Train Loss of 1.30992 ; Valid Loss of 1.52848 ; Accuracy of 0.54102\n","Epoch 4 : Train Loss of 1.28896 ; Valid Loss of 1.55251 ; Accuracy of 0.53223\n","Epoch 5 : Train Loss of 1.25590 ; Valid Loss of 1.58112 ; Accuracy of 0.52930\n","Epoch 6 : Train Loss of 1.24258 ; Valid Loss of 1.63709 ; Accuracy of 0.53223\n","Epoch 7 : Train Loss of 1.21365 ; Valid Loss of 1.62123 ; Accuracy of 0.52832\n","Epoch 8 : Train Loss of 1.18822 ; Valid Loss of 1.63873 ; Accuracy of 0.52734\n","Epoch 9 : Train Loss of 1.17906 ; Valid Loss of 1.67255 ; Accuracy of 0.51465\n","Epoch 10 : Train Loss of 1.17056 ; Valid Loss of 1.64066 ; Accuracy of 0.51660\n","Epoch 11 : Train Loss of 1.15662 ; Valid Loss of 1.69723 ; Accuracy of 0.51172\n","Epoch 12 : Train Loss of 1.14275 ; Valid Loss of 1.68780 ; Accuracy of 0.52246\n","Epoch 13 : Train Loss of 1.14596 ; Valid Loss of 1.69860 ; Accuracy of 0.51953\n","Epoch 14 : Train Loss of 1.12714 ; Valid Loss of 1.72618 ; Accuracy of 0.50098\n","Epoch 15 : Train Loss of 1.11327 ; Valid Loss of 1.73013 ; Accuracy of 0.50586\n","Epoch 16 : Train Loss of 1.09785 ; Valid Loss of 1.71041 ; Accuracy of 0.51953\n","Epoch 17 : Train Loss of 1.09825 ; Valid Loss of 1.76803 ; Accuracy of 0.50098\n","Epoch 18 : Train Loss of 1.09493 ; Valid Loss of 1.71984 ; Accuracy of 0.50977\n","Epoch 19 : Train Loss of 1.07851 ; Valid Loss of 1.74348 ; Accuracy of 0.51172\n","Epoch 20 : Train Loss of 1.06874 ; Valid Loss of 1.76616 ; Accuracy of 0.49902\n","Epoch 21 : Train Loss of 1.06617 ; Valid Loss of 1.75628 ; Accuracy of 0.50781\n","Epoch 22 : Train Loss of 1.05798 ; Valid Loss of 1.77210 ; Accuracy of 0.49316\n","Epoch 23 : Train Loss of 1.05418 ; Valid Loss of 1.80824 ; Accuracy of 0.48633\n","Epoch 24 : Train Loss of 1.05759 ; Valid Loss of 1.82505 ; Accuracy of 0.48047\n","Epoch 25 : Train Loss of 1.03984 ; Valid Loss of 1.74175 ; Accuracy of 0.50684\n","Epoch 26 : Train Loss of 1.04113 ; Valid Loss of 1.80435 ; Accuracy of 0.49121\n","Epoch 27 : Train Loss of 1.02721 ; Valid Loss of 1.78373 ; Accuracy of 0.49316\n","Epoch 28 : Train Loss of 1.03156 ; Valid Loss of 1.76790 ; Accuracy of 0.49805\n","Epoch 29 : Train Loss of 1.02866 ; Valid Loss of 1.83126 ; Accuracy of 0.49121\n","Epoch 30 : Train Loss of 1.01196 ; Valid Loss of 1.81492 ; Accuracy of 0.49512\n","Epoch 31 : Train Loss of 1.00757 ; Valid Loss of 1.80760 ; Accuracy of 0.49512\n","Epoch 32 : Train Loss of 1.01073 ; Valid Loss of 1.77740 ; Accuracy of 0.50098\n","Epoch 33 : Train Loss of 1.00892 ; Valid Loss of 1.81217 ; Accuracy of 0.49219\n","Epoch 34 : Train Loss of 1.00357 ; Valid Loss of 1.74174 ; Accuracy of 0.50684\n","Epoch 35 : Train Loss of 1.00490 ; Valid Loss of 1.78486 ; Accuracy of 0.50098\n","Epoch 36 : Train Loss of 0.99862 ; Valid Loss of 1.84108 ; Accuracy of 0.48242\n","Epoch 37 : Train Loss of 1.00485 ; Valid Loss of 1.79331 ; Accuracy of 0.50195\n","Epoch 38 : Train Loss of 0.99224 ; Valid Loss of 1.80197 ; Accuracy of 0.50000\n","Epoch 39 : Train Loss of 0.98369 ; Valid Loss of 1.80700 ; Accuracy of 0.49414\n","Epoch 40 : Train Loss of 0.97700 ; Valid Loss of 1.79404 ; Accuracy of 0.49316\n","Epoch 41 : Train Loss of 0.98128 ; Valid Loss of 1.81496 ; Accuracy of 0.49902\n","Epoch 42 : Train Loss of 0.96965 ; Valid Loss of 1.81054 ; Accuracy of 0.50586\n","Epoch 43 : Train Loss of 0.96516 ; Valid Loss of 1.87618 ; Accuracy of 0.49707\n","Epoch 44 : Train Loss of 0.97567 ; Valid Loss of 1.76916 ; Accuracy of 0.52246\n","Epoch 45 : Train Loss of 0.97195 ; Valid Loss of 1.78519 ; Accuracy of 0.51270\n","Epoch 46 : Train Loss of 0.96161 ; Valid Loss of 1.81682 ; Accuracy of 0.50000\n","Epoch 47 : Train Loss of 0.95371 ; Valid Loss of 1.79578 ; Accuracy of 0.51367\n","Epoch 48 : Train Loss of 0.95639 ; Valid Loss of 1.81733 ; Accuracy of 0.50391\n","Epoch 49 : Train Loss of 0.95149 ; Valid Loss of 1.76819 ; Accuracy of 0.51172\n","Epoch 50 : Train Loss of 0.94527 ; Valid Loss of 1.83461 ; Accuracy of 0.50391\n","Epoch 51 : Train Loss of 0.94531 ; Valid Loss of 1.84145 ; Accuracy of 0.50098\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e9978>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.49894\n","Running Threshold 217\n","Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='total_10-06-20_512_256_lr_6e-4', lr=0.0005, model='total', production=1, save_processed_data=0, swa=0, threshold=217)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea55ac8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.50112 ; Valid Loss of 1.78224 ; Accuracy of 0.50977\n","Epoch 2 : Train Loss of 1.35259 ; Valid Loss of 1.83778 ; Accuracy of 0.50684\n","Epoch 3 : Train Loss of 1.28711 ; Valid Loss of 1.90189 ; Accuracy of 0.49219\n","Epoch 4 : Train Loss of 1.25071 ; Valid Loss of 1.92704 ; Accuracy of 0.50000\n","Epoch 5 : Train Loss of 1.23884 ; Valid Loss of 1.92602 ; Accuracy of 0.49805\n","Epoch 6 : Train Loss of 1.21749 ; Valid Loss of 1.95179 ; Accuracy of 0.49121\n","Epoch 7 : Train Loss of 1.19588 ; Valid Loss of 1.97908 ; Accuracy of 0.49219\n","Epoch 8 : Train Loss of 1.19566 ; Valid Loss of 1.96218 ; Accuracy of 0.48730\n","Epoch 9 : Train Loss of 1.17172 ; Valid Loss of 1.96659 ; Accuracy of 0.50098\n","Epoch 10 : Train Loss of 1.17101 ; Valid Loss of 1.95614 ; Accuracy of 0.50098\n","Epoch 11 : Train Loss of 1.14648 ; Valid Loss of 1.97831 ; Accuracy of 0.50488\n","Epoch 12 : Train Loss of 1.13807 ; Valid Loss of 2.00315 ; Accuracy of 0.49219\n","Epoch 13 : Train Loss of 1.12878 ; Valid Loss of 1.97869 ; Accuracy of 0.50977\n","Epoch 14 : Train Loss of 1.11967 ; Valid Loss of 1.97296 ; Accuracy of 0.50293\n","Epoch 15 : Train Loss of 1.11395 ; Valid Loss of 2.03695 ; Accuracy of 0.49219\n","Epoch 16 : Train Loss of 1.10656 ; Valid Loss of 1.98443 ; Accuracy of 0.50391\n","Epoch 17 : Train Loss of 1.09116 ; Valid Loss of 2.01708 ; Accuracy of 0.50195\n","Epoch 18 : Train Loss of 1.08119 ; Valid Loss of 1.98842 ; Accuracy of 0.50488\n","Epoch 19 : Train Loss of 1.09441 ; Valid Loss of 2.00673 ; Accuracy of 0.50293\n","Epoch 20 : Train Loss of 1.08001 ; Valid Loss of 2.01278 ; Accuracy of 0.50293\n","Epoch 21 : Train Loss of 1.05725 ; Valid Loss of 2.02314 ; Accuracy of 0.50098\n","Epoch 22 : Train Loss of 1.06420 ; Valid Loss of 2.00733 ; Accuracy of 0.50781\n","Epoch 23 : Train Loss of 1.06221 ; Valid Loss of 2.00975 ; Accuracy of 0.50000\n","Epoch 24 : Train Loss of 1.05499 ; Valid Loss of 1.98468 ; Accuracy of 0.51270\n","Epoch 25 : Train Loss of 1.05382 ; Valid Loss of 1.99564 ; Accuracy of 0.51074\n","Epoch 26 : Train Loss of 1.04712 ; Valid Loss of 1.96056 ; Accuracy of 0.49805\n","Epoch 27 : Train Loss of 1.04149 ; Valid Loss of 1.98375 ; Accuracy of 0.50391\n","Epoch 28 : Train Loss of 1.02874 ; Valid Loss of 2.00055 ; Accuracy of 0.49902\n","Epoch 29 : Train Loss of 1.02221 ; Valid Loss of 2.02848 ; Accuracy of 0.49609\n","Epoch 30 : Train Loss of 1.01453 ; Valid Loss of 2.02002 ; Accuracy of 0.50488\n","Epoch 31 : Train Loss of 1.02386 ; Valid Loss of 2.02878 ; Accuracy of 0.50195\n","Epoch 32 : Train Loss of 1.01730 ; Valid Loss of 2.02786 ; Accuracy of 0.51172\n","Epoch 33 : Train Loss of 1.00351 ; Valid Loss of 1.99148 ; Accuracy of 0.51367\n","Epoch 34 : Train Loss of 0.99850 ; Valid Loss of 2.00523 ; Accuracy of 0.50977\n","Epoch 35 : Train Loss of 1.00837 ; Valid Loss of 2.03202 ; Accuracy of 0.51367\n","Epoch 36 : Train Loss of 1.00987 ; Valid Loss of 2.01178 ; Accuracy of 0.50977\n","Epoch 37 : Train Loss of 0.99117 ; Valid Loss of 2.06761 ; Accuracy of 0.51074\n","Epoch 38 : Train Loss of 0.99750 ; Valid Loss of 2.03581 ; Accuracy of 0.51465\n","Epoch 39 : Train Loss of 0.98260 ; Valid Loss of 2.05607 ; Accuracy of 0.51172\n","Epoch 40 : Train Loss of 0.98303 ; Valid Loss of 2.07087 ; Accuracy of 0.50098\n","Epoch 41 : Train Loss of 0.98131 ; Valid Loss of 2.02332 ; Accuracy of 0.50879\n","Epoch 42 : Train Loss of 0.98191 ; Valid Loss of 2.06161 ; Accuracy of 0.50977\n","Epoch 43 : Train Loss of 0.96942 ; Valid Loss of 2.08223 ; Accuracy of 0.51074\n","Epoch 44 : Train Loss of 0.96861 ; Valid Loss of 1.99484 ; Accuracy of 0.51270\n","Epoch 45 : Train Loss of 0.97033 ; Valid Loss of 2.04674 ; Accuracy of 0.50977\n","Epoch 46 : Train Loss of 0.96339 ; Valid Loss of 2.06372 ; Accuracy of 0.50000\n","Epoch 47 : Train Loss of 0.96742 ; Valid Loss of 2.00853 ; Accuracy of 0.51465\n","Epoch 48 : Train Loss of 0.95544 ; Valid Loss of 2.01792 ; Accuracy of 0.51660\n","Epoch 49 : Train Loss of 0.95737 ; Valid Loss of 2.01624 ; Accuracy of 0.50977\n","Epoch 50 : Train Loss of 0.95367 ; Valid Loss of 2.01741 ; Accuracy of 0.51270\n","Epoch 51 : Train Loss of 0.95796 ; Valid Loss of 2.08216 ; Accuracy of 0.49902\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97e3e10>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.55648\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97e3d68>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.52256 ; Valid Loss of 1.78715 ; Accuracy of 0.49219\n","Epoch 2 : Train Loss of 1.34171 ; Valid Loss of 1.87178 ; Accuracy of 0.49414\n","Epoch 3 : Train Loss of 1.29074 ; Valid Loss of 1.95842 ; Accuracy of 0.47754\n","Epoch 4 : Train Loss of 1.24257 ; Valid Loss of 1.98667 ; Accuracy of 0.49902\n","Epoch 5 : Train Loss of 1.22927 ; Valid Loss of 1.99244 ; Accuracy of 0.50098\n","Epoch 6 : Train Loss of 1.20225 ; Valid Loss of 2.02738 ; Accuracy of 0.49512\n","Epoch 7 : Train Loss of 1.18678 ; Valid Loss of 2.03330 ; Accuracy of 0.48828\n","Epoch 8 : Train Loss of 1.17317 ; Valid Loss of 2.04892 ; Accuracy of 0.48438\n","Epoch 9 : Train Loss of 1.15788 ; Valid Loss of 2.07082 ; Accuracy of 0.49316\n","Epoch 10 : Train Loss of 1.14378 ; Valid Loss of 2.07888 ; Accuracy of 0.48926\n","Epoch 11 : Train Loss of 1.14056 ; Valid Loss of 2.07000 ; Accuracy of 0.49121\n","Epoch 12 : Train Loss of 1.12801 ; Valid Loss of 2.12411 ; Accuracy of 0.49121\n","Epoch 13 : Train Loss of 1.12184 ; Valid Loss of 2.07312 ; Accuracy of 0.48730\n","Epoch 14 : Train Loss of 1.11440 ; Valid Loss of 2.06817 ; Accuracy of 0.49219\n","Epoch 15 : Train Loss of 1.09436 ; Valid Loss of 2.14600 ; Accuracy of 0.48340\n","Epoch 16 : Train Loss of 1.09536 ; Valid Loss of 2.07813 ; Accuracy of 0.49121\n","Epoch 17 : Train Loss of 1.07759 ; Valid Loss of 2.11574 ; Accuracy of 0.48926\n","Epoch 18 : Train Loss of 1.07648 ; Valid Loss of 2.09726 ; Accuracy of 0.48047\n","Epoch 19 : Train Loss of 1.05611 ; Valid Loss of 2.16345 ; Accuracy of 0.47363\n","Epoch 20 : Train Loss of 1.06300 ; Valid Loss of 2.16904 ; Accuracy of 0.48438\n","Epoch 21 : Train Loss of 1.06454 ; Valid Loss of 2.13173 ; Accuracy of 0.48145\n","Epoch 22 : Train Loss of 1.04331 ; Valid Loss of 2.15427 ; Accuracy of 0.47949\n","Epoch 23 : Train Loss of 1.04632 ; Valid Loss of 2.15151 ; Accuracy of 0.47949\n","Epoch 24 : Train Loss of 1.03274 ; Valid Loss of 2.20333 ; Accuracy of 0.46777\n","Epoch 25 : Train Loss of 1.03927 ; Valid Loss of 2.13087 ; Accuracy of 0.47949\n","Epoch 26 : Train Loss of 1.03870 ; Valid Loss of 2.17135 ; Accuracy of 0.47852\n","Epoch 27 : Train Loss of 1.01741 ; Valid Loss of 2.14931 ; Accuracy of 0.48535\n","Epoch 28 : Train Loss of 1.01954 ; Valid Loss of 2.16873 ; Accuracy of 0.47559\n","Epoch 29 : Train Loss of 1.00670 ; Valid Loss of 2.16316 ; Accuracy of 0.47266\n","Epoch 30 : Train Loss of 0.99566 ; Valid Loss of 2.16861 ; Accuracy of 0.48340\n","Epoch 31 : Train Loss of 1.00959 ; Valid Loss of 2.15332 ; Accuracy of 0.47266\n","Epoch 32 : Train Loss of 0.99945 ; Valid Loss of 2.17792 ; Accuracy of 0.47754\n","Epoch 33 : Train Loss of 1.00049 ; Valid Loss of 2.14360 ; Accuracy of 0.48438\n","Epoch 34 : Train Loss of 0.99844 ; Valid Loss of 2.12684 ; Accuracy of 0.48242\n","Epoch 35 : Train Loss of 0.98502 ; Valid Loss of 2.10728 ; Accuracy of 0.48535\n","Epoch 36 : Train Loss of 0.97621 ; Valid Loss of 2.12865 ; Accuracy of 0.48438\n","Epoch 37 : Train Loss of 0.98776 ; Valid Loss of 2.10308 ; Accuracy of 0.49707\n","Epoch 38 : Train Loss of 0.98375 ; Valid Loss of 2.15485 ; Accuracy of 0.48438\n","Epoch 39 : Train Loss of 0.97892 ; Valid Loss of 2.10454 ; Accuracy of 0.49023\n","Epoch 40 : Train Loss of 0.97810 ; Valid Loss of 2.10220 ; Accuracy of 0.49707\n","Epoch 41 : Train Loss of 0.96992 ; Valid Loss of 2.07185 ; Accuracy of 0.50195\n","Epoch 42 : Train Loss of 0.96230 ; Valid Loss of 2.09139 ; Accuracy of 0.50391\n","Epoch 43 : Train Loss of 0.95959 ; Valid Loss of 2.11841 ; Accuracy of 0.49414\n","Epoch 44 : Train Loss of 0.95822 ; Valid Loss of 2.12774 ; Accuracy of 0.49902\n","Epoch 45 : Train Loss of 0.95620 ; Valid Loss of 2.11680 ; Accuracy of 0.49805\n","Epoch 46 : Train Loss of 0.94656 ; Valid Loss of 2.08279 ; Accuracy of 0.49121\n","Epoch 47 : Train Loss of 0.95503 ; Valid Loss of 2.11273 ; Accuracy of 0.49805\n","Epoch 48 : Train Loss of 0.95280 ; Valid Loss of 2.10964 ; Accuracy of 0.50195\n","Epoch 49 : Train Loss of 0.94209 ; Valid Loss of 2.12624 ; Accuracy of 0.49414\n","Epoch 50 : Train Loss of 0.94227 ; Valid Loss of 2.07979 ; Accuracy of 0.50684\n","Epoch 51 : Train Loss of 0.94371 ; Valid Loss of 2.11945 ; Accuracy of 0.49707\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea55400>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.46506\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea55128>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.44327 ; Valid Loss of 1.72937 ; Accuracy of 0.50488\n","Epoch 2 : Train Loss of 1.29736 ; Valid Loss of 1.81029 ; Accuracy of 0.49707\n","Epoch 3 : Train Loss of 1.24206 ; Valid Loss of 1.85552 ; Accuracy of 0.50391\n","Epoch 4 : Train Loss of 1.20692 ; Valid Loss of 1.88390 ; Accuracy of 0.49414\n","Epoch 5 : Train Loss of 1.18764 ; Valid Loss of 1.90611 ; Accuracy of 0.49316\n","Epoch 6 : Train Loss of 1.16410 ; Valid Loss of 1.92168 ; Accuracy of 0.49805\n","Epoch 7 : Train Loss of 1.15253 ; Valid Loss of 1.91322 ; Accuracy of 0.50195\n","Epoch 8 : Train Loss of 1.12379 ; Valid Loss of 1.97051 ; Accuracy of 0.50098\n","Epoch 9 : Train Loss of 1.12174 ; Valid Loss of 1.94255 ; Accuracy of 0.50586\n","Epoch 10 : Train Loss of 1.10964 ; Valid Loss of 1.94036 ; Accuracy of 0.51758\n","Epoch 11 : Train Loss of 1.09465 ; Valid Loss of 1.98699 ; Accuracy of 0.50781\n","Epoch 12 : Train Loss of 1.09281 ; Valid Loss of 1.96035 ; Accuracy of 0.51465\n","Epoch 13 : Train Loss of 1.07972 ; Valid Loss of 1.97640 ; Accuracy of 0.51270\n","Epoch 14 : Train Loss of 1.07592 ; Valid Loss of 1.95149 ; Accuracy of 0.50879\n","Epoch 15 : Train Loss of 1.06440 ; Valid Loss of 1.98415 ; Accuracy of 0.49805\n","Epoch 16 : Train Loss of 1.04987 ; Valid Loss of 1.97882 ; Accuracy of 0.50684\n","Epoch 17 : Train Loss of 1.05414 ; Valid Loss of 1.96781 ; Accuracy of 0.50781\n","Epoch 18 : Train Loss of 1.03741 ; Valid Loss of 2.00289 ; Accuracy of 0.50195\n","Epoch 19 : Train Loss of 1.03104 ; Valid Loss of 1.98903 ; Accuracy of 0.50879\n","Epoch 20 : Train Loss of 1.03783 ; Valid Loss of 1.99752 ; Accuracy of 0.50977\n","Epoch 21 : Train Loss of 1.03427 ; Valid Loss of 2.02673 ; Accuracy of 0.51367\n","Epoch 22 : Train Loss of 1.02280 ; Valid Loss of 1.98079 ; Accuracy of 0.50684\n","Epoch 23 : Train Loss of 1.01869 ; Valid Loss of 2.02332 ; Accuracy of 0.50586\n","Epoch 24 : Train Loss of 1.00224 ; Valid Loss of 1.97052 ; Accuracy of 0.50781\n","Epoch 25 : Train Loss of 1.00871 ; Valid Loss of 1.97755 ; Accuracy of 0.51562\n","Epoch 26 : Train Loss of 1.00250 ; Valid Loss of 2.01282 ; Accuracy of 0.50781\n","Epoch 27 : Train Loss of 0.99368 ; Valid Loss of 2.00032 ; Accuracy of 0.50488\n","Epoch 28 : Train Loss of 0.99789 ; Valid Loss of 1.95423 ; Accuracy of 0.51270\n","Epoch 29 : Train Loss of 0.98996 ; Valid Loss of 2.00835 ; Accuracy of 0.50000\n","Epoch 30 : Train Loss of 0.98188 ; Valid Loss of 1.98793 ; Accuracy of 0.50000\n","Epoch 31 : Train Loss of 0.98064 ; Valid Loss of 1.96348 ; Accuracy of 0.50391\n","Epoch 32 : Train Loss of 0.97740 ; Valid Loss of 2.02245 ; Accuracy of 0.50391\n","Epoch 33 : Train Loss of 0.97534 ; Valid Loss of 2.01460 ; Accuracy of 0.50293\n","Epoch 34 : Train Loss of 0.98515 ; Valid Loss of 1.97659 ; Accuracy of 0.51172\n","Epoch 35 : Train Loss of 0.96325 ; Valid Loss of 2.03067 ; Accuracy of 0.49414\n","Epoch 36 : Train Loss of 0.96661 ; Valid Loss of 1.97098 ; Accuracy of 0.50879\n","Epoch 37 : Train Loss of 0.96275 ; Valid Loss of 2.00328 ; Accuracy of 0.50391\n","Epoch 38 : Train Loss of 0.96796 ; Valid Loss of 1.98895 ; Accuracy of 0.50781\n","Epoch 39 : Train Loss of 0.96190 ; Valid Loss of 1.99561 ; Accuracy of 0.49902\n","Epoch 40 : Train Loss of 0.95698 ; Valid Loss of 2.00753 ; Accuracy of 0.50391\n","Epoch 41 : Train Loss of 0.95503 ; Valid Loss of 2.05641 ; Accuracy of 0.48730\n","Epoch 42 : Train Loss of 0.95272 ; Valid Loss of 2.00456 ; Accuracy of 0.50000\n","Epoch 43 : Train Loss of 0.95015 ; Valid Loss of 2.01869 ; Accuracy of 0.50293\n","Epoch 44 : Train Loss of 0.94355 ; Valid Loss of 1.96776 ; Accuracy of 0.50977\n","Epoch 45 : Train Loss of 0.94221 ; Valid Loss of 2.02227 ; Accuracy of 0.50879\n","Epoch 46 : Train Loss of 0.93946 ; Valid Loss of 2.03080 ; Accuracy of 0.49902\n","Epoch 47 : Train Loss of 0.93909 ; Valid Loss of 2.02017 ; Accuracy of 0.51172\n","Epoch 48 : Train Loss of 0.93497 ; Valid Loss of 2.05365 ; Accuracy of 0.50977\n","Epoch 49 : Train Loss of 0.93638 ; Valid Loss of 2.05942 ; Accuracy of 0.49023\n","Epoch 50 : Train Loss of 0.93650 ; Valid Loss of 2.01032 ; Accuracy of 0.49805\n","Epoch 51 : Train Loss of 0.92896 ; Valid Loss of 2.01100 ; Accuracy of 0.50195\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea55c88>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.49637\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d6770b8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.46987 ; Valid Loss of 1.63997 ; Accuracy of 0.54297\n","Epoch 2 : Train Loss of 1.32614 ; Valid Loss of 1.67068 ; Accuracy of 0.54199\n","Epoch 3 : Train Loss of 1.28461 ; Valid Loss of 1.73940 ; Accuracy of 0.52441\n","Epoch 4 : Train Loss of 1.24203 ; Valid Loss of 1.70969 ; Accuracy of 0.52832\n","Epoch 5 : Train Loss of 1.22275 ; Valid Loss of 1.74424 ; Accuracy of 0.53711\n","Epoch 6 : Train Loss of 1.20880 ; Valid Loss of 1.79623 ; Accuracy of 0.52148\n","Epoch 7 : Train Loss of 1.19190 ; Valid Loss of 1.76763 ; Accuracy of 0.53320\n","Epoch 8 : Train Loss of 1.17245 ; Valid Loss of 1.81531 ; Accuracy of 0.52930\n","Epoch 9 : Train Loss of 1.16639 ; Valid Loss of 1.77757 ; Accuracy of 0.53809\n","Epoch 10 : Train Loss of 1.13927 ; Valid Loss of 1.82943 ; Accuracy of 0.52734\n","Epoch 11 : Train Loss of 1.14892 ; Valid Loss of 1.81942 ; Accuracy of 0.53516\n","Epoch 12 : Train Loss of 1.12174 ; Valid Loss of 1.82692 ; Accuracy of 0.52734\n","Epoch 13 : Train Loss of 1.10718 ; Valid Loss of 1.86596 ; Accuracy of 0.52637\n","Epoch 14 : Train Loss of 1.10457 ; Valid Loss of 1.80560 ; Accuracy of 0.53711\n","Epoch 15 : Train Loss of 1.09694 ; Valid Loss of 1.81999 ; Accuracy of 0.52539\n","Epoch 16 : Train Loss of 1.08724 ; Valid Loss of 1.83135 ; Accuracy of 0.53125\n","Epoch 17 : Train Loss of 1.07568 ; Valid Loss of 1.90883 ; Accuracy of 0.51562\n","Epoch 18 : Train Loss of 1.08965 ; Valid Loss of 1.86885 ; Accuracy of 0.52441\n","Epoch 19 : Train Loss of 1.07339 ; Valid Loss of 1.88478 ; Accuracy of 0.51367\n","Epoch 20 : Train Loss of 1.05940 ; Valid Loss of 1.86609 ; Accuracy of 0.52148\n","Epoch 21 : Train Loss of 1.05027 ; Valid Loss of 1.84605 ; Accuracy of 0.52539\n","Epoch 22 : Train Loss of 1.05707 ; Valid Loss of 1.87026 ; Accuracy of 0.51855\n","Epoch 23 : Train Loss of 1.04349 ; Valid Loss of 1.82690 ; Accuracy of 0.52441\n","Epoch 24 : Train Loss of 1.04235 ; Valid Loss of 1.84554 ; Accuracy of 0.52441\n","Epoch 25 : Train Loss of 1.03391 ; Valid Loss of 1.87142 ; Accuracy of 0.53027\n","Epoch 26 : Train Loss of 1.02264 ; Valid Loss of 1.85698 ; Accuracy of 0.52539\n","Epoch 27 : Train Loss of 1.02183 ; Valid Loss of 1.85578 ; Accuracy of 0.51855\n","Epoch 28 : Train Loss of 1.01581 ; Valid Loss of 1.88389 ; Accuracy of 0.51172\n","Epoch 29 : Train Loss of 1.01203 ; Valid Loss of 1.92786 ; Accuracy of 0.50195\n","Epoch 30 : Train Loss of 1.00394 ; Valid Loss of 1.88087 ; Accuracy of 0.52539\n","Epoch 31 : Train Loss of 1.00213 ; Valid Loss of 1.88911 ; Accuracy of 0.52148\n","Epoch 32 : Train Loss of 0.99379 ; Valid Loss of 1.91254 ; Accuracy of 0.52051\n","Epoch 33 : Train Loss of 1.00289 ; Valid Loss of 1.88483 ; Accuracy of 0.52734\n","Epoch 34 : Train Loss of 0.99799 ; Valid Loss of 1.91950 ; Accuracy of 0.52051\n","Epoch 35 : Train Loss of 0.98689 ; Valid Loss of 1.88999 ; Accuracy of 0.51953\n","Epoch 36 : Train Loss of 0.98168 ; Valid Loss of 1.86151 ; Accuracy of 0.52246\n","Epoch 37 : Train Loss of 0.97991 ; Valid Loss of 1.90574 ; Accuracy of 0.51562\n","Epoch 38 : Train Loss of 0.98527 ; Valid Loss of 1.89047 ; Accuracy of 0.53125\n","Epoch 39 : Train Loss of 0.97196 ; Valid Loss of 1.86699 ; Accuracy of 0.53125\n","Epoch 40 : Train Loss of 0.96699 ; Valid Loss of 1.90503 ; Accuracy of 0.53320\n","Epoch 41 : Train Loss of 0.97156 ; Valid Loss of 1.85266 ; Accuracy of 0.53809\n","Epoch 42 : Train Loss of 0.95768 ; Valid Loss of 1.92522 ; Accuracy of 0.53320\n","Epoch 43 : Train Loss of 0.96386 ; Valid Loss of 1.91622 ; Accuracy of 0.53027\n","Epoch 44 : Train Loss of 0.95803 ; Valid Loss of 1.87754 ; Accuracy of 0.53613\n","Epoch 45 : Train Loss of 0.95220 ; Valid Loss of 1.84720 ; Accuracy of 0.53711\n","Epoch 46 : Train Loss of 0.95907 ; Valid Loss of 1.90080 ; Accuracy of 0.53125\n","Epoch 47 : Train Loss of 0.95425 ; Valid Loss of 1.88354 ; Accuracy of 0.53516\n","Epoch 48 : Train Loss of 0.94576 ; Valid Loss of 1.84848 ; Accuracy of 0.53418\n","Epoch 49 : Train Loss of 0.94186 ; Valid Loss of 1.92741 ; Accuracy of 0.52246\n","Epoch 50 : Train Loss of 0.93808 ; Valid Loss of 1.88634 ; Accuracy of 0.52832\n","Epoch 51 : Train Loss of 0.94341 ; Valid Loss of 1.92918 ; Accuracy of 0.52539\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d677048>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.58264\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea5f198>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.52845 ; Valid Loss of 2.05311 ; Accuracy of 0.48730\n","Epoch 2 : Train Loss of 1.33972 ; Valid Loss of 2.08160 ; Accuracy of 0.48047\n","Epoch 3 : Train Loss of 1.26516 ; Valid Loss of 2.06599 ; Accuracy of 0.48926\n","Epoch 4 : Train Loss of 1.23576 ; Valid Loss of 2.17506 ; Accuracy of 0.46777\n","Epoch 5 : Train Loss of 1.21561 ; Valid Loss of 2.18688 ; Accuracy of 0.46875\n","Epoch 6 : Train Loss of 1.19143 ; Valid Loss of 2.18560 ; Accuracy of 0.48535\n","Epoch 7 : Train Loss of 1.16939 ; Valid Loss of 2.21691 ; Accuracy of 0.47754\n","Epoch 8 : Train Loss of 1.16821 ; Valid Loss of 2.25470 ; Accuracy of 0.46777\n","Epoch 9 : Train Loss of 1.15089 ; Valid Loss of 2.22133 ; Accuracy of 0.48047\n","Epoch 10 : Train Loss of 1.14034 ; Valid Loss of 2.27996 ; Accuracy of 0.47168\n","Epoch 11 : Train Loss of 1.13805 ; Valid Loss of 2.23728 ; Accuracy of 0.47363\n","Epoch 12 : Train Loss of 1.12307 ; Valid Loss of 2.22786 ; Accuracy of 0.47852\n","Epoch 13 : Train Loss of 1.10960 ; Valid Loss of 2.21429 ; Accuracy of 0.47656\n","Epoch 14 : Train Loss of 1.09585 ; Valid Loss of 2.24468 ; Accuracy of 0.47266\n","Epoch 15 : Train Loss of 1.09205 ; Valid Loss of 2.24457 ; Accuracy of 0.47168\n","Epoch 16 : Train Loss of 1.08408 ; Valid Loss of 2.23416 ; Accuracy of 0.47656\n","Epoch 17 : Train Loss of 1.06953 ; Valid Loss of 2.21814 ; Accuracy of 0.47363\n","Epoch 18 : Train Loss of 1.07356 ; Valid Loss of 2.21504 ; Accuracy of 0.48828\n","Epoch 19 : Train Loss of 1.06416 ; Valid Loss of 2.21976 ; Accuracy of 0.48242\n","Epoch 20 : Train Loss of 1.04899 ; Valid Loss of 2.20204 ; Accuracy of 0.48633\n","Epoch 21 : Train Loss of 1.05500 ; Valid Loss of 2.24253 ; Accuracy of 0.47754\n","Epoch 22 : Train Loss of 1.03404 ; Valid Loss of 2.20301 ; Accuracy of 0.48926\n","Epoch 23 : Train Loss of 1.03953 ; Valid Loss of 2.21494 ; Accuracy of 0.48633\n","Epoch 24 : Train Loss of 1.03613 ; Valid Loss of 2.22960 ; Accuracy of 0.49121\n","Epoch 25 : Train Loss of 1.01990 ; Valid Loss of 2.22240 ; Accuracy of 0.48535\n","Epoch 26 : Train Loss of 1.02628 ; Valid Loss of 2.19246 ; Accuracy of 0.49414\n","Epoch 27 : Train Loss of 1.02023 ; Valid Loss of 2.22209 ; Accuracy of 0.49023\n","Epoch 28 : Train Loss of 1.01414 ; Valid Loss of 2.15460 ; Accuracy of 0.48535\n","Epoch 29 : Train Loss of 1.01127 ; Valid Loss of 2.23608 ; Accuracy of 0.47363\n","Epoch 30 : Train Loss of 1.01102 ; Valid Loss of 2.17172 ; Accuracy of 0.48730\n","Epoch 31 : Train Loss of 0.99735 ; Valid Loss of 2.24063 ; Accuracy of 0.49023\n","Epoch 32 : Train Loss of 0.99487 ; Valid Loss of 2.16938 ; Accuracy of 0.49316\n","Epoch 33 : Train Loss of 0.99242 ; Valid Loss of 2.17659 ; Accuracy of 0.50098\n","Epoch 34 : Train Loss of 0.99346 ; Valid Loss of 2.15804 ; Accuracy of 0.49902\n","Epoch 35 : Train Loss of 0.98934 ; Valid Loss of 2.16156 ; Accuracy of 0.49609\n","Epoch 36 : Train Loss of 0.98301 ; Valid Loss of 2.20461 ; Accuracy of 0.49316\n","Epoch 37 : Train Loss of 0.97818 ; Valid Loss of 2.21415 ; Accuracy of 0.49219\n","Epoch 38 : Train Loss of 0.97547 ; Valid Loss of 2.19266 ; Accuracy of 0.49707\n","Epoch 39 : Train Loss of 0.96681 ; Valid Loss of 2.22396 ; Accuracy of 0.48730\n","Epoch 40 : Train Loss of 0.96739 ; Valid Loss of 2.17440 ; Accuracy of 0.50391\n","Epoch 41 : Train Loss of 0.96504 ; Valid Loss of 2.18969 ; Accuracy of 0.49707\n","Epoch 42 : Train Loss of 0.95952 ; Valid Loss of 2.11397 ; Accuracy of 0.51074\n","Epoch 43 : Train Loss of 0.95501 ; Valid Loss of 2.19872 ; Accuracy of 0.49707\n","Epoch 44 : Train Loss of 0.95362 ; Valid Loss of 2.16313 ; Accuracy of 0.50098\n","Epoch 45 : Train Loss of 0.96313 ; Valid Loss of 2.20698 ; Accuracy of 0.48340\n","Epoch 46 : Train Loss of 0.94028 ; Valid Loss of 2.15225 ; Accuracy of 0.50391\n","Epoch 47 : Train Loss of 0.94413 ; Valid Loss of 2.18083 ; Accuracy of 0.49609\n","Epoch 48 : Train Loss of 0.94429 ; Valid Loss of 2.19484 ; Accuracy of 0.50098\n","Epoch 49 : Train Loss of 0.94427 ; Valid Loss of 2.22414 ; Accuracy of 0.49609\n","Epoch 50 : Train Loss of 0.94400 ; Valid Loss of 2.17544 ; Accuracy of 0.51074\n","Epoch 51 : Train Loss of 0.93830 ; Valid Loss of 2.19850 ; Accuracy of 0.50293\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea55d68>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.52980\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea5f198>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.53306 ; Valid Loss of 1.77461 ; Accuracy of 0.54785\n","Epoch 2 : Train Loss of 1.35903 ; Valid Loss of 1.81770 ; Accuracy of 0.53320\n","Epoch 3 : Train Loss of 1.28610 ; Valid Loss of 1.82006 ; Accuracy of 0.52832\n","Epoch 4 : Train Loss of 1.26823 ; Valid Loss of 1.79230 ; Accuracy of 0.52832\n","Epoch 5 : Train Loss of 1.24143 ; Valid Loss of 1.87073 ; Accuracy of 0.50684\n","Epoch 6 : Train Loss of 1.22023 ; Valid Loss of 1.89395 ; Accuracy of 0.50586\n","Epoch 7 : Train Loss of 1.20860 ; Valid Loss of 1.87872 ; Accuracy of 0.52148\n","Epoch 8 : Train Loss of 1.19416 ; Valid Loss of 1.88506 ; Accuracy of 0.50586\n","Epoch 9 : Train Loss of 1.17486 ; Valid Loss of 1.90973 ; Accuracy of 0.51367\n","Epoch 10 : Train Loss of 1.15906 ; Valid Loss of 1.88106 ; Accuracy of 0.51270\n","Epoch 11 : Train Loss of 1.14450 ; Valid Loss of 1.90074 ; Accuracy of 0.51270\n","Epoch 12 : Train Loss of 1.13590 ; Valid Loss of 1.89105 ; Accuracy of 0.50879\n","Epoch 13 : Train Loss of 1.12668 ; Valid Loss of 1.91046 ; Accuracy of 0.50391\n","Epoch 14 : Train Loss of 1.11492 ; Valid Loss of 1.88809 ; Accuracy of 0.51367\n","Epoch 15 : Train Loss of 1.11365 ; Valid Loss of 1.91541 ; Accuracy of 0.51172\n","Epoch 16 : Train Loss of 1.10844 ; Valid Loss of 1.92874 ; Accuracy of 0.51660\n","Epoch 17 : Train Loss of 1.09644 ; Valid Loss of 1.94584 ; Accuracy of 0.51172\n","Epoch 18 : Train Loss of 1.08767 ; Valid Loss of 1.96848 ; Accuracy of 0.50293\n","Epoch 19 : Train Loss of 1.08798 ; Valid Loss of 1.95215 ; Accuracy of 0.50879\n","Epoch 20 : Train Loss of 1.07795 ; Valid Loss of 1.96068 ; Accuracy of 0.50195\n","Epoch 21 : Train Loss of 1.07845 ; Valid Loss of 1.88017 ; Accuracy of 0.51172\n","Epoch 22 : Train Loss of 1.06415 ; Valid Loss of 1.89757 ; Accuracy of 0.51855\n","Epoch 23 : Train Loss of 1.05065 ; Valid Loss of 1.92785 ; Accuracy of 0.52441\n","Epoch 24 : Train Loss of 1.05042 ; Valid Loss of 1.90614 ; Accuracy of 0.51660\n","Epoch 25 : Train Loss of 1.04624 ; Valid Loss of 1.92732 ; Accuracy of 0.52051\n","Epoch 26 : Train Loss of 1.04474 ; Valid Loss of 1.95982 ; Accuracy of 0.52539\n","Epoch 27 : Train Loss of 1.03103 ; Valid Loss of 1.96391 ; Accuracy of 0.52148\n","Epoch 28 : Train Loss of 1.03489 ; Valid Loss of 1.95188 ; Accuracy of 0.52051\n","Epoch 29 : Train Loss of 1.03160 ; Valid Loss of 1.96077 ; Accuracy of 0.51758\n","Epoch 30 : Train Loss of 1.02618 ; Valid Loss of 1.98513 ; Accuracy of 0.51465\n","Epoch 31 : Train Loss of 1.02205 ; Valid Loss of 1.94464 ; Accuracy of 0.52344\n","Epoch 32 : Train Loss of 1.01303 ; Valid Loss of 1.92986 ; Accuracy of 0.52734\n","Epoch 33 : Train Loss of 1.00118 ; Valid Loss of 1.96143 ; Accuracy of 0.52344\n","Epoch 34 : Train Loss of 1.00305 ; Valid Loss of 1.90858 ; Accuracy of 0.52637\n","Epoch 35 : Train Loss of 1.00621 ; Valid Loss of 1.93875 ; Accuracy of 0.53125\n","Epoch 36 : Train Loss of 1.00751 ; Valid Loss of 1.97661 ; Accuracy of 0.52441\n","Epoch 37 : Train Loss of 0.99689 ; Valid Loss of 1.98593 ; Accuracy of 0.51758\n","Epoch 38 : Train Loss of 0.98991 ; Valid Loss of 1.97049 ; Accuracy of 0.52246\n","Epoch 39 : Train Loss of 0.97262 ; Valid Loss of 1.97265 ; Accuracy of 0.52637\n","Epoch 40 : Train Loss of 0.99099 ; Valid Loss of 1.93906 ; Accuracy of 0.51758\n","Epoch 41 : Train Loss of 0.99012 ; Valid Loss of 1.97312 ; Accuracy of 0.52051\n","Epoch 42 : Train Loss of 0.98266 ; Valid Loss of 1.96876 ; Accuracy of 0.51270\n","Epoch 43 : Train Loss of 0.97946 ; Valid Loss of 2.02029 ; Accuracy of 0.51953\n","Epoch 44 : Train Loss of 0.97584 ; Valid Loss of 1.96327 ; Accuracy of 0.51270\n","Epoch 45 : Train Loss of 0.97322 ; Valid Loss of 2.01152 ; Accuracy of 0.51562\n","Epoch 46 : Train Loss of 0.96068 ; Valid Loss of 1.98526 ; Accuracy of 0.52148\n","Epoch 47 : Train Loss of 0.96112 ; Valid Loss of 1.96754 ; Accuracy of 0.52637\n","Epoch 48 : Train Loss of 0.96192 ; Valid Loss of 2.01150 ; Accuracy of 0.51660\n","Epoch 49 : Train Loss of 0.95571 ; Valid Loss of 1.95666 ; Accuracy of 0.51855\n","Epoch 50 : Train Loss of 0.95851 ; Valid Loss of 1.97063 ; Accuracy of 0.51172\n","Epoch 51 : Train Loss of 0.95245 ; Valid Loss of 1.96075 ; Accuracy of 0.53125\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d677a58>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.45452\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea639e8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.55699 ; Valid Loss of 1.63527 ; Accuracy of 0.50098\n","Epoch 2 : Train Loss of 1.34918 ; Valid Loss of 1.74692 ; Accuracy of 0.51172\n","Epoch 3 : Train Loss of 1.27167 ; Valid Loss of 1.76648 ; Accuracy of 0.50977\n","Epoch 4 : Train Loss of 1.24827 ; Valid Loss of 1.78890 ; Accuracy of 0.49512\n","Epoch 5 : Train Loss of 1.22350 ; Valid Loss of 1.79145 ; Accuracy of 0.50391\n","Epoch 6 : Train Loss of 1.21294 ; Valid Loss of 1.86231 ; Accuracy of 0.48730\n","Epoch 7 : Train Loss of 1.17652 ; Valid Loss of 1.83665 ; Accuracy of 0.50293\n","Epoch 8 : Train Loss of 1.16240 ; Valid Loss of 1.86098 ; Accuracy of 0.49902\n","Epoch 9 : Train Loss of 1.15761 ; Valid Loss of 1.92831 ; Accuracy of 0.48730\n","Epoch 10 : Train Loss of 1.14434 ; Valid Loss of 1.89696 ; Accuracy of 0.50293\n","Epoch 11 : Train Loss of 1.13933 ; Valid Loss of 1.91942 ; Accuracy of 0.48633\n","Epoch 12 : Train Loss of 1.11660 ; Valid Loss of 1.89105 ; Accuracy of 0.49316\n","Epoch 13 : Train Loss of 1.10762 ; Valid Loss of 1.91869 ; Accuracy of 0.50000\n","Epoch 14 : Train Loss of 1.10897 ; Valid Loss of 1.91883 ; Accuracy of 0.50391\n","Epoch 15 : Train Loss of 1.08435 ; Valid Loss of 1.94728 ; Accuracy of 0.48730\n","Epoch 16 : Train Loss of 1.09191 ; Valid Loss of 1.95772 ; Accuracy of 0.49609\n","Epoch 17 : Train Loss of 1.07504 ; Valid Loss of 1.92432 ; Accuracy of 0.50488\n","Epoch 18 : Train Loss of 1.07457 ; Valid Loss of 1.92411 ; Accuracy of 0.50391\n","Epoch 19 : Train Loss of 1.06127 ; Valid Loss of 1.94860 ; Accuracy of 0.50000\n","Epoch 20 : Train Loss of 1.05576 ; Valid Loss of 1.94009 ; Accuracy of 0.50000\n","Epoch 21 : Train Loss of 1.05801 ; Valid Loss of 1.97971 ; Accuracy of 0.49121\n","Epoch 22 : Train Loss of 1.04499 ; Valid Loss of 1.93297 ; Accuracy of 0.49121\n","Epoch 23 : Train Loss of 1.04011 ; Valid Loss of 1.95417 ; Accuracy of 0.49316\n","Epoch 24 : Train Loss of 1.02936 ; Valid Loss of 1.97500 ; Accuracy of 0.49512\n","Epoch 25 : Train Loss of 1.03615 ; Valid Loss of 1.89528 ; Accuracy of 0.50195\n","Epoch 26 : Train Loss of 1.02711 ; Valid Loss of 1.95859 ; Accuracy of 0.49023\n","Epoch 27 : Train Loss of 1.02174 ; Valid Loss of 1.96040 ; Accuracy of 0.50000\n","Epoch 28 : Train Loss of 1.01661 ; Valid Loss of 1.98389 ; Accuracy of 0.48340\n","Epoch 29 : Train Loss of 1.01500 ; Valid Loss of 1.95875 ; Accuracy of 0.49805\n","Epoch 30 : Train Loss of 1.01520 ; Valid Loss of 1.94700 ; Accuracy of 0.49707\n","Epoch 31 : Train Loss of 1.00647 ; Valid Loss of 1.93203 ; Accuracy of 0.50098\n","Epoch 32 : Train Loss of 0.99893 ; Valid Loss of 1.96007 ; Accuracy of 0.49707\n","Epoch 33 : Train Loss of 0.99477 ; Valid Loss of 1.95740 ; Accuracy of 0.50684\n","Epoch 34 : Train Loss of 0.99522 ; Valid Loss of 1.94745 ; Accuracy of 0.50488\n","Epoch 35 : Train Loss of 0.98777 ; Valid Loss of 1.98428 ; Accuracy of 0.49707\n","Epoch 36 : Train Loss of 0.98522 ; Valid Loss of 1.96465 ; Accuracy of 0.50195\n","Epoch 37 : Train Loss of 0.98260 ; Valid Loss of 1.97548 ; Accuracy of 0.49707\n","Epoch 38 : Train Loss of 0.96948 ; Valid Loss of 1.95253 ; Accuracy of 0.50684\n","Epoch 39 : Train Loss of 0.97373 ; Valid Loss of 2.00857 ; Accuracy of 0.49121\n","Epoch 40 : Train Loss of 0.97434 ; Valid Loss of 1.95623 ; Accuracy of 0.50684\n","Epoch 41 : Train Loss of 0.96719 ; Valid Loss of 1.95842 ; Accuracy of 0.50195\n","Epoch 42 : Train Loss of 0.97315 ; Valid Loss of 1.99202 ; Accuracy of 0.49707\n","Epoch 43 : Train Loss of 0.96054 ; Valid Loss of 2.00017 ; Accuracy of 0.50000\n","Epoch 44 : Train Loss of 0.96251 ; Valid Loss of 1.98952 ; Accuracy of 0.49512\n","Epoch 45 : Train Loss of 0.95368 ; Valid Loss of 1.99321 ; Accuracy of 0.50391\n","Epoch 46 : Train Loss of 0.94726 ; Valid Loss of 1.97868 ; Accuracy of 0.50293\n","Epoch 47 : Train Loss of 0.95421 ; Valid Loss of 1.98454 ; Accuracy of 0.50488\n","Epoch 48 : Train Loss of 0.94743 ; Valid Loss of 2.01647 ; Accuracy of 0.49316\n","Epoch 49 : Train Loss of 0.95000 ; Valid Loss of 1.97170 ; Accuracy of 0.49805\n","Epoch 50 : Train Loss of 0.94104 ; Valid Loss of 1.96854 ; Accuracy of 0.50391\n","Epoch 51 : Train Loss of 0.94145 ; Valid Loss of 2.03418 ; Accuracy of 0.49902\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97e3668>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.47513\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea5f5f8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.52526 ; Valid Loss of 1.69970 ; Accuracy of 0.52441\n","Epoch 2 : Train Loss of 1.34353 ; Valid Loss of 1.74110 ; Accuracy of 0.52148\n","Epoch 3 : Train Loss of 1.28394 ; Valid Loss of 1.82710 ; Accuracy of 0.51758\n","Epoch 4 : Train Loss of 1.24232 ; Valid Loss of 1.81336 ; Accuracy of 0.51660\n","Epoch 5 : Train Loss of 1.21248 ; Valid Loss of 1.85903 ; Accuracy of 0.51855\n","Epoch 6 : Train Loss of 1.19733 ; Valid Loss of 1.82503 ; Accuracy of 0.50977\n","Epoch 7 : Train Loss of 1.17187 ; Valid Loss of 1.84179 ; Accuracy of 0.51562\n","Epoch 8 : Train Loss of 1.16530 ; Valid Loss of 1.83796 ; Accuracy of 0.50684\n","Epoch 9 : Train Loss of 1.16016 ; Valid Loss of 1.87260 ; Accuracy of 0.51660\n","Epoch 10 : Train Loss of 1.14856 ; Valid Loss of 1.85986 ; Accuracy of 0.52246\n","Epoch 11 : Train Loss of 1.13027 ; Valid Loss of 1.84945 ; Accuracy of 0.51855\n","Epoch 12 : Train Loss of 1.11382 ; Valid Loss of 1.86858 ; Accuracy of 0.51855\n","Epoch 13 : Train Loss of 1.11258 ; Valid Loss of 1.84892 ; Accuracy of 0.51758\n","Epoch 14 : Train Loss of 1.09514 ; Valid Loss of 1.85381 ; Accuracy of 0.51270\n","Epoch 15 : Train Loss of 1.09599 ; Valid Loss of 1.85512 ; Accuracy of 0.51074\n","Epoch 16 : Train Loss of 1.08618 ; Valid Loss of 1.85565 ; Accuracy of 0.51758\n","Epoch 17 : Train Loss of 1.07715 ; Valid Loss of 1.86426 ; Accuracy of 0.51172\n","Epoch 18 : Train Loss of 1.06492 ; Valid Loss of 1.86185 ; Accuracy of 0.50781\n","Epoch 19 : Train Loss of 1.06525 ; Valid Loss of 1.85603 ; Accuracy of 0.51074\n","Epoch 20 : Train Loss of 1.06112 ; Valid Loss of 1.90330 ; Accuracy of 0.50488\n","Epoch 21 : Train Loss of 1.04655 ; Valid Loss of 1.89184 ; Accuracy of 0.50781\n","Epoch 22 : Train Loss of 1.04605 ; Valid Loss of 1.89069 ; Accuracy of 0.50684\n","Epoch 23 : Train Loss of 1.04620 ; Valid Loss of 1.86102 ; Accuracy of 0.51758\n","Epoch 24 : Train Loss of 1.03799 ; Valid Loss of 1.87921 ; Accuracy of 0.51660\n","Epoch 25 : Train Loss of 1.02594 ; Valid Loss of 1.84782 ; Accuracy of 0.50977\n","Epoch 26 : Train Loss of 1.02345 ; Valid Loss of 1.87006 ; Accuracy of 0.51660\n","Epoch 27 : Train Loss of 1.01993 ; Valid Loss of 1.83382 ; Accuracy of 0.51953\n","Epoch 28 : Train Loss of 1.01808 ; Valid Loss of 1.87026 ; Accuracy of 0.52148\n","Epoch 29 : Train Loss of 1.01529 ; Valid Loss of 1.91640 ; Accuracy of 0.50391\n","Epoch 30 : Train Loss of 0.99867 ; Valid Loss of 1.86888 ; Accuracy of 0.51074\n","Epoch 31 : Train Loss of 0.99828 ; Valid Loss of 1.92397 ; Accuracy of 0.50391\n","Epoch 32 : Train Loss of 0.99734 ; Valid Loss of 1.86145 ; Accuracy of 0.51660\n","Epoch 33 : Train Loss of 0.98094 ; Valid Loss of 1.87344 ; Accuracy of 0.51172\n","Epoch 34 : Train Loss of 0.99766 ; Valid Loss of 1.90855 ; Accuracy of 0.51172\n","Epoch 35 : Train Loss of 0.98062 ; Valid Loss of 1.93675 ; Accuracy of 0.50586\n","Epoch 36 : Train Loss of 0.98817 ; Valid Loss of 1.92000 ; Accuracy of 0.50586\n","Epoch 37 : Train Loss of 0.98610 ; Valid Loss of 1.89848 ; Accuracy of 0.50781\n","Epoch 38 : Train Loss of 0.97558 ; Valid Loss of 1.91467 ; Accuracy of 0.51074\n","Epoch 39 : Train Loss of 0.97894 ; Valid Loss of 1.86949 ; Accuracy of 0.53125\n","Epoch 40 : Train Loss of 0.97108 ; Valid Loss of 1.90656 ; Accuracy of 0.51270\n","Epoch 41 : Train Loss of 0.95913 ; Valid Loss of 1.93687 ; Accuracy of 0.51953\n","Epoch 42 : Train Loss of 0.95440 ; Valid Loss of 1.90810 ; Accuracy of 0.51465\n","Epoch 43 : Train Loss of 0.96064 ; Valid Loss of 1.87642 ; Accuracy of 0.52148\n","Epoch 44 : Train Loss of 0.94811 ; Valid Loss of 1.92473 ; Accuracy of 0.51953\n","Epoch 45 : Train Loss of 0.95451 ; Valid Loss of 1.88808 ; Accuracy of 0.52148\n","Epoch 46 : Train Loss of 0.95420 ; Valid Loss of 1.94463 ; Accuracy of 0.51660\n","Epoch 47 : Train Loss of 0.95534 ; Valid Loss of 1.88573 ; Accuracy of 0.51953\n","Epoch 48 : Train Loss of 0.94472 ; Valid Loss of 1.90425 ; Accuracy of 0.52637\n","Epoch 49 : Train Loss of 0.94193 ; Valid Loss of 1.95501 ; Accuracy of 0.50879\n","Epoch 50 : Train Loss of 0.93804 ; Valid Loss of 1.95014 ; Accuracy of 0.51172\n","Epoch 51 : Train Loss of 0.93669 ; Valid Loss of 1.89208 ; Accuracy of 0.52637\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea5f518>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.53531\n","Proportion of 1 is for train set is : 0.24196361824071766\n","Proportion of 1 is for valid set is : 0.5947368421052631\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d677ba8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.64251 ; Valid Loss of 1.51003 ; Accuracy of 0.52051\n","Epoch 2 : Train Loss of 1.42182 ; Valid Loss of 1.54977 ; Accuracy of 0.52930\n","Epoch 3 : Train Loss of 1.33184 ; Valid Loss of 1.58570 ; Accuracy of 0.52832\n","Epoch 4 : Train Loss of 1.31338 ; Valid Loss of 1.61893 ; Accuracy of 0.52246\n","Epoch 5 : Train Loss of 1.27738 ; Valid Loss of 1.64515 ; Accuracy of 0.52637\n","Epoch 6 : Train Loss of 1.26226 ; Valid Loss of 1.69945 ; Accuracy of 0.53125\n","Epoch 7 : Train Loss of 1.23475 ; Valid Loss of 1.68226 ; Accuracy of 0.52930\n","Epoch 8 : Train Loss of 1.20566 ; Valid Loss of 1.70682 ; Accuracy of 0.53516\n","Epoch 9 : Train Loss of 1.20048 ; Valid Loss of 1.74449 ; Accuracy of 0.51562\n","Epoch 10 : Train Loss of 1.18945 ; Valid Loss of 1.70644 ; Accuracy of 0.51855\n","Epoch 11 : Train Loss of 1.17545 ; Valid Loss of 1.76502 ; Accuracy of 0.51172\n","Epoch 12 : Train Loss of 1.16079 ; Valid Loss of 1.74911 ; Accuracy of 0.51660\n","Epoch 13 : Train Loss of 1.16339 ; Valid Loss of 1.76267 ; Accuracy of 0.52637\n","Epoch 14 : Train Loss of 1.14783 ; Valid Loss of 1.80129 ; Accuracy of 0.50391\n","Epoch 15 : Train Loss of 1.13096 ; Valid Loss of 1.79604 ; Accuracy of 0.51074\n","Epoch 16 : Train Loss of 1.11748 ; Valid Loss of 1.77925 ; Accuracy of 0.52637\n","Epoch 17 : Train Loss of 1.11547 ; Valid Loss of 1.83636 ; Accuracy of 0.49707\n","Epoch 18 : Train Loss of 1.11334 ; Valid Loss of 1.78893 ; Accuracy of 0.51172\n","Epoch 19 : Train Loss of 1.09710 ; Valid Loss of 1.80839 ; Accuracy of 0.51465\n","Epoch 20 : Train Loss of 1.08511 ; Valid Loss of 1.82735 ; Accuracy of 0.49805\n","Epoch 21 : Train Loss of 1.08280 ; Valid Loss of 1.82697 ; Accuracy of 0.50195\n","Epoch 22 : Train Loss of 1.07396 ; Valid Loss of 1.84049 ; Accuracy of 0.50098\n","Epoch 23 : Train Loss of 1.07007 ; Valid Loss of 1.87970 ; Accuracy of 0.49902\n","Epoch 24 : Train Loss of 1.07688 ; Valid Loss of 1.90258 ; Accuracy of 0.48438\n","Epoch 25 : Train Loss of 1.05787 ; Valid Loss of 1.82373 ; Accuracy of 0.51367\n","Epoch 26 : Train Loss of 1.05744 ; Valid Loss of 1.87942 ; Accuracy of 0.50000\n","Epoch 27 : Train Loss of 1.04456 ; Valid Loss of 1.86129 ; Accuracy of 0.50195\n","Epoch 28 : Train Loss of 1.04730 ; Valid Loss of 1.84341 ; Accuracy of 0.49414\n","Epoch 29 : Train Loss of 1.04328 ; Valid Loss of 1.90285 ; Accuracy of 0.50293\n","Epoch 30 : Train Loss of 1.02630 ; Valid Loss of 1.88502 ; Accuracy of 0.50879\n","Epoch 31 : Train Loss of 1.02689 ; Valid Loss of 1.87810 ; Accuracy of 0.49902\n","Epoch 32 : Train Loss of 1.02519 ; Valid Loss of 1.86642 ; Accuracy of 0.50098\n","Epoch 33 : Train Loss of 1.02371 ; Valid Loss of 1.89838 ; Accuracy of 0.50195\n","Epoch 34 : Train Loss of 1.01968 ; Valid Loss of 1.82061 ; Accuracy of 0.50977\n","Epoch 35 : Train Loss of 1.02107 ; Valid Loss of 1.85921 ; Accuracy of 0.50488\n","Epoch 36 : Train Loss of 1.01481 ; Valid Loss of 1.92087 ; Accuracy of 0.48828\n","Epoch 37 : Train Loss of 1.02094 ; Valid Loss of 1.86502 ; Accuracy of 0.51465\n","Epoch 38 : Train Loss of 1.00491 ; Valid Loss of 1.87633 ; Accuracy of 0.50977\n","Epoch 39 : Train Loss of 0.99675 ; Valid Loss of 1.88496 ; Accuracy of 0.50195\n","Epoch 40 : Train Loss of 0.99404 ; Valid Loss of 1.87856 ; Accuracy of 0.50293\n","Epoch 41 : Train Loss of 0.99710 ; Valid Loss of 1.89863 ; Accuracy of 0.50488\n","Epoch 42 : Train Loss of 0.98399 ; Valid Loss of 1.89577 ; Accuracy of 0.51562\n","Epoch 43 : Train Loss of 0.98079 ; Valid Loss of 1.95194 ; Accuracy of 0.50977\n","Epoch 44 : Train Loss of 0.99188 ; Valid Loss of 1.84142 ; Accuracy of 0.52930\n","Epoch 45 : Train Loss of 0.98508 ; Valid Loss of 1.85066 ; Accuracy of 0.52637\n","Epoch 46 : Train Loss of 0.97557 ; Valid Loss of 1.88569 ; Accuracy of 0.51367\n","Epoch 47 : Train Loss of 0.96782 ; Valid Loss of 1.86161 ; Accuracy of 0.51953\n","Epoch 48 : Train Loss of 0.97073 ; Valid Loss of 1.88828 ; Accuracy of 0.51855\n","Epoch 49 : Train Loss of 0.96601 ; Valid Loss of 1.83406 ; Accuracy of 0.52539\n","Epoch 50 : Train Loss of 0.95813 ; Valid Loss of 1.89745 ; Accuracy of 0.51660\n","Epoch 51 : Train Loss of 0.95732 ; Valid Loss of 1.91002 ; Accuracy of 0.51172\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261d677c88>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.53030\n","Running Threshold 218\n","Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='total_10-06-20_512_256_lr_6e-4', lr=0.0005, model='total', production=1, save_processed_data=0, swa=0, threshold=218)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cb400>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.52550 ; Valid Loss of 1.87189 ; Accuracy of 0.50879\n","Epoch 2 : Train Loss of 1.37492 ; Valid Loss of 1.93129 ; Accuracy of 0.50293\n","Epoch 3 : Train Loss of 1.31041 ; Valid Loss of 2.00048 ; Accuracy of 0.49902\n","Epoch 4 : Train Loss of 1.26890 ; Valid Loss of 2.03184 ; Accuracy of 0.50195\n","Epoch 5 : Train Loss of 1.25925 ; Valid Loss of 2.03116 ; Accuracy of 0.50684\n","Epoch 6 : Train Loss of 1.23694 ; Valid Loss of 2.06113 ; Accuracy of 0.49707\n","Epoch 7 : Train Loss of 1.21334 ; Valid Loss of 2.09169 ; Accuracy of 0.50195\n","Epoch 8 : Train Loss of 1.21225 ; Valid Loss of 2.07657 ; Accuracy of 0.48926\n","Epoch 9 : Train Loss of 1.18874 ; Valid Loss of 2.07936 ; Accuracy of 0.50391\n","Epoch 10 : Train Loss of 1.19240 ; Valid Loss of 2.07292 ; Accuracy of 0.50098\n","Epoch 11 : Train Loss of 1.16639 ; Valid Loss of 2.09870 ; Accuracy of 0.50586\n","Epoch 12 : Train Loss of 1.15632 ; Valid Loss of 2.12426 ; Accuracy of 0.49707\n","Epoch 13 : Train Loss of 1.14712 ; Valid Loss of 2.09422 ; Accuracy of 0.51074\n","Epoch 14 : Train Loss of 1.13393 ; Valid Loss of 2.08985 ; Accuracy of 0.50195\n","Epoch 15 : Train Loss of 1.13177 ; Valid Loss of 2.15673 ; Accuracy of 0.49512\n","Epoch 16 : Train Loss of 1.12298 ; Valid Loss of 2.11001 ; Accuracy of 0.50488\n","Epoch 17 : Train Loss of 1.10594 ; Valid Loss of 2.14010 ; Accuracy of 0.50195\n","Epoch 18 : Train Loss of 1.09958 ; Valid Loss of 2.11141 ; Accuracy of 0.50879\n","Epoch 19 : Train Loss of 1.10979 ; Valid Loss of 2.13994 ; Accuracy of 0.50684\n","Epoch 20 : Train Loss of 1.09533 ; Valid Loss of 2.13681 ; Accuracy of 0.50586\n","Epoch 21 : Train Loss of 1.07354 ; Valid Loss of 2.14301 ; Accuracy of 0.50000\n","Epoch 22 : Train Loss of 1.08370 ; Valid Loss of 2.12980 ; Accuracy of 0.50781\n","Epoch 23 : Train Loss of 1.07709 ; Valid Loss of 2.14183 ; Accuracy of 0.50293\n","Epoch 24 : Train Loss of 1.07223 ; Valid Loss of 2.10678 ; Accuracy of 0.50684\n","Epoch 25 : Train Loss of 1.06821 ; Valid Loss of 2.12300 ; Accuracy of 0.51172\n","Epoch 26 : Train Loss of 1.06326 ; Valid Loss of 2.08174 ; Accuracy of 0.50586\n","Epoch 27 : Train Loss of 1.05852 ; Valid Loss of 2.10504 ; Accuracy of 0.50293\n","Epoch 28 : Train Loss of 1.04517 ; Valid Loss of 2.13700 ; Accuracy of 0.50195\n","Epoch 29 : Train Loss of 1.03911 ; Valid Loss of 2.16127 ; Accuracy of 0.50293\n","Epoch 30 : Train Loss of 1.03039 ; Valid Loss of 2.14984 ; Accuracy of 0.51074\n","Epoch 31 : Train Loss of 1.04150 ; Valid Loss of 2.15217 ; Accuracy of 0.50293\n","Epoch 32 : Train Loss of 1.03042 ; Valid Loss of 2.16318 ; Accuracy of 0.51172\n","Epoch 33 : Train Loss of 1.01780 ; Valid Loss of 2.11293 ; Accuracy of 0.52051\n","Epoch 34 : Train Loss of 1.01390 ; Valid Loss of 2.12731 ; Accuracy of 0.51367\n","Epoch 35 : Train Loss of 1.02455 ; Valid Loss of 2.15425 ; Accuracy of 0.52246\n","Epoch 36 : Train Loss of 1.02597 ; Valid Loss of 2.13606 ; Accuracy of 0.52246\n","Epoch 37 : Train Loss of 1.00538 ; Valid Loss of 2.19765 ; Accuracy of 0.51562\n","Epoch 38 : Train Loss of 1.01347 ; Valid Loss of 2.15895 ; Accuracy of 0.51855\n","Epoch 39 : Train Loss of 0.99491 ; Valid Loss of 2.18447 ; Accuracy of 0.51758\n","Epoch 40 : Train Loss of 0.99585 ; Valid Loss of 2.19828 ; Accuracy of 0.50391\n","Epoch 41 : Train Loss of 0.99563 ; Valid Loss of 2.14837 ; Accuracy of 0.52051\n","Epoch 42 : Train Loss of 0.99519 ; Valid Loss of 2.19456 ; Accuracy of 0.51855\n","Epoch 43 : Train Loss of 0.98504 ; Valid Loss of 2.21143 ; Accuracy of 0.51855\n","Epoch 44 : Train Loss of 0.98316 ; Valid Loss of 2.12179 ; Accuracy of 0.52441\n","Epoch 45 : Train Loss of 0.98540 ; Valid Loss of 2.18010 ; Accuracy of 0.52246\n","Epoch 46 : Train Loss of 0.97843 ; Valid Loss of 2.18878 ; Accuracy of 0.51367\n","Epoch 47 : Train Loss of 0.98450 ; Valid Loss of 2.13666 ; Accuracy of 0.52246\n","Epoch 48 : Train Loss of 0.96918 ; Valid Loss of 2.14324 ; Accuracy of 0.52148\n","Epoch 49 : Train Loss of 0.97230 ; Valid Loss of 2.13533 ; Accuracy of 0.51660\n","Epoch 50 : Train Loss of 0.96987 ; Valid Loss of 2.14176 ; Accuracy of 0.52344\n","Epoch 51 : Train Loss of 0.97193 ; Valid Loss of 2.20506 ; Accuracy of 0.51074\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cbd30>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.58855\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e3ba8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.55100 ; Valid Loss of 1.87633 ; Accuracy of 0.49219\n","Epoch 2 : Train Loss of 1.36662 ; Valid Loss of 1.96368 ; Accuracy of 0.50000\n","Epoch 3 : Train Loss of 1.31054 ; Valid Loss of 2.04987 ; Accuracy of 0.48340\n","Epoch 4 : Train Loss of 1.26455 ; Valid Loss of 2.08309 ; Accuracy of 0.50586\n","Epoch 5 : Train Loss of 1.24680 ; Valid Loss of 2.08739 ; Accuracy of 0.50586\n","Epoch 6 : Train Loss of 1.22156 ; Valid Loss of 2.12133 ; Accuracy of 0.50098\n","Epoch 7 : Train Loss of 1.20507 ; Valid Loss of 2.13124 ; Accuracy of 0.49609\n","Epoch 8 : Train Loss of 1.19384 ; Valid Loss of 2.15172 ; Accuracy of 0.49414\n","Epoch 9 : Train Loss of 1.17835 ; Valid Loss of 2.17561 ; Accuracy of 0.49707\n","Epoch 10 : Train Loss of 1.16176 ; Valid Loss of 2.18725 ; Accuracy of 0.49121\n","Epoch 11 : Train Loss of 1.15903 ; Valid Loss of 2.18180 ; Accuracy of 0.49219\n","Epoch 12 : Train Loss of 1.14629 ; Valid Loss of 2.23025 ; Accuracy of 0.49609\n","Epoch 13 : Train Loss of 1.14143 ; Valid Loss of 2.18134 ; Accuracy of 0.50293\n","Epoch 14 : Train Loss of 1.13278 ; Valid Loss of 2.17856 ; Accuracy of 0.49609\n","Epoch 15 : Train Loss of 1.11029 ; Valid Loss of 2.25890 ; Accuracy of 0.49316\n","Epoch 16 : Train Loss of 1.11397 ; Valid Loss of 2.18438 ; Accuracy of 0.49805\n","Epoch 17 : Train Loss of 1.09490 ; Valid Loss of 2.21940 ; Accuracy of 0.49707\n","Epoch 18 : Train Loss of 1.09447 ; Valid Loss of 2.20098 ; Accuracy of 0.49121\n","Epoch 19 : Train Loss of 1.07244 ; Valid Loss of 2.27348 ; Accuracy of 0.48535\n","Epoch 20 : Train Loss of 1.07983 ; Valid Loss of 2.29200 ; Accuracy of 0.48535\n","Epoch 21 : Train Loss of 1.08207 ; Valid Loss of 2.23577 ; Accuracy of 0.49316\n","Epoch 22 : Train Loss of 1.06004 ; Valid Loss of 2.27489 ; Accuracy of 0.49023\n","Epoch 23 : Train Loss of 1.06248 ; Valid Loss of 2.26157 ; Accuracy of 0.48633\n","Epoch 24 : Train Loss of 1.04635 ; Valid Loss of 2.31902 ; Accuracy of 0.47949\n","Epoch 25 : Train Loss of 1.05668 ; Valid Loss of 2.25197 ; Accuracy of 0.48926\n","Epoch 26 : Train Loss of 1.05572 ; Valid Loss of 2.28672 ; Accuracy of 0.49023\n","Epoch 27 : Train Loss of 1.03350 ; Valid Loss of 2.27019 ; Accuracy of 0.49805\n","Epoch 28 : Train Loss of 1.03453 ; Valid Loss of 2.28306 ; Accuracy of 0.48145\n","Epoch 29 : Train Loss of 1.02091 ; Valid Loss of 2.27909 ; Accuracy of 0.48340\n","Epoch 30 : Train Loss of 1.00919 ; Valid Loss of 2.29417 ; Accuracy of 0.49805\n","Epoch 31 : Train Loss of 1.02693 ; Valid Loss of 2.27333 ; Accuracy of 0.48730\n","Epoch 32 : Train Loss of 1.01499 ; Valid Loss of 2.29788 ; Accuracy of 0.48730\n","Epoch 33 : Train Loss of 1.01645 ; Valid Loss of 2.25718 ; Accuracy of 0.49414\n","Epoch 34 : Train Loss of 1.01390 ; Valid Loss of 2.24288 ; Accuracy of 0.49219\n","Epoch 35 : Train Loss of 0.99804 ; Valid Loss of 2.22142 ; Accuracy of 0.49512\n","Epoch 36 : Train Loss of 0.99057 ; Valid Loss of 2.25199 ; Accuracy of 0.48926\n","Epoch 37 : Train Loss of 1.00144 ; Valid Loss of 2.21808 ; Accuracy of 0.50098\n","Epoch 38 : Train Loss of 0.99668 ; Valid Loss of 2.27031 ; Accuracy of 0.49512\n","Epoch 39 : Train Loss of 0.99467 ; Valid Loss of 2.22859 ; Accuracy of 0.49805\n","Epoch 40 : Train Loss of 0.99353 ; Valid Loss of 2.22051 ; Accuracy of 0.50684\n","Epoch 41 : Train Loss of 0.98532 ; Valid Loss of 2.18593 ; Accuracy of 0.50488\n","Epoch 42 : Train Loss of 0.97540 ; Valid Loss of 2.20585 ; Accuracy of 0.50781\n","Epoch 43 : Train Loss of 0.97454 ; Valid Loss of 2.23309 ; Accuracy of 0.50293\n","Epoch 44 : Train Loss of 0.97339 ; Valid Loss of 2.24710 ; Accuracy of 0.50684\n","Epoch 45 : Train Loss of 0.97117 ; Valid Loss of 2.23599 ; Accuracy of 0.50195\n","Epoch 46 : Train Loss of 0.95948 ; Valid Loss of 2.20230 ; Accuracy of 0.49414\n","Epoch 47 : Train Loss of 0.96898 ; Valid Loss of 2.23633 ; Accuracy of 0.50000\n","Epoch 48 : Train Loss of 0.96717 ; Valid Loss of 2.23546 ; Accuracy of 0.50098\n","Epoch 49 : Train Loss of 0.95673 ; Valid Loss of 2.24697 ; Accuracy of 0.50000\n","Epoch 50 : Train Loss of 0.95728 ; Valid Loss of 2.20948 ; Accuracy of 0.51172\n","Epoch 51 : Train Loss of 0.95685 ; Valid Loss of 2.23943 ; Accuracy of 0.50293\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cb7b8>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.49666\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e3780>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.46705 ; Valid Loss of 1.82202 ; Accuracy of 0.50391\n","Epoch 2 : Train Loss of 1.31884 ; Valid Loss of 1.90214 ; Accuracy of 0.49609\n","Epoch 3 : Train Loss of 1.26409 ; Valid Loss of 1.95462 ; Accuracy of 0.50098\n","Epoch 4 : Train Loss of 1.22578 ; Valid Loss of 1.97896 ; Accuracy of 0.49805\n","Epoch 5 : Train Loss of 1.20697 ; Valid Loss of 2.01042 ; Accuracy of 0.49121\n","Epoch 6 : Train Loss of 1.18202 ; Valid Loss of 2.03251 ; Accuracy of 0.49902\n","Epoch 7 : Train Loss of 1.17129 ; Valid Loss of 2.03387 ; Accuracy of 0.49902\n","Epoch 8 : Train Loss of 1.14259 ; Valid Loss of 2.08501 ; Accuracy of 0.50195\n","Epoch 9 : Train Loss of 1.14033 ; Valid Loss of 2.05463 ; Accuracy of 0.50879\n","Epoch 10 : Train Loss of 1.12583 ; Valid Loss of 2.04194 ; Accuracy of 0.51855\n","Epoch 11 : Train Loss of 1.11039 ; Valid Loss of 2.09361 ; Accuracy of 0.49805\n","Epoch 12 : Train Loss of 1.10981 ; Valid Loss of 2.06209 ; Accuracy of 0.51074\n","Epoch 13 : Train Loss of 1.09679 ; Valid Loss of 2.08359 ; Accuracy of 0.50586\n","Epoch 14 : Train Loss of 1.09317 ; Valid Loss of 2.06290 ; Accuracy of 0.50879\n","Epoch 15 : Train Loss of 1.08016 ; Valid Loss of 2.08922 ; Accuracy of 0.50098\n","Epoch 16 : Train Loss of 1.06819 ; Valid Loss of 2.09235 ; Accuracy of 0.51074\n","Epoch 17 : Train Loss of 1.07162 ; Valid Loss of 2.07439 ; Accuracy of 0.50781\n","Epoch 18 : Train Loss of 1.05512 ; Valid Loss of 2.10616 ; Accuracy of 0.50391\n","Epoch 19 : Train Loss of 1.04769 ; Valid Loss of 2.09164 ; Accuracy of 0.51660\n","Epoch 20 : Train Loss of 1.05483 ; Valid Loss of 2.10728 ; Accuracy of 0.51172\n","Epoch 21 : Train Loss of 1.05005 ; Valid Loss of 2.14468 ; Accuracy of 0.50781\n","Epoch 22 : Train Loss of 1.04122 ; Valid Loss of 2.08316 ; Accuracy of 0.51465\n","Epoch 23 : Train Loss of 1.03418 ; Valid Loss of 2.12270 ; Accuracy of 0.50977\n","Epoch 24 : Train Loss of 1.01974 ; Valid Loss of 2.07056 ; Accuracy of 0.51367\n","Epoch 25 : Train Loss of 1.02375 ; Valid Loss of 2.07728 ; Accuracy of 0.51953\n","Epoch 26 : Train Loss of 1.01668 ; Valid Loss of 2.11882 ; Accuracy of 0.50977\n","Epoch 27 : Train Loss of 1.00863 ; Valid Loss of 2.10368 ; Accuracy of 0.50977\n","Epoch 28 : Train Loss of 1.01252 ; Valid Loss of 2.06388 ; Accuracy of 0.51562\n","Epoch 29 : Train Loss of 1.00522 ; Valid Loss of 2.11090 ; Accuracy of 0.51465\n","Epoch 30 : Train Loss of 0.99832 ; Valid Loss of 2.09675 ; Accuracy of 0.50586\n","Epoch 31 : Train Loss of 0.99561 ; Valid Loss of 2.06435 ; Accuracy of 0.51855\n","Epoch 32 : Train Loss of 0.99258 ; Valid Loss of 2.13076 ; Accuracy of 0.51270\n","Epoch 33 : Train Loss of 0.99012 ; Valid Loss of 2.12458 ; Accuracy of 0.51074\n","Epoch 34 : Train Loss of 0.99906 ; Valid Loss of 2.08915 ; Accuracy of 0.52148\n","Epoch 35 : Train Loss of 0.97790 ; Valid Loss of 2.13365 ; Accuracy of 0.50488\n","Epoch 36 : Train Loss of 0.97952 ; Valid Loss of 2.07155 ; Accuracy of 0.52344\n","Epoch 37 : Train Loss of 0.97816 ; Valid Loss of 2.10210 ; Accuracy of 0.50977\n","Epoch 38 : Train Loss of 0.98443 ; Valid Loss of 2.09246 ; Accuracy of 0.51758\n","Epoch 39 : Train Loss of 0.97424 ; Valid Loss of 2.10286 ; Accuracy of 0.50195\n","Epoch 40 : Train Loss of 0.97072 ; Valid Loss of 2.10624 ; Accuracy of 0.51270\n","Epoch 41 : Train Loss of 0.96921 ; Valid Loss of 2.17670 ; Accuracy of 0.50000\n","Epoch 42 : Train Loss of 0.96595 ; Valid Loss of 2.12634 ; Accuracy of 0.51270\n","Epoch 43 : Train Loss of 0.96442 ; Valid Loss of 2.12709 ; Accuracy of 0.51172\n","Epoch 44 : Train Loss of 0.95759 ; Valid Loss of 2.06684 ; Accuracy of 0.51953\n","Epoch 45 : Train Loss of 0.95403 ; Valid Loss of 2.12396 ; Accuracy of 0.51953\n","Epoch 46 : Train Loss of 0.95293 ; Valid Loss of 2.13202 ; Accuracy of 0.51855\n","Epoch 47 : Train Loss of 0.95199 ; Valid Loss of 2.11848 ; Accuracy of 0.52051\n","Epoch 48 : Train Loss of 0.94975 ; Valid Loss of 2.15301 ; Accuracy of 0.52344\n","Epoch 49 : Train Loss of 0.95065 ; Valid Loss of 2.16064 ; Accuracy of 0.51172\n","Epoch 50 : Train Loss of 0.94774 ; Valid Loss of 2.11961 ; Accuracy of 0.51367\n","Epoch 51 : Train Loss of 0.94386 ; Valid Loss of 2.10517 ; Accuracy of 0.52344\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0c2748>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.52783\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cb518>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.49486 ; Valid Loss of 1.69886 ; Accuracy of 0.54199\n","Epoch 2 : Train Loss of 1.34647 ; Valid Loss of 1.73545 ; Accuracy of 0.54102\n","Epoch 3 : Train Loss of 1.30816 ; Valid Loss of 1.81023 ; Accuracy of 0.52832\n","Epoch 4 : Train Loss of 1.26070 ; Valid Loss of 1.77474 ; Accuracy of 0.53027\n","Epoch 5 : Train Loss of 1.24360 ; Valid Loss of 1.81965 ; Accuracy of 0.53516\n","Epoch 6 : Train Loss of 1.22748 ; Valid Loss of 1.88021 ; Accuracy of 0.52148\n","Epoch 7 : Train Loss of 1.21407 ; Valid Loss of 1.84612 ; Accuracy of 0.53125\n","Epoch 8 : Train Loss of 1.18974 ; Valid Loss of 1.89837 ; Accuracy of 0.52930\n","Epoch 9 : Train Loss of 1.18455 ; Valid Loss of 1.86169 ; Accuracy of 0.53906\n","Epoch 10 : Train Loss of 1.15933 ; Valid Loss of 1.92467 ; Accuracy of 0.53125\n","Epoch 11 : Train Loss of 1.16482 ; Valid Loss of 1.90370 ; Accuracy of 0.53906\n","Epoch 12 : Train Loss of 1.14018 ; Valid Loss of 1.91349 ; Accuracy of 0.52734\n","Epoch 13 : Train Loss of 1.12480 ; Valid Loss of 1.95051 ; Accuracy of 0.53027\n","Epoch 14 : Train Loss of 1.12047 ; Valid Loss of 1.90124 ; Accuracy of 0.52832\n","Epoch 15 : Train Loss of 1.11362 ; Valid Loss of 1.90635 ; Accuracy of 0.52930\n","Epoch 16 : Train Loss of 1.10356 ; Valid Loss of 1.91600 ; Accuracy of 0.53418\n","Epoch 17 : Train Loss of 1.09332 ; Valid Loss of 2.00692 ; Accuracy of 0.51855\n","Epoch 18 : Train Loss of 1.10541 ; Valid Loss of 1.96122 ; Accuracy of 0.52441\n","Epoch 19 : Train Loss of 1.08924 ; Valid Loss of 1.97766 ; Accuracy of 0.51855\n","Epoch 20 : Train Loss of 1.07642 ; Valid Loss of 1.95777 ; Accuracy of 0.52246\n","Epoch 21 : Train Loss of 1.06650 ; Valid Loss of 1.93876 ; Accuracy of 0.53320\n","Epoch 22 : Train Loss of 1.07398 ; Valid Loss of 1.98153 ; Accuracy of 0.52734\n","Epoch 23 : Train Loss of 1.05913 ; Valid Loss of 1.92407 ; Accuracy of 0.53320\n","Epoch 24 : Train Loss of 1.05734 ; Valid Loss of 1.93666 ; Accuracy of 0.53125\n","Epoch 25 : Train Loss of 1.04859 ; Valid Loss of 1.97153 ; Accuracy of 0.53125\n","Epoch 26 : Train Loss of 1.03784 ; Valid Loss of 1.95208 ; Accuracy of 0.53223\n","Epoch 27 : Train Loss of 1.03979 ; Valid Loss of 1.94918 ; Accuracy of 0.52344\n","Epoch 28 : Train Loss of 1.02929 ; Valid Loss of 1.98149 ; Accuracy of 0.51758\n","Epoch 29 : Train Loss of 1.02780 ; Valid Loss of 2.03094 ; Accuracy of 0.50684\n","Epoch 30 : Train Loss of 1.01852 ; Valid Loss of 1.98357 ; Accuracy of 0.52441\n","Epoch 31 : Train Loss of 1.01613 ; Valid Loss of 1.98289 ; Accuracy of 0.52051\n","Epoch 32 : Train Loss of 1.00727 ; Valid Loss of 2.00644 ; Accuracy of 0.52344\n","Epoch 33 : Train Loss of 1.01978 ; Valid Loss of 1.97940 ; Accuracy of 0.52344\n","Epoch 34 : Train Loss of 1.01302 ; Valid Loss of 2.01999 ; Accuracy of 0.51660\n","Epoch 35 : Train Loss of 1.00223 ; Valid Loss of 1.98516 ; Accuracy of 0.52148\n","Epoch 36 : Train Loss of 0.99672 ; Valid Loss of 1.95792 ; Accuracy of 0.53125\n","Epoch 37 : Train Loss of 0.99017 ; Valid Loss of 2.00911 ; Accuracy of 0.50977\n","Epoch 38 : Train Loss of 1.00029 ; Valid Loss of 1.98818 ; Accuracy of 0.52637\n","Epoch 39 : Train Loss of 0.98592 ; Valid Loss of 1.96471 ; Accuracy of 0.53418\n","Epoch 40 : Train Loss of 0.98294 ; Valid Loss of 2.00209 ; Accuracy of 0.53320\n","Epoch 41 : Train Loss of 0.98555 ; Valid Loss of 1.95088 ; Accuracy of 0.54590\n","Epoch 42 : Train Loss of 0.97259 ; Valid Loss of 2.02324 ; Accuracy of 0.53125\n","Epoch 43 : Train Loss of 0.97636 ; Valid Loss of 2.02067 ; Accuracy of 0.52539\n","Epoch 44 : Train Loss of 0.97237 ; Valid Loss of 1.98023 ; Accuracy of 0.53125\n","Epoch 45 : Train Loss of 0.96536 ; Valid Loss of 1.96247 ; Accuracy of 0.53711\n","Epoch 46 : Train Loss of 0.97256 ; Valid Loss of 1.99961 ; Accuracy of 0.52930\n","Epoch 47 : Train Loss of 0.96748 ; Valid Loss of 1.98030 ; Accuracy of 0.53516\n","Epoch 48 : Train Loss of 0.95873 ; Valid Loss of 1.94157 ; Accuracy of 0.54199\n","Epoch 49 : Train Loss of 0.95503 ; Valid Loss of 2.04217 ; Accuracy of 0.52539\n","Epoch 50 : Train Loss of 0.95197 ; Valid Loss of 1.99060 ; Accuracy of 0.53320\n","Epoch 51 : Train Loss of 0.95805 ; Valid Loss of 2.03187 ; Accuracy of 0.53027\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0d9e80>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.61569\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0d9240>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.55858 ; Valid Loss of 2.15714 ; Accuracy of 0.49219\n","Epoch 2 : Train Loss of 1.36433 ; Valid Loss of 2.18277 ; Accuracy of 0.48926\n","Epoch 3 : Train Loss of 1.28873 ; Valid Loss of 2.16585 ; Accuracy of 0.49512\n","Epoch 4 : Train Loss of 1.25691 ; Valid Loss of 2.28253 ; Accuracy of 0.47754\n","Epoch 5 : Train Loss of 1.23281 ; Valid Loss of 2.30245 ; Accuracy of 0.47949\n","Epoch 6 : Train Loss of 1.20934 ; Valid Loss of 2.29706 ; Accuracy of 0.49219\n","Epoch 7 : Train Loss of 1.18953 ; Valid Loss of 2.33233 ; Accuracy of 0.48145\n","Epoch 8 : Train Loss of 1.18640 ; Valid Loss of 2.37660 ; Accuracy of 0.47266\n","Epoch 9 : Train Loss of 1.16646 ; Valid Loss of 2.33723 ; Accuracy of 0.48633\n","Epoch 10 : Train Loss of 1.15752 ; Valid Loss of 2.40187 ; Accuracy of 0.47852\n","Epoch 11 : Train Loss of 1.15534 ; Valid Loss of 2.35919 ; Accuracy of 0.47656\n","Epoch 12 : Train Loss of 1.14004 ; Valid Loss of 2.34126 ; Accuracy of 0.48145\n","Epoch 13 : Train Loss of 1.12718 ; Valid Loss of 2.33484 ; Accuracy of 0.48047\n","Epoch 14 : Train Loss of 1.11527 ; Valid Loss of 2.36516 ; Accuracy of 0.47656\n","Epoch 15 : Train Loss of 1.10855 ; Valid Loss of 2.36774 ; Accuracy of 0.47852\n","Epoch 16 : Train Loss of 1.10309 ; Valid Loss of 2.34713 ; Accuracy of 0.49023\n","Epoch 17 : Train Loss of 1.08588 ; Valid Loss of 2.32772 ; Accuracy of 0.48438\n","Epoch 18 : Train Loss of 1.09024 ; Valid Loss of 2.32361 ; Accuracy of 0.49512\n","Epoch 19 : Train Loss of 1.07951 ; Valid Loss of 2.32813 ; Accuracy of 0.48438\n","Epoch 20 : Train Loss of 1.06454 ; Valid Loss of 2.31872 ; Accuracy of 0.49121\n","Epoch 21 : Train Loss of 1.07184 ; Valid Loss of 2.35378 ; Accuracy of 0.48730\n","Epoch 22 : Train Loss of 1.04917 ; Valid Loss of 2.30347 ; Accuracy of 0.49219\n","Epoch 23 : Train Loss of 1.05424 ; Valid Loss of 2.33528 ; Accuracy of 0.48730\n","Epoch 24 : Train Loss of 1.05111 ; Valid Loss of 2.34444 ; Accuracy of 0.49609\n","Epoch 25 : Train Loss of 1.03386 ; Valid Loss of 2.33412 ; Accuracy of 0.48926\n","Epoch 26 : Train Loss of 1.04034 ; Valid Loss of 2.30284 ; Accuracy of 0.49707\n","Epoch 27 : Train Loss of 1.03608 ; Valid Loss of 2.33581 ; Accuracy of 0.49414\n","Epoch 28 : Train Loss of 1.02716 ; Valid Loss of 2.25771 ; Accuracy of 0.49219\n","Epoch 29 : Train Loss of 1.02683 ; Valid Loss of 2.35021 ; Accuracy of 0.47949\n","Epoch 30 : Train Loss of 1.02508 ; Valid Loss of 2.28083 ; Accuracy of 0.50391\n","Epoch 31 : Train Loss of 1.01187 ; Valid Loss of 2.35511 ; Accuracy of 0.49121\n","Epoch 32 : Train Loss of 1.00973 ; Valid Loss of 2.27241 ; Accuracy of 0.50684\n","Epoch 33 : Train Loss of 1.00928 ; Valid Loss of 2.28647 ; Accuracy of 0.51562\n","Epoch 34 : Train Loss of 1.00721 ; Valid Loss of 2.27481 ; Accuracy of 0.50195\n","Epoch 35 : Train Loss of 1.00348 ; Valid Loss of 2.27610 ; Accuracy of 0.50586\n","Epoch 36 : Train Loss of 0.99889 ; Valid Loss of 2.31914 ; Accuracy of 0.49805\n","Epoch 37 : Train Loss of 0.98999 ; Valid Loss of 2.33059 ; Accuracy of 0.49609\n","Epoch 38 : Train Loss of 0.98949 ; Valid Loss of 2.31196 ; Accuracy of 0.50977\n","Epoch 39 : Train Loss of 0.98148 ; Valid Loss of 2.33637 ; Accuracy of 0.49414\n","Epoch 40 : Train Loss of 0.98143 ; Valid Loss of 2.29839 ; Accuracy of 0.50977\n","Epoch 41 : Train Loss of 0.98196 ; Valid Loss of 2.30652 ; Accuracy of 0.50391\n","Epoch 42 : Train Loss of 0.97317 ; Valid Loss of 2.22095 ; Accuracy of 0.51660\n","Epoch 43 : Train Loss of 0.96690 ; Valid Loss of 2.31664 ; Accuracy of 0.50586\n","Epoch 44 : Train Loss of 0.96658 ; Valid Loss of 2.27700 ; Accuracy of 0.51172\n","Epoch 45 : Train Loss of 0.97821 ; Valid Loss of 2.32564 ; Accuracy of 0.49414\n","Epoch 46 : Train Loss of 0.95369 ; Valid Loss of 2.27567 ; Accuracy of 0.50781\n","Epoch 47 : Train Loss of 0.95588 ; Valid Loss of 2.29665 ; Accuracy of 0.50195\n","Epoch 48 : Train Loss of 0.95973 ; Valid Loss of 2.30641 ; Accuracy of 0.50293\n","Epoch 49 : Train Loss of 0.95757 ; Valid Loss of 2.34622 ; Accuracy of 0.50586\n","Epoch 50 : Train Loss of 0.95638 ; Valid Loss of 2.29747 ; Accuracy of 0.51758\n","Epoch 51 : Train Loss of 0.95124 ; Valid Loss of 2.31394 ; Accuracy of 0.51074\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0e3940>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.55937\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0d9860>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.56273 ; Valid Loss of 1.85014 ; Accuracy of 0.55078\n","Epoch 2 : Train Loss of 1.38516 ; Valid Loss of 1.89748 ; Accuracy of 0.53809\n","Epoch 3 : Train Loss of 1.30764 ; Valid Loss of 1.90330 ; Accuracy of 0.52441\n","Epoch 4 : Train Loss of 1.28908 ; Valid Loss of 1.88246 ; Accuracy of 0.52734\n","Epoch 5 : Train Loss of 1.26330 ; Valid Loss of 1.96802 ; Accuracy of 0.51074\n","Epoch 6 : Train Loss of 1.24329 ; Valid Loss of 1.99096 ; Accuracy of 0.51855\n","Epoch 7 : Train Loss of 1.23024 ; Valid Loss of 1.97127 ; Accuracy of 0.53125\n","Epoch 8 : Train Loss of 1.21255 ; Valid Loss of 1.98637 ; Accuracy of 0.51562\n","Epoch 9 : Train Loss of 1.19299 ; Valid Loss of 2.01285 ; Accuracy of 0.51953\n","Epoch 10 : Train Loss of 1.18073 ; Valid Loss of 1.98168 ; Accuracy of 0.51758\n","Epoch 11 : Train Loss of 1.16251 ; Valid Loss of 2.00377 ; Accuracy of 0.51855\n","Epoch 12 : Train Loss of 1.15555 ; Valid Loss of 2.00152 ; Accuracy of 0.51270\n","Epoch 13 : Train Loss of 1.14349 ; Valid Loss of 2.03059 ; Accuracy of 0.50488\n","Epoch 14 : Train Loss of 1.12833 ; Valid Loss of 1.99599 ; Accuracy of 0.52051\n","Epoch 15 : Train Loss of 1.13150 ; Valid Loss of 2.02611 ; Accuracy of 0.51270\n","Epoch 16 : Train Loss of 1.12641 ; Valid Loss of 2.04197 ; Accuracy of 0.51660\n","Epoch 17 : Train Loss of 1.11356 ; Valid Loss of 2.07101 ; Accuracy of 0.51953\n","Epoch 18 : Train Loss of 1.10298 ; Valid Loss of 2.08163 ; Accuracy of 0.50586\n","Epoch 19 : Train Loss of 1.10353 ; Valid Loss of 2.07272 ; Accuracy of 0.51074\n","Epoch 20 : Train Loss of 1.09450 ; Valid Loss of 2.07341 ; Accuracy of 0.50684\n","Epoch 21 : Train Loss of 1.09474 ; Valid Loss of 1.99721 ; Accuracy of 0.51660\n","Epoch 22 : Train Loss of 1.08182 ; Valid Loss of 2.01680 ; Accuracy of 0.51855\n","Epoch 23 : Train Loss of 1.06774 ; Valid Loss of 2.04270 ; Accuracy of 0.52734\n","Epoch 24 : Train Loss of 1.06319 ; Valid Loss of 2.02034 ; Accuracy of 0.52246\n","Epoch 25 : Train Loss of 1.06340 ; Valid Loss of 2.03574 ; Accuracy of 0.52246\n","Epoch 26 : Train Loss of 1.06183 ; Valid Loss of 2.08299 ; Accuracy of 0.52246\n","Epoch 27 : Train Loss of 1.04565 ; Valid Loss of 2.08442 ; Accuracy of 0.52441\n","Epoch 28 : Train Loss of 1.05165 ; Valid Loss of 2.07237 ; Accuracy of 0.53125\n","Epoch 29 : Train Loss of 1.04804 ; Valid Loss of 2.08439 ; Accuracy of 0.52344\n","Epoch 30 : Train Loss of 1.04193 ; Valid Loss of 2.09768 ; Accuracy of 0.52637\n","Epoch 31 : Train Loss of 1.03933 ; Valid Loss of 2.05078 ; Accuracy of 0.53516\n","Epoch 32 : Train Loss of 1.02648 ; Valid Loss of 2.04497 ; Accuracy of 0.53027\n","Epoch 33 : Train Loss of 1.01538 ; Valid Loss of 2.07399 ; Accuracy of 0.52734\n","Epoch 34 : Train Loss of 1.01672 ; Valid Loss of 2.01446 ; Accuracy of 0.52637\n","Epoch 35 : Train Loss of 1.02306 ; Valid Loss of 2.04511 ; Accuracy of 0.54004\n","Epoch 36 : Train Loss of 1.02312 ; Valid Loss of 2.09078 ; Accuracy of 0.53125\n","Epoch 37 : Train Loss of 1.01158 ; Valid Loss of 2.10679 ; Accuracy of 0.52539\n","Epoch 38 : Train Loss of 1.00523 ; Valid Loss of 2.09086 ; Accuracy of 0.52832\n","Epoch 39 : Train Loss of 0.98657 ; Valid Loss of 2.08290 ; Accuracy of 0.53809\n","Epoch 40 : Train Loss of 1.00535 ; Valid Loss of 2.05784 ; Accuracy of 0.53320\n","Epoch 41 : Train Loss of 1.00422 ; Valid Loss of 2.09457 ; Accuracy of 0.52539\n","Epoch 42 : Train Loss of 0.99717 ; Valid Loss of 2.08178 ; Accuracy of 0.52344\n","Epoch 43 : Train Loss of 0.99524 ; Valid Loss of 2.14139 ; Accuracy of 0.52441\n","Epoch 44 : Train Loss of 0.99064 ; Valid Loss of 2.08301 ; Accuracy of 0.52148\n","Epoch 45 : Train Loss of 0.98817 ; Valid Loss of 2.13012 ; Accuracy of 0.52051\n","Epoch 46 : Train Loss of 0.97343 ; Valid Loss of 2.10424 ; Accuracy of 0.52832\n","Epoch 47 : Train Loss of 0.97422 ; Valid Loss of 2.07435 ; Accuracy of 0.53516\n","Epoch 48 : Train Loss of 0.97723 ; Valid Loss of 2.12979 ; Accuracy of 0.52246\n","Epoch 49 : Train Loss of 0.96937 ; Valid Loss of 2.07536 ; Accuracy of 0.52051\n","Epoch 50 : Train Loss of 0.97292 ; Valid Loss of 2.08857 ; Accuracy of 0.51562\n","Epoch 51 : Train Loss of 0.96696 ; Valid Loss of 2.08188 ; Accuracy of 0.53320\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0c2ef0>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.47995\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cb828>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.58432 ; Valid Loss of 1.70880 ; Accuracy of 0.49512\n","Epoch 2 : Train Loss of 1.36924 ; Valid Loss of 1.82715 ; Accuracy of 0.50879\n","Epoch 3 : Train Loss of 1.29614 ; Valid Loss of 1.85524 ; Accuracy of 0.50684\n","Epoch 4 : Train Loss of 1.26629 ; Valid Loss of 1.87902 ; Accuracy of 0.49609\n","Epoch 5 : Train Loss of 1.24507 ; Valid Loss of 1.87875 ; Accuracy of 0.50977\n","Epoch 6 : Train Loss of 1.23438 ; Valid Loss of 1.96087 ; Accuracy of 0.48828\n","Epoch 7 : Train Loss of 1.19734 ; Valid Loss of 1.92900 ; Accuracy of 0.50879\n","Epoch 8 : Train Loss of 1.18156 ; Valid Loss of 1.95400 ; Accuracy of 0.50586\n","Epoch 9 : Train Loss of 1.17546 ; Valid Loss of 2.02885 ; Accuracy of 0.49512\n","Epoch 10 : Train Loss of 1.16358 ; Valid Loss of 1.99235 ; Accuracy of 0.50586\n","Epoch 11 : Train Loss of 1.15634 ; Valid Loss of 2.01763 ; Accuracy of 0.49121\n","Epoch 12 : Train Loss of 1.13514 ; Valid Loss of 1.98725 ; Accuracy of 0.50000\n","Epoch 13 : Train Loss of 1.12565 ; Valid Loss of 2.01195 ; Accuracy of 0.50879\n","Epoch 14 : Train Loss of 1.12478 ; Valid Loss of 2.02280 ; Accuracy of 0.50195\n","Epoch 15 : Train Loss of 1.09989 ; Valid Loss of 2.04986 ; Accuracy of 0.49023\n","Epoch 16 : Train Loss of 1.11053 ; Valid Loss of 2.05815 ; Accuracy of 0.49512\n","Epoch 17 : Train Loss of 1.09025 ; Valid Loss of 2.03185 ; Accuracy of 0.49805\n","Epoch 18 : Train Loss of 1.09085 ; Valid Loss of 2.02544 ; Accuracy of 0.50586\n","Epoch 19 : Train Loss of 1.07621 ; Valid Loss of 2.04969 ; Accuracy of 0.50586\n","Epoch 20 : Train Loss of 1.07267 ; Valid Loss of 2.04810 ; Accuracy of 0.50293\n","Epoch 21 : Train Loss of 1.07464 ; Valid Loss of 2.08406 ; Accuracy of 0.50098\n","Epoch 22 : Train Loss of 1.06364 ; Valid Loss of 2.03469 ; Accuracy of 0.49707\n","Epoch 23 : Train Loss of 1.05798 ; Valid Loss of 2.06718 ; Accuracy of 0.49121\n","Epoch 24 : Train Loss of 1.04656 ; Valid Loss of 2.07863 ; Accuracy of 0.50195\n","Epoch 25 : Train Loss of 1.05188 ; Valid Loss of 1.99750 ; Accuracy of 0.50391\n","Epoch 26 : Train Loss of 1.04213 ; Valid Loss of 2.06364 ; Accuracy of 0.49902\n","Epoch 27 : Train Loss of 1.03906 ; Valid Loss of 2.06999 ; Accuracy of 0.50781\n","Epoch 28 : Train Loss of 1.03329 ; Valid Loss of 2.09441 ; Accuracy of 0.49609\n","Epoch 29 : Train Loss of 1.03270 ; Valid Loss of 2.06386 ; Accuracy of 0.50293\n","Epoch 30 : Train Loss of 1.03042 ; Valid Loss of 2.05588 ; Accuracy of 0.50781\n","Epoch 31 : Train Loss of 1.02102 ; Valid Loss of 2.03036 ; Accuracy of 0.51172\n","Epoch 32 : Train Loss of 1.01365 ; Valid Loss of 2.07150 ; Accuracy of 0.50391\n","Epoch 33 : Train Loss of 1.00855 ; Valid Loss of 2.05870 ; Accuracy of 0.51660\n","Epoch 34 : Train Loss of 1.01062 ; Valid Loss of 2.04830 ; Accuracy of 0.51367\n","Epoch 35 : Train Loss of 1.00336 ; Valid Loss of 2.08542 ; Accuracy of 0.50977\n","Epoch 36 : Train Loss of 0.99911 ; Valid Loss of 2.07144 ; Accuracy of 0.51270\n","Epoch 37 : Train Loss of 0.99779 ; Valid Loss of 2.07229 ; Accuracy of 0.50781\n","Epoch 38 : Train Loss of 0.98232 ; Valid Loss of 2.06173 ; Accuracy of 0.51074\n","Epoch 39 : Train Loss of 0.98850 ; Valid Loss of 2.12277 ; Accuracy of 0.49609\n","Epoch 40 : Train Loss of 0.99018 ; Valid Loss of 2.06108 ; Accuracy of 0.51758\n","Epoch 41 : Train Loss of 0.98046 ; Valid Loss of 2.05894 ; Accuracy of 0.50684\n","Epoch 42 : Train Loss of 0.98643 ; Valid Loss of 2.09645 ; Accuracy of 0.50586\n","Epoch 43 : Train Loss of 0.97522 ; Valid Loss of 2.10701 ; Accuracy of 0.51074\n","Epoch 44 : Train Loss of 0.97782 ; Valid Loss of 2.09571 ; Accuracy of 0.50293\n","Epoch 45 : Train Loss of 0.96863 ; Valid Loss of 2.09705 ; Accuracy of 0.50879\n","Epoch 46 : Train Loss of 0.95999 ; Valid Loss of 2.07946 ; Accuracy of 0.51074\n","Epoch 47 : Train Loss of 0.96686 ; Valid Loss of 2.10035 ; Accuracy of 0.50879\n","Epoch 48 : Train Loss of 0.96298 ; Valid Loss of 2.11478 ; Accuracy of 0.50098\n","Epoch 49 : Train Loss of 0.96437 ; Valid Loss of 2.07246 ; Accuracy of 0.50684\n","Epoch 50 : Train Loss of 0.95352 ; Valid Loss of 2.06987 ; Accuracy of 0.50879\n","Epoch 51 : Train Loss of 0.95730 ; Valid Loss of 2.13824 ; Accuracy of 0.50195\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0cb748>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.50428\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0f40f0>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.55589 ; Valid Loss of 1.74746 ; Accuracy of 0.53516\n","Epoch 2 : Train Loss of 1.36833 ; Valid Loss of 1.81736 ; Accuracy of 0.52734\n","Epoch 3 : Train Loss of 1.30543 ; Valid Loss of 1.88874 ; Accuracy of 0.52441\n","Epoch 4 : Train Loss of 1.26131 ; Valid Loss of 1.87605 ; Accuracy of 0.52344\n","Epoch 5 : Train Loss of 1.23216 ; Valid Loss of 1.92469 ; Accuracy of 0.52148\n","Epoch 6 : Train Loss of 1.21771 ; Valid Loss of 1.89353 ; Accuracy of 0.51953\n","Epoch 7 : Train Loss of 1.19026 ; Valid Loss of 1.92595 ; Accuracy of 0.52539\n","Epoch 8 : Train Loss of 1.18202 ; Valid Loss of 1.91062 ; Accuracy of 0.51270\n","Epoch 9 : Train Loss of 1.18007 ; Valid Loss of 1.95074 ; Accuracy of 0.51855\n","Epoch 10 : Train Loss of 1.16728 ; Valid Loss of 1.94244 ; Accuracy of 0.52637\n","Epoch 11 : Train Loss of 1.14728 ; Valid Loss of 1.93858 ; Accuracy of 0.51855\n","Epoch 12 : Train Loss of 1.12764 ; Valid Loss of 1.96082 ; Accuracy of 0.52344\n","Epoch 13 : Train Loss of 1.12877 ; Valid Loss of 1.92755 ; Accuracy of 0.51953\n","Epoch 14 : Train Loss of 1.11129 ; Valid Loss of 1.93565 ; Accuracy of 0.52148\n","Epoch 15 : Train Loss of 1.11187 ; Valid Loss of 1.93672 ; Accuracy of 0.51953\n","Epoch 16 : Train Loss of 1.10236 ; Valid Loss of 1.93620 ; Accuracy of 0.52344\n","Epoch 17 : Train Loss of 1.09363 ; Valid Loss of 1.95037 ; Accuracy of 0.51367\n","Epoch 18 : Train Loss of 1.08240 ; Valid Loss of 1.95397 ; Accuracy of 0.51367\n","Epoch 19 : Train Loss of 1.08339 ; Valid Loss of 1.93979 ; Accuracy of 0.51953\n","Epoch 20 : Train Loss of 1.07681 ; Valid Loss of 2.00491 ; Accuracy of 0.50977\n","Epoch 21 : Train Loss of 1.06119 ; Valid Loss of 1.99098 ; Accuracy of 0.51172\n","Epoch 22 : Train Loss of 1.06277 ; Valid Loss of 1.97346 ; Accuracy of 0.51660\n","Epoch 23 : Train Loss of 1.06068 ; Valid Loss of 1.95452 ; Accuracy of 0.52148\n","Epoch 24 : Train Loss of 1.05299 ; Valid Loss of 1.98197 ; Accuracy of 0.52148\n","Epoch 25 : Train Loss of 1.04285 ; Valid Loss of 1.94971 ; Accuracy of 0.51855\n","Epoch 26 : Train Loss of 1.03839 ; Valid Loss of 1.96503 ; Accuracy of 0.52148\n","Epoch 27 : Train Loss of 1.03233 ; Valid Loss of 1.93158 ; Accuracy of 0.52637\n","Epoch 28 : Train Loss of 1.03488 ; Valid Loss of 1.97448 ; Accuracy of 0.53027\n","Epoch 29 : Train Loss of 1.03025 ; Valid Loss of 2.01074 ; Accuracy of 0.51465\n","Epoch 30 : Train Loss of 1.01391 ; Valid Loss of 1.96326 ; Accuracy of 0.51270\n","Epoch 31 : Train Loss of 1.01247 ; Valid Loss of 2.02483 ; Accuracy of 0.51074\n","Epoch 32 : Train Loss of 1.01074 ; Valid Loss of 1.95436 ; Accuracy of 0.52246\n","Epoch 33 : Train Loss of 0.99579 ; Valid Loss of 1.97116 ; Accuracy of 0.51465\n","Epoch 34 : Train Loss of 1.01227 ; Valid Loss of 2.00983 ; Accuracy of 0.51270\n","Epoch 35 : Train Loss of 0.99579 ; Valid Loss of 2.03540 ; Accuracy of 0.50781\n","Epoch 36 : Train Loss of 1.00076 ; Valid Loss of 2.02798 ; Accuracy of 0.51367\n","Epoch 37 : Train Loss of 1.00003 ; Valid Loss of 2.00305 ; Accuracy of 0.51660\n","Epoch 38 : Train Loss of 0.98892 ; Valid Loss of 2.01946 ; Accuracy of 0.51465\n","Epoch 39 : Train Loss of 0.99226 ; Valid Loss of 1.95938 ; Accuracy of 0.53223\n","Epoch 40 : Train Loss of 0.98264 ; Valid Loss of 2.00414 ; Accuracy of 0.51660\n","Epoch 41 : Train Loss of 0.97150 ; Valid Loss of 2.03549 ; Accuracy of 0.52051\n","Epoch 42 : Train Loss of 0.96821 ; Valid Loss of 2.01169 ; Accuracy of 0.52051\n","Epoch 43 : Train Loss of 0.97386 ; Valid Loss of 1.96875 ; Accuracy of 0.52734\n","Epoch 44 : Train Loss of 0.96136 ; Valid Loss of 2.03323 ; Accuracy of 0.51953\n","Epoch 45 : Train Loss of 0.96759 ; Valid Loss of 1.98119 ; Accuracy of 0.52637\n","Epoch 46 : Train Loss of 0.96959 ; Valid Loss of 2.05250 ; Accuracy of 0.51074\n","Epoch 47 : Train Loss of 0.97054 ; Valid Loss of 1.97563 ; Accuracy of 0.52637\n","Epoch 48 : Train Loss of 0.95957 ; Valid Loss of 2.00093 ; Accuracy of 0.52930\n","Epoch 49 : Train Loss of 0.95437 ; Valid Loss of 2.05158 ; Accuracy of 0.52051\n","Epoch 50 : Train Loss of 0.95188 ; Valid Loss of 2.04792 ; Accuracy of 0.51953\n","Epoch 51 : Train Loss of 0.95215 ; Valid Loss of 1.98560 ; Accuracy of 0.53027\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0f4b38>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.56155\n","Proportion of 1 is for train set is : 0.22913032643907302\n","Proportion of 1 is for valid set is : 0.5824561403508772\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0f4550>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.67182 ; Valid Loss of 1.57960 ; Accuracy of 0.51660\n","Epoch 2 : Train Loss of 1.44690 ; Valid Loss of 1.62107 ; Accuracy of 0.52539\n","Epoch 3 : Train Loss of 1.35461 ; Valid Loss of 1.65153 ; Accuracy of 0.52930\n","Epoch 4 : Train Loss of 1.33478 ; Valid Loss of 1.69257 ; Accuracy of 0.52441\n","Epoch 5 : Train Loss of 1.29713 ; Valid Loss of 1.71157 ; Accuracy of 0.52637\n","Epoch 6 : Train Loss of 1.28451 ; Valid Loss of 1.77333 ; Accuracy of 0.53027\n","Epoch 7 : Train Loss of 1.25404 ; Valid Loss of 1.75702 ; Accuracy of 0.52539\n","Epoch 8 : Train Loss of 1.22373 ; Valid Loss of 1.78117 ; Accuracy of 0.52930\n","Epoch 9 : Train Loss of 1.21756 ; Valid Loss of 1.82282 ; Accuracy of 0.51855\n","Epoch 10 : Train Loss of 1.20934 ; Valid Loss of 1.78874 ; Accuracy of 0.51367\n","Epoch 11 : Train Loss of 1.19335 ; Valid Loss of 1.84797 ; Accuracy of 0.51074\n","Epoch 12 : Train Loss of 1.17870 ; Valid Loss of 1.83184 ; Accuracy of 0.51562\n","Epoch 13 : Train Loss of 1.18307 ; Valid Loss of 1.84064 ; Accuracy of 0.53223\n","Epoch 14 : Train Loss of 1.16271 ; Valid Loss of 1.88424 ; Accuracy of 0.50781\n","Epoch 15 : Train Loss of 1.14502 ; Valid Loss of 1.87830 ; Accuracy of 0.51465\n","Epoch 16 : Train Loss of 1.13347 ; Valid Loss of 1.87073 ; Accuracy of 0.52637\n","Epoch 17 : Train Loss of 1.13365 ; Valid Loss of 1.92483 ; Accuracy of 0.50391\n","Epoch 18 : Train Loss of 1.12953 ; Valid Loss of 1.87968 ; Accuracy of 0.51953\n","Epoch 19 : Train Loss of 1.11440 ; Valid Loss of 1.91050 ; Accuracy of 0.51758\n","Epoch 20 : Train Loss of 1.10143 ; Valid Loss of 1.92490 ; Accuracy of 0.50586\n","Epoch 21 : Train Loss of 1.10129 ; Valid Loss of 1.91789 ; Accuracy of 0.50684\n","Epoch 22 : Train Loss of 1.08918 ; Valid Loss of 1.94100 ; Accuracy of 0.50293\n","Epoch 23 : Train Loss of 1.08827 ; Valid Loss of 1.96791 ; Accuracy of 0.50488\n","Epoch 24 : Train Loss of 1.09439 ; Valid Loss of 1.99945 ; Accuracy of 0.49219\n","Epoch 25 : Train Loss of 1.07324 ; Valid Loss of 1.91215 ; Accuracy of 0.51758\n","Epoch 26 : Train Loss of 1.07598 ; Valid Loss of 1.96942 ; Accuracy of 0.50586\n","Epoch 27 : Train Loss of 1.06294 ; Valid Loss of 1.95267 ; Accuracy of 0.50879\n","Epoch 28 : Train Loss of 1.06130 ; Valid Loss of 1.93942 ; Accuracy of 0.51855\n","Epoch 29 : Train Loss of 1.05825 ; Valid Loss of 2.00163 ; Accuracy of 0.51270\n","Epoch 30 : Train Loss of 1.04251 ; Valid Loss of 1.98311 ; Accuracy of 0.51074\n","Epoch 31 : Train Loss of 1.04242 ; Valid Loss of 1.98392 ; Accuracy of 0.49902\n","Epoch 32 : Train Loss of 1.04128 ; Valid Loss of 1.96265 ; Accuracy of 0.50879\n","Epoch 33 : Train Loss of 1.04032 ; Valid Loss of 2.00155 ; Accuracy of 0.50000\n","Epoch 34 : Train Loss of 1.03596 ; Valid Loss of 1.92415 ; Accuracy of 0.51465\n","Epoch 35 : Train Loss of 1.03475 ; Valid Loss of 1.96882 ; Accuracy of 0.51562\n","Epoch 36 : Train Loss of 1.03098 ; Valid Loss of 2.03790 ; Accuracy of 0.49902\n","Epoch 37 : Train Loss of 1.03637 ; Valid Loss of 1.97996 ; Accuracy of 0.51758\n","Epoch 38 : Train Loss of 1.01941 ; Valid Loss of 1.98190 ; Accuracy of 0.51074\n","Epoch 39 : Train Loss of 1.01167 ; Valid Loss of 1.99419 ; Accuracy of 0.51074\n","Epoch 40 : Train Loss of 1.00638 ; Valid Loss of 1.98641 ; Accuracy of 0.50586\n","Epoch 41 : Train Loss of 1.01210 ; Valid Loss of 2.00625 ; Accuracy of 0.51172\n","Epoch 42 : Train Loss of 1.00022 ; Valid Loss of 2.01164 ; Accuracy of 0.51855\n","Epoch 43 : Train Loss of 0.99724 ; Valid Loss of 2.06788 ; Accuracy of 0.50586\n","Epoch 44 : Train Loss of 1.00541 ; Valid Loss of 1.94884 ; Accuracy of 0.53320\n","Epoch 45 : Train Loss of 0.99974 ; Valid Loss of 1.96827 ; Accuracy of 0.51855\n","Epoch 46 : Train Loss of 0.99236 ; Valid Loss of 1.99504 ; Accuracy of 0.51465\n","Epoch 47 : Train Loss of 0.98381 ; Valid Loss of 1.97015 ; Accuracy of 0.52051\n","Epoch 48 : Train Loss of 0.98505 ; Valid Loss of 2.00185 ; Accuracy of 0.52441\n","Epoch 49 : Train Loss of 0.97862 ; Valid Loss of 1.94431 ; Accuracy of 0.52637\n","Epoch 50 : Train Loss of 0.97211 ; Valid Loss of 2.00717 ; Accuracy of 0.52051\n","Epoch 51 : Train Loss of 0.97121 ; Valid Loss of 2.02901 ; Accuracy of 0.50586\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c0f4c18>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.55951\n","Running Threshold 220\n","Args are: Namespace(date='2020-10-06', early_stopping=50, lin_layer_dropout=[0.5, 0.5], lin_layer_size=[512, 256], load_processed_data=1, log_dir_folder='total_10-06-20_512_256_lr_6e-4', lr=0.0005, model='total', production=1, save_processed_data=0, swa=0, threshold=220)\n","is score_diff in Features ? False\n","shape of data before dropping is (49296, 781)\n","shape of data after dropping is (49296, 781)\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea66cf8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.58224 ; Valid Loss of 2.04103 ; Accuracy of 0.50391\n","Epoch 2 : Train Loss of 1.41662 ; Valid Loss of 2.11402 ; Accuracy of 0.50684\n","Epoch 3 : Train Loss of 1.35611 ; Valid Loss of 2.19507 ; Accuracy of 0.50000\n","Epoch 4 : Train Loss of 1.30590 ; Valid Loss of 2.25004 ; Accuracy of 0.50293\n","Epoch 5 : Train Loss of 1.30116 ; Valid Loss of 2.25666 ; Accuracy of 0.50488\n","Epoch 6 : Train Loss of 1.27557 ; Valid Loss of 2.28665 ; Accuracy of 0.49805\n","Epoch 7 : Train Loss of 1.25262 ; Valid Loss of 2.29996 ; Accuracy of 0.50293\n","Epoch 8 : Train Loss of 1.24771 ; Valid Loss of 2.28643 ; Accuracy of 0.49316\n","Epoch 9 : Train Loss of 1.22112 ; Valid Loss of 2.30840 ; Accuracy of 0.50195\n","Epoch 10 : Train Loss of 1.23320 ; Valid Loss of 2.28989 ; Accuracy of 0.49512\n","Epoch 11 : Train Loss of 1.20119 ; Valid Loss of 2.31373 ; Accuracy of 0.51172\n","Epoch 12 : Train Loss of 1.19101 ; Valid Loss of 2.34147 ; Accuracy of 0.50488\n","Epoch 13 : Train Loss of 1.18038 ; Valid Loss of 2.30678 ; Accuracy of 0.51172\n","Epoch 14 : Train Loss of 1.17163 ; Valid Loss of 2.30635 ; Accuracy of 0.51172\n","Epoch 15 : Train Loss of 1.16737 ; Valid Loss of 2.40034 ; Accuracy of 0.49414\n","Epoch 16 : Train Loss of 1.15329 ; Valid Loss of 2.35505 ; Accuracy of 0.50000\n","Epoch 17 : Train Loss of 1.14188 ; Valid Loss of 2.39189 ; Accuracy of 0.50293\n","Epoch 18 : Train Loss of 1.13179 ; Valid Loss of 2.35886 ; Accuracy of 0.50977\n","Epoch 19 : Train Loss of 1.14435 ; Valid Loss of 2.40242 ; Accuracy of 0.51172\n","Epoch 20 : Train Loss of 1.13036 ; Valid Loss of 2.37589 ; Accuracy of 0.51270\n","Epoch 21 : Train Loss of 1.10532 ; Valid Loss of 2.39488 ; Accuracy of 0.50781\n","Epoch 22 : Train Loss of 1.11490 ; Valid Loss of 2.36829 ; Accuracy of 0.51660\n","Epoch 23 : Train Loss of 1.10717 ; Valid Loss of 2.39122 ; Accuracy of 0.51172\n","Epoch 24 : Train Loss of 1.10187 ; Valid Loss of 2.36227 ; Accuracy of 0.51660\n","Epoch 25 : Train Loss of 1.09934 ; Valid Loss of 2.36787 ; Accuracy of 0.51465\n","Epoch 26 : Train Loss of 1.09649 ; Valid Loss of 2.32510 ; Accuracy of 0.51270\n","Epoch 27 : Train Loss of 1.08576 ; Valid Loss of 2.36707 ; Accuracy of 0.50879\n","Epoch 28 : Train Loss of 1.07205 ; Valid Loss of 2.41005 ; Accuracy of 0.50488\n","Epoch 29 : Train Loss of 1.07398 ; Valid Loss of 2.41991 ; Accuracy of 0.50586\n","Epoch 30 : Train Loss of 1.06900 ; Valid Loss of 2.41736 ; Accuracy of 0.50879\n","Epoch 31 : Train Loss of 1.07373 ; Valid Loss of 2.43078 ; Accuracy of 0.50977\n","Epoch 32 : Train Loss of 1.06391 ; Valid Loss of 2.43146 ; Accuracy of 0.51758\n","Epoch 33 : Train Loss of 1.05064 ; Valid Loss of 2.39542 ; Accuracy of 0.51953\n","Epoch 34 : Train Loss of 1.04856 ; Valid Loss of 2.39391 ; Accuracy of 0.51172\n","Epoch 35 : Train Loss of 1.05547 ; Valid Loss of 2.41956 ; Accuracy of 0.52148\n","Epoch 36 : Train Loss of 1.05178 ; Valid Loss of 2.38658 ; Accuracy of 0.52344\n","Epoch 37 : Train Loss of 1.03316 ; Valid Loss of 2.45949 ; Accuracy of 0.50879\n","Epoch 38 : Train Loss of 1.04387 ; Valid Loss of 2.42574 ; Accuracy of 0.51465\n","Epoch 39 : Train Loss of 1.02989 ; Valid Loss of 2.45520 ; Accuracy of 0.52051\n","Epoch 40 : Train Loss of 1.02608 ; Valid Loss of 2.46019 ; Accuracy of 0.51074\n","Epoch 41 : Train Loss of 1.02848 ; Valid Loss of 2.41180 ; Accuracy of 0.51758\n","Epoch 42 : Train Loss of 1.02451 ; Valid Loss of 2.46018 ; Accuracy of 0.51367\n","Epoch 43 : Train Loss of 1.01574 ; Valid Loss of 2.47521 ; Accuracy of 0.51562\n","Epoch 44 : Train Loss of 1.01377 ; Valid Loss of 2.38494 ; Accuracy of 0.51562\n","Epoch 45 : Train Loss of 1.01540 ; Valid Loss of 2.45555 ; Accuracy of 0.51660\n","Epoch 46 : Train Loss of 1.00605 ; Valid Loss of 2.46405 ; Accuracy of 0.51367\n","Epoch 47 : Train Loss of 1.01017 ; Valid Loss of 2.40072 ; Accuracy of 0.51953\n","Epoch 48 : Train Loss of 0.99947 ; Valid Loss of 2.39938 ; Accuracy of 0.52539\n","Epoch 49 : Train Loss of 0.99898 ; Valid Loss of 2.40889 ; Accuracy of 0.51953\n","Epoch 50 : Train Loss of 1.00309 ; Valid Loss of 2.39575 ; Accuracy of 0.51953\n","Epoch 51 : Train Loss of 0.99799 ; Valid Loss of 2.46835 ; Accuracy of 0.50391\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c07f0>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.64663\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea68048>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.59970 ; Valid Loss of 2.01948 ; Accuracy of 0.50391\n","Epoch 2 : Train Loss of 1.41616 ; Valid Loss of 2.12054 ; Accuracy of 0.51758\n","Epoch 3 : Train Loss of 1.35686 ; Valid Loss of 2.21982 ; Accuracy of 0.50391\n","Epoch 4 : Train Loss of 1.30710 ; Valid Loss of 2.26727 ; Accuracy of 0.51855\n","Epoch 5 : Train Loss of 1.27958 ; Valid Loss of 2.27528 ; Accuracy of 0.52148\n","Epoch 6 : Train Loss of 1.26508 ; Valid Loss of 2.32765 ; Accuracy of 0.50781\n","Epoch 7 : Train Loss of 1.24735 ; Valid Loss of 2.33813 ; Accuracy of 0.50977\n","Epoch 8 : Train Loss of 1.23371 ; Valid Loss of 2.36412 ; Accuracy of 0.51270\n","Epoch 9 : Train Loss of 1.21602 ; Valid Loss of 2.38413 ; Accuracy of 0.50879\n","Epoch 10 : Train Loss of 1.20221 ; Valid Loss of 2.39447 ; Accuracy of 0.50879\n","Epoch 11 : Train Loss of 1.19110 ; Valid Loss of 2.39730 ; Accuracy of 0.50781\n","Epoch 12 : Train Loss of 1.18069 ; Valid Loss of 2.46088 ; Accuracy of 0.50293\n","Epoch 13 : Train Loss of 1.17471 ; Valid Loss of 2.40774 ; Accuracy of 0.50195\n","Epoch 14 : Train Loss of 1.16978 ; Valid Loss of 2.39365 ; Accuracy of 0.51270\n","Epoch 15 : Train Loss of 1.15019 ; Valid Loss of 2.49964 ; Accuracy of 0.50391\n","Epoch 16 : Train Loss of 1.14868 ; Valid Loss of 2.40572 ; Accuracy of 0.51562\n","Epoch 17 : Train Loss of 1.13103 ; Valid Loss of 2.45697 ; Accuracy of 0.51660\n","Epoch 18 : Train Loss of 1.12976 ; Valid Loss of 2.44949 ; Accuracy of 0.50293\n","Epoch 19 : Train Loss of 1.10343 ; Valid Loss of 2.53263 ; Accuracy of 0.49805\n","Epoch 20 : Train Loss of 1.11102 ; Valid Loss of 2.54846 ; Accuracy of 0.49902\n","Epoch 21 : Train Loss of 1.11508 ; Valid Loss of 2.48497 ; Accuracy of 0.50586\n","Epoch 22 : Train Loss of 1.09307 ; Valid Loss of 2.53436 ; Accuracy of 0.50293\n","Epoch 23 : Train Loss of 1.09718 ; Valid Loss of 2.50461 ; Accuracy of 0.50488\n","Epoch 24 : Train Loss of 1.08222 ; Valid Loss of 2.58540 ; Accuracy of 0.49316\n","Epoch 25 : Train Loss of 1.09205 ; Valid Loss of 2.49917 ; Accuracy of 0.51074\n","Epoch 26 : Train Loss of 1.08601 ; Valid Loss of 2.54315 ; Accuracy of 0.49609\n","Epoch 27 : Train Loss of 1.06409 ; Valid Loss of 2.53977 ; Accuracy of 0.50293\n","Epoch 28 : Train Loss of 1.06243 ; Valid Loss of 2.55688 ; Accuracy of 0.49316\n","Epoch 29 : Train Loss of 1.05278 ; Valid Loss of 2.53620 ; Accuracy of 0.49414\n","Epoch 30 : Train Loss of 1.03970 ; Valid Loss of 2.55003 ; Accuracy of 0.50293\n","Epoch 31 : Train Loss of 1.05542 ; Valid Loss of 2.52501 ; Accuracy of 0.50000\n","Epoch 32 : Train Loss of 1.04464 ; Valid Loss of 2.58016 ; Accuracy of 0.49414\n","Epoch 33 : Train Loss of 1.04815 ; Valid Loss of 2.52278 ; Accuracy of 0.50098\n","Epoch 34 : Train Loss of 1.04426 ; Valid Loss of 2.50266 ; Accuracy of 0.49609\n","Epoch 35 : Train Loss of 1.03057 ; Valid Loss of 2.48535 ; Accuracy of 0.50586\n","Epoch 36 : Train Loss of 1.01864 ; Valid Loss of 2.50106 ; Accuracy of 0.49902\n","Epoch 37 : Train Loss of 1.03156 ; Valid Loss of 2.45888 ; Accuracy of 0.51172\n","Epoch 38 : Train Loss of 1.02428 ; Valid Loss of 2.51223 ; Accuracy of 0.49512\n","Epoch 39 : Train Loss of 1.02363 ; Valid Loss of 2.47153 ; Accuracy of 0.50879\n","Epoch 40 : Train Loss of 1.01906 ; Valid Loss of 2.47782 ; Accuracy of 0.50879\n","Epoch 41 : Train Loss of 1.01405 ; Valid Loss of 2.43775 ; Accuracy of 0.50586\n","Epoch 42 : Train Loss of 1.00452 ; Valid Loss of 2.46402 ; Accuracy of 0.51465\n","Epoch 43 : Train Loss of 1.00338 ; Valid Loss of 2.48609 ; Accuracy of 0.50586\n","Epoch 44 : Train Loss of 1.00250 ; Valid Loss of 2.49908 ; Accuracy of 0.50488\n","Epoch 45 : Train Loss of 0.99818 ; Valid Loss of 2.47456 ; Accuracy of 0.50684\n","Epoch 46 : Train Loss of 0.98996 ; Valid Loss of 2.44484 ; Accuracy of 0.50684\n","Epoch 47 : Train Loss of 0.99759 ; Valid Loss of 2.48497 ; Accuracy of 0.51367\n","Epoch 48 : Train Loss of 0.99605 ; Valid Loss of 2.50556 ; Accuracy of 0.50684\n","Epoch 49 : Train Loss of 0.98254 ; Valid Loss of 2.49962 ; Accuracy of 0.50977\n","Epoch 50 : Train Loss of 0.98733 ; Valid Loss of 2.46200 ; Accuracy of 0.51758\n","Epoch 51 : Train Loss of 0.98372 ; Valid Loss of 2.48921 ; Accuracy of 0.50879\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c3b6978>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.54807\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c3b6a20>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.51622 ; Valid Loss of 1.96397 ; Accuracy of 0.50879\n","Epoch 2 : Train Loss of 1.36798 ; Valid Loss of 2.03913 ; Accuracy of 0.51074\n","Epoch 3 : Train Loss of 1.30840 ; Valid Loss of 2.09728 ; Accuracy of 0.51562\n","Epoch 4 : Train Loss of 1.26353 ; Valid Loss of 2.13480 ; Accuracy of 0.51465\n","Epoch 5 : Train Loss of 1.24861 ; Valid Loss of 2.16910 ; Accuracy of 0.50684\n","Epoch 6 : Train Loss of 1.22020 ; Valid Loss of 2.20496 ; Accuracy of 0.51074\n","Epoch 7 : Train Loss of 1.21466 ; Valid Loss of 2.19794 ; Accuracy of 0.50879\n","Epoch 8 : Train Loss of 1.18324 ; Valid Loss of 2.25551 ; Accuracy of 0.51367\n","Epoch 9 : Train Loss of 1.17985 ; Valid Loss of 2.23286 ; Accuracy of 0.51074\n","Epoch 10 : Train Loss of 1.16353 ; Valid Loss of 2.21019 ; Accuracy of 0.52930\n","Epoch 11 : Train Loss of 1.15023 ; Valid Loss of 2.29020 ; Accuracy of 0.51367\n","Epoch 12 : Train Loss of 1.14654 ; Valid Loss of 2.25083 ; Accuracy of 0.51758\n","Epoch 13 : Train Loss of 1.13013 ; Valid Loss of 2.27931 ; Accuracy of 0.50977\n","Epoch 14 : Train Loss of 1.12797 ; Valid Loss of 2.25998 ; Accuracy of 0.51562\n","Epoch 15 : Train Loss of 1.11399 ; Valid Loss of 2.28233 ; Accuracy of 0.51074\n","Epoch 16 : Train Loss of 1.10254 ; Valid Loss of 2.29994 ; Accuracy of 0.51855\n","Epoch 17 : Train Loss of 1.10532 ; Valid Loss of 2.26394 ; Accuracy of 0.51270\n","Epoch 18 : Train Loss of 1.08707 ; Valid Loss of 2.31428 ; Accuracy of 0.50977\n","Epoch 19 : Train Loss of 1.07960 ; Valid Loss of 2.29663 ; Accuracy of 0.51562\n","Epoch 20 : Train Loss of 1.08709 ; Valid Loss of 2.30841 ; Accuracy of 0.51074\n","Epoch 21 : Train Loss of 1.08441 ; Valid Loss of 2.37415 ; Accuracy of 0.51465\n","Epoch 22 : Train Loss of 1.07543 ; Valid Loss of 2.30896 ; Accuracy of 0.51074\n","Epoch 23 : Train Loss of 1.06435 ; Valid Loss of 2.34153 ; Accuracy of 0.51172\n","Epoch 24 : Train Loss of 1.05264 ; Valid Loss of 2.28168 ; Accuracy of 0.51953\n","Epoch 25 : Train Loss of 1.05678 ; Valid Loss of 2.30407 ; Accuracy of 0.52246\n","Epoch 26 : Train Loss of 1.05376 ; Valid Loss of 2.33643 ; Accuracy of 0.51465\n","Epoch 27 : Train Loss of 1.04148 ; Valid Loss of 2.34184 ; Accuracy of 0.51367\n","Epoch 28 : Train Loss of 1.04308 ; Valid Loss of 2.30723 ; Accuracy of 0.51562\n","Epoch 29 : Train Loss of 1.03873 ; Valid Loss of 2.33190 ; Accuracy of 0.51758\n","Epoch 30 : Train Loss of 1.02844 ; Valid Loss of 2.30958 ; Accuracy of 0.51465\n","Epoch 31 : Train Loss of 1.03025 ; Valid Loss of 2.28219 ; Accuracy of 0.52637\n","Epoch 32 : Train Loss of 1.02013 ; Valid Loss of 2.36437 ; Accuracy of 0.51953\n","Epoch 33 : Train Loss of 1.02350 ; Valid Loss of 2.37091 ; Accuracy of 0.51465\n","Epoch 34 : Train Loss of 1.03143 ; Valid Loss of 2.32934 ; Accuracy of 0.52832\n","Epoch 35 : Train Loss of 1.00736 ; Valid Loss of 2.36037 ; Accuracy of 0.51074\n","Epoch 36 : Train Loss of 1.01236 ; Valid Loss of 2.30068 ; Accuracy of 0.52930\n","Epoch 37 : Train Loss of 1.00955 ; Valid Loss of 2.33768 ; Accuracy of 0.52051\n","Epoch 38 : Train Loss of 1.01534 ; Valid Loss of 2.32945 ; Accuracy of 0.52637\n","Epoch 39 : Train Loss of 1.00274 ; Valid Loss of 2.33289 ; Accuracy of 0.51660\n","Epoch 40 : Train Loss of 0.99971 ; Valid Loss of 2.31753 ; Accuracy of 0.51758\n","Epoch 41 : Train Loss of 0.99933 ; Valid Loss of 2.42482 ; Accuracy of 0.50781\n","Epoch 42 : Train Loss of 0.99733 ; Valid Loss of 2.35962 ; Accuracy of 0.51465\n","Epoch 43 : Train Loss of 0.99625 ; Valid Loss of 2.35100 ; Accuracy of 0.51465\n","Epoch 44 : Train Loss of 0.98830 ; Valid Loss of 2.27812 ; Accuracy of 0.52441\n","Epoch 45 : Train Loss of 0.98198 ; Valid Loss of 2.35777 ; Accuracy of 0.52734\n","Epoch 46 : Train Loss of 0.98116 ; Valid Loss of 2.36670 ; Accuracy of 0.52246\n","Epoch 47 : Train Loss of 0.98016 ; Valid Loss of 2.36803 ; Accuracy of 0.52734\n","Epoch 48 : Train Loss of 0.97593 ; Valid Loss of 2.39442 ; Accuracy of 0.52344\n","Epoch 49 : Train Loss of 0.97927 ; Valid Loss of 2.41750 ; Accuracy of 0.51270\n","Epoch 50 : Train Loss of 0.97278 ; Valid Loss of 2.34698 ; Accuracy of 0.51855\n","Epoch 51 : Train Loss of 0.97104 ; Valid Loss of 2.32421 ; Accuracy of 0.52832\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea664e0>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.58993\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea687b8>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.54557 ; Valid Loss of 1.81512 ; Accuracy of 0.54395\n","Epoch 2 : Train Loss of 1.39364 ; Valid Loss of 1.86330 ; Accuracy of 0.54785\n","Epoch 3 : Train Loss of 1.34737 ; Valid Loss of 1.94479 ; Accuracy of 0.53418\n","Epoch 4 : Train Loss of 1.30114 ; Valid Loss of 1.92265 ; Accuracy of 0.53125\n","Epoch 5 : Train Loss of 1.28402 ; Valid Loss of 1.96565 ; Accuracy of 0.53906\n","Epoch 6 : Train Loss of 1.26912 ; Valid Loss of 2.03083 ; Accuracy of 0.52441\n","Epoch 7 : Train Loss of 1.25213 ; Valid Loss of 1.99739 ; Accuracy of 0.53516\n","Epoch 8 : Train Loss of 1.22639 ; Valid Loss of 2.06097 ; Accuracy of 0.53125\n","Epoch 9 : Train Loss of 1.22276 ; Valid Loss of 2.02088 ; Accuracy of 0.54297\n","Epoch 10 : Train Loss of 1.19760 ; Valid Loss of 2.10084 ; Accuracy of 0.53320\n","Epoch 11 : Train Loss of 1.20210 ; Valid Loss of 2.06332 ; Accuracy of 0.54004\n","Epoch 12 : Train Loss of 1.17599 ; Valid Loss of 2.08121 ; Accuracy of 0.53125\n","Epoch 13 : Train Loss of 1.15942 ; Valid Loss of 2.12986 ; Accuracy of 0.53320\n","Epoch 14 : Train Loss of 1.15214 ; Valid Loss of 2.07316 ; Accuracy of 0.53906\n","Epoch 15 : Train Loss of 1.14779 ; Valid Loss of 2.08757 ; Accuracy of 0.53613\n","Epoch 16 : Train Loss of 1.13575 ; Valid Loss of 2.10504 ; Accuracy of 0.53906\n","Epoch 17 : Train Loss of 1.12687 ; Valid Loss of 2.19900 ; Accuracy of 0.52441\n","Epoch 18 : Train Loss of 1.13860 ; Valid Loss of 2.15421 ; Accuracy of 0.53125\n","Epoch 19 : Train Loss of 1.12358 ; Valid Loss of 2.18767 ; Accuracy of 0.51953\n","Epoch 20 : Train Loss of 1.11060 ; Valid Loss of 2.15627 ; Accuracy of 0.52637\n","Epoch 21 : Train Loss of 1.09902 ; Valid Loss of 2.14005 ; Accuracy of 0.53613\n","Epoch 22 : Train Loss of 1.10731 ; Valid Loss of 2.18280 ; Accuracy of 0.52930\n","Epoch 23 : Train Loss of 1.08916 ; Valid Loss of 2.14175 ; Accuracy of 0.52832\n","Epoch 24 : Train Loss of 1.08653 ; Valid Loss of 2.11992 ; Accuracy of 0.52930\n","Epoch 25 : Train Loss of 1.08138 ; Valid Loss of 2.17018 ; Accuracy of 0.53809\n","Epoch 26 : Train Loss of 1.06663 ; Valid Loss of 2.15904 ; Accuracy of 0.52734\n","Epoch 27 : Train Loss of 1.06888 ; Valid Loss of 2.15649 ; Accuracy of 0.52930\n","Epoch 28 : Train Loss of 1.05774 ; Valid Loss of 2.18780 ; Accuracy of 0.52246\n","Epoch 29 : Train Loss of 1.06000 ; Valid Loss of 2.24414 ; Accuracy of 0.51270\n","Epoch 30 : Train Loss of 1.05286 ; Valid Loss of 2.16937 ; Accuracy of 0.53320\n","Epoch 31 : Train Loss of 1.04502 ; Valid Loss of 2.17507 ; Accuracy of 0.52832\n","Epoch 32 : Train Loss of 1.03856 ; Valid Loss of 2.21639 ; Accuracy of 0.52637\n","Epoch 33 : Train Loss of 1.04946 ; Valid Loss of 2.17779 ; Accuracy of 0.52441\n","Epoch 34 : Train Loss of 1.04390 ; Valid Loss of 2.23302 ; Accuracy of 0.52148\n","Epoch 35 : Train Loss of 1.03090 ; Valid Loss of 2.17967 ; Accuracy of 0.51953\n","Epoch 36 : Train Loss of 1.02891 ; Valid Loss of 2.14722 ; Accuracy of 0.53711\n","Epoch 37 : Train Loss of 1.01883 ; Valid Loss of 2.21770 ; Accuracy of 0.52246\n","Epoch 38 : Train Loss of 1.02797 ; Valid Loss of 2.18738 ; Accuracy of 0.53320\n","Epoch 39 : Train Loss of 1.01613 ; Valid Loss of 2.17003 ; Accuracy of 0.53027\n","Epoch 40 : Train Loss of 1.01000 ; Valid Loss of 2.20221 ; Accuracy of 0.53516\n","Epoch 41 : Train Loss of 1.00999 ; Valid Loss of 2.14079 ; Accuracy of 0.54492\n","Epoch 42 : Train Loss of 1.00082 ; Valid Loss of 2.23284 ; Accuracy of 0.53418\n","Epoch 43 : Train Loss of 1.00757 ; Valid Loss of 2.21970 ; Accuracy of 0.52246\n","Epoch 44 : Train Loss of 1.00148 ; Valid Loss of 2.19944 ; Accuracy of 0.53906\n","Epoch 45 : Train Loss of 0.99103 ; Valid Loss of 2.16782 ; Accuracy of 0.53906\n","Epoch 46 : Train Loss of 1.00074 ; Valid Loss of 2.20001 ; Accuracy of 0.53613\n","Epoch 47 : Train Loss of 0.99373 ; Valid Loss of 2.18674 ; Accuracy of 0.53223\n","Epoch 48 : Train Loss of 0.98626 ; Valid Loss of 2.14347 ; Accuracy of 0.54492\n","Epoch 49 : Train Loss of 0.98312 ; Valid Loss of 2.26092 ; Accuracy of 0.52539\n","Epoch 50 : Train Loss of 0.98111 ; Valid Loss of 2.18401 ; Accuracy of 0.53418\n","Epoch 51 : Train Loss of 0.98658 ; Valid Loss of 2.24665 ; Accuracy of 0.53320\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea68e48>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.67891\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea68ef0>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.61210 ; Valid Loss of 2.32563 ; Accuracy of 0.50391\n","Epoch 2 : Train Loss of 1.41051 ; Valid Loss of 2.37213 ; Accuracy of 0.50488\n","Epoch 3 : Train Loss of 1.33071 ; Valid Loss of 2.36213 ; Accuracy of 0.50879\n","Epoch 4 : Train Loss of 1.29618 ; Valid Loss of 2.49142 ; Accuracy of 0.49902\n","Epoch 5 : Train Loss of 1.26897 ; Valid Loss of 2.49465 ; Accuracy of 0.50000\n","Epoch 6 : Train Loss of 1.24830 ; Valid Loss of 2.51345 ; Accuracy of 0.51074\n","Epoch 7 : Train Loss of 1.23041 ; Valid Loss of 2.55515 ; Accuracy of 0.50098\n","Epoch 8 : Train Loss of 1.22038 ; Valid Loss of 2.59792 ; Accuracy of 0.49609\n","Epoch 9 : Train Loss of 1.20695 ; Valid Loss of 2.55877 ; Accuracy of 0.50391\n","Epoch 10 : Train Loss of 1.19865 ; Valid Loss of 2.62037 ; Accuracy of 0.49902\n","Epoch 11 : Train Loss of 1.18890 ; Valid Loss of 2.58305 ; Accuracy of 0.49609\n","Epoch 12 : Train Loss of 1.17120 ; Valid Loss of 2.57746 ; Accuracy of 0.49707\n","Epoch 13 : Train Loss of 1.16047 ; Valid Loss of 2.57051 ; Accuracy of 0.50098\n","Epoch 14 : Train Loss of 1.14802 ; Valid Loss of 2.60599 ; Accuracy of 0.49219\n","Epoch 15 : Train Loss of 1.14359 ; Valid Loss of 2.61280 ; Accuracy of 0.49316\n","Epoch 16 : Train Loss of 1.13706 ; Valid Loss of 2.57429 ; Accuracy of 0.50293\n","Epoch 17 : Train Loss of 1.12030 ; Valid Loss of 2.55302 ; Accuracy of 0.50195\n","Epoch 18 : Train Loss of 1.12474 ; Valid Loss of 2.55616 ; Accuracy of 0.51270\n","Epoch 19 : Train Loss of 1.11477 ; Valid Loss of 2.54503 ; Accuracy of 0.50488\n","Epoch 20 : Train Loss of 1.09854 ; Valid Loss of 2.52720 ; Accuracy of 0.50586\n","Epoch 21 : Train Loss of 1.10570 ; Valid Loss of 2.60378 ; Accuracy of 0.49902\n","Epoch 22 : Train Loss of 1.07935 ; Valid Loss of 2.53461 ; Accuracy of 0.49902\n","Epoch 23 : Train Loss of 1.08524 ; Valid Loss of 2.56254 ; Accuracy of 0.50391\n","Epoch 24 : Train Loss of 1.08570 ; Valid Loss of 2.56891 ; Accuracy of 0.50488\n","Epoch 25 : Train Loss of 1.06158 ; Valid Loss of 2.57860 ; Accuracy of 0.50195\n","Epoch 26 : Train Loss of 1.07259 ; Valid Loss of 2.52359 ; Accuracy of 0.51270\n","Epoch 27 : Train Loss of 1.07047 ; Valid Loss of 2.58730 ; Accuracy of 0.50781\n","Epoch 28 : Train Loss of 1.06236 ; Valid Loss of 2.48853 ; Accuracy of 0.50684\n","Epoch 29 : Train Loss of 1.06145 ; Valid Loss of 2.57887 ; Accuracy of 0.49707\n","Epoch 30 : Train Loss of 1.05763 ; Valid Loss of 2.51831 ; Accuracy of 0.50586\n","Epoch 31 : Train Loss of 1.03985 ; Valid Loss of 2.56764 ; Accuracy of 0.50293\n","Epoch 32 : Train Loss of 1.04117 ; Valid Loss of 2.48729 ; Accuracy of 0.51270\n","Epoch 33 : Train Loss of 1.04023 ; Valid Loss of 2.49967 ; Accuracy of 0.52344\n","Epoch 34 : Train Loss of 1.03933 ; Valid Loss of 2.48251 ; Accuracy of 0.51367\n","Epoch 35 : Train Loss of 1.03474 ; Valid Loss of 2.50086 ; Accuracy of 0.50781\n","Epoch 36 : Train Loss of 1.03351 ; Valid Loss of 2.53653 ; Accuracy of 0.50293\n","Epoch 37 : Train Loss of 1.01576 ; Valid Loss of 2.55071 ; Accuracy of 0.50879\n","Epoch 38 : Train Loss of 1.01922 ; Valid Loss of 2.54971 ; Accuracy of 0.51465\n","Epoch 39 : Train Loss of 1.01106 ; Valid Loss of 2.56872 ; Accuracy of 0.50879\n","Epoch 40 : Train Loss of 1.01457 ; Valid Loss of 2.50991 ; Accuracy of 0.51367\n","Epoch 41 : Train Loss of 1.01027 ; Valid Loss of 2.53250 ; Accuracy of 0.50977\n","Epoch 42 : Train Loss of 1.00193 ; Valid Loss of 2.41904 ; Accuracy of 0.52246\n","Epoch 43 : Train Loss of 0.99559 ; Valid Loss of 2.53315 ; Accuracy of 0.51270\n","Epoch 44 : Train Loss of 0.99244 ; Valid Loss of 2.48239 ; Accuracy of 0.52051\n","Epoch 45 : Train Loss of 1.00688 ; Valid Loss of 2.55074 ; Accuracy of 0.50293\n","Epoch 46 : Train Loss of 0.98255 ; Valid Loss of 2.49249 ; Accuracy of 0.51562\n","Epoch 47 : Train Loss of 0.98474 ; Valid Loss of 2.50228 ; Accuracy of 0.51758\n","Epoch 48 : Train Loss of 0.98743 ; Valid Loss of 2.53447 ; Accuracy of 0.50684\n","Epoch 49 : Train Loss of 0.98830 ; Valid Loss of 2.56984 ; Accuracy of 0.50488\n","Epoch 50 : Train Loss of 0.98608 ; Valid Loss of 2.49361 ; Accuracy of 0.51953\n","Epoch 51 : Train Loss of 0.97959 ; Valid Loss of 2.52762 ; Accuracy of 0.51660\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c08d0>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.61520\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261c3b6da0>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.61881 ; Valid Loss of 2.00025 ; Accuracy of 0.54492\n","Epoch 2 : Train Loss of 1.43447 ; Valid Loss of 2.07624 ; Accuracy of 0.53027\n","Epoch 3 : Train Loss of 1.35347 ; Valid Loss of 2.07249 ; Accuracy of 0.52441\n","Epoch 4 : Train Loss of 1.32928 ; Valid Loss of 2.05521 ; Accuracy of 0.52734\n","Epoch 5 : Train Loss of 1.30101 ; Valid Loss of 2.14837 ; Accuracy of 0.50684\n","Epoch 6 : Train Loss of 1.28950 ; Valid Loss of 2.18711 ; Accuracy of 0.50977\n","Epoch 7 : Train Loss of 1.27279 ; Valid Loss of 2.17557 ; Accuracy of 0.51172\n","Epoch 8 : Train Loss of 1.25049 ; Valid Loss of 2.18317 ; Accuracy of 0.50684\n","Epoch 9 : Train Loss of 1.22924 ; Valid Loss of 2.21724 ; Accuracy of 0.51172\n","Epoch 10 : Train Loss of 1.22016 ; Valid Loss of 2.18160 ; Accuracy of 0.51855\n","Epoch 11 : Train Loss of 1.20390 ; Valid Loss of 2.21598 ; Accuracy of 0.52148\n","Epoch 12 : Train Loss of 1.19033 ; Valid Loss of 2.19803 ; Accuracy of 0.51367\n","Epoch 13 : Train Loss of 1.17458 ; Valid Loss of 2.24462 ; Accuracy of 0.51270\n","Epoch 14 : Train Loss of 1.16543 ; Valid Loss of 2.20060 ; Accuracy of 0.52930\n","Epoch 15 : Train Loss of 1.17044 ; Valid Loss of 2.22112 ; Accuracy of 0.51270\n","Epoch 16 : Train Loss of 1.16203 ; Valid Loss of 2.24591 ; Accuracy of 0.52441\n","Epoch 17 : Train Loss of 1.14974 ; Valid Loss of 2.28065 ; Accuracy of 0.52051\n","Epoch 18 : Train Loss of 1.13676 ; Valid Loss of 2.30522 ; Accuracy of 0.51465\n","Epoch 19 : Train Loss of 1.13791 ; Valid Loss of 2.28163 ; Accuracy of 0.51465\n","Epoch 20 : Train Loss of 1.12679 ; Valid Loss of 2.30349 ; Accuracy of 0.51562\n","Epoch 21 : Train Loss of 1.12737 ; Valid Loss of 2.20540 ; Accuracy of 0.52148\n","Epoch 22 : Train Loss of 1.11465 ; Valid Loss of 2.22968 ; Accuracy of 0.52344\n","Epoch 23 : Train Loss of 1.10194 ; Valid Loss of 2.27504 ; Accuracy of 0.53125\n","Epoch 24 : Train Loss of 1.09405 ; Valid Loss of 2.23828 ; Accuracy of 0.51953\n","Epoch 25 : Train Loss of 1.09374 ; Valid Loss of 2.24907 ; Accuracy of 0.52539\n","Epoch 26 : Train Loss of 1.09499 ; Valid Loss of 2.30509 ; Accuracy of 0.52637\n","Epoch 27 : Train Loss of 1.07795 ; Valid Loss of 2.30365 ; Accuracy of 0.53125\n","Epoch 28 : Train Loss of 1.08212 ; Valid Loss of 2.29132 ; Accuracy of 0.53223\n","Epoch 29 : Train Loss of 1.08011 ; Valid Loss of 2.30892 ; Accuracy of 0.52930\n","Epoch 30 : Train Loss of 1.07563 ; Valid Loss of 2.31380 ; Accuracy of 0.53613\n","Epoch 31 : Train Loss of 1.07032 ; Valid Loss of 2.27665 ; Accuracy of 0.54297\n","Epoch 32 : Train Loss of 1.05395 ; Valid Loss of 2.25798 ; Accuracy of 0.54199\n","Epoch 33 : Train Loss of 1.04620 ; Valid Loss of 2.27209 ; Accuracy of 0.53809\n","Epoch 34 : Train Loss of 1.04212 ; Valid Loss of 2.21887 ; Accuracy of 0.54102\n","Epoch 35 : Train Loss of 1.05302 ; Valid Loss of 2.27711 ; Accuracy of 0.54297\n","Epoch 36 : Train Loss of 1.05594 ; Valid Loss of 2.31770 ; Accuracy of 0.53711\n","Epoch 37 : Train Loss of 1.03703 ; Valid Loss of 2.32656 ; Accuracy of 0.53027\n","Epoch 38 : Train Loss of 1.03269 ; Valid Loss of 2.31311 ; Accuracy of 0.53125\n","Epoch 39 : Train Loss of 1.01843 ; Valid Loss of 2.30633 ; Accuracy of 0.54297\n","Epoch 40 : Train Loss of 1.03056 ; Valid Loss of 2.27397 ; Accuracy of 0.53516\n","Epoch 41 : Train Loss of 1.03573 ; Valid Loss of 2.31886 ; Accuracy of 0.53223\n","Epoch 42 : Train Loss of 1.02852 ; Valid Loss of 2.28802 ; Accuracy of 0.53418\n","Epoch 43 : Train Loss of 1.02386 ; Valid Loss of 2.37428 ; Accuracy of 0.53906\n","Epoch 44 : Train Loss of 1.02387 ; Valid Loss of 2.31488 ; Accuracy of 0.52441\n","Epoch 45 : Train Loss of 1.01250 ; Valid Loss of 2.34455 ; Accuracy of 0.53125\n","Epoch 46 : Train Loss of 1.00292 ; Valid Loss of 2.31462 ; Accuracy of 0.54102\n","Epoch 47 : Train Loss of 1.00267 ; Valid Loss of 2.28329 ; Accuracy of 0.54102\n","Epoch 48 : Train Loss of 1.00513 ; Valid Loss of 2.35001 ; Accuracy of 0.52734\n","Epoch 49 : Train Loss of 0.99542 ; Valid Loss of 2.28206 ; Accuracy of 0.53516\n","Epoch 50 : Train Loss of 0.99870 ; Valid Loss of 2.28275 ; Accuracy of 0.52832\n","Epoch 51 : Train Loss of 0.99800 ; Valid Loss of 2.29278 ; Accuracy of 0.53906\n","Early Stopping, Best Optimal Number of Epoch is 1\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f25e97c0e10>\n","Training For Optimal Number of Epochs 1 Based on Early Stopping\n","Epoch 0 : Entire Train Loss of 1.52786\n","Proportion of 1 is for train set is : 0.20389982556690756\n","Proportion of 1 is for valid set is : 0.5412280701754386\n","Proportion of 1 is for test set is : 0.0\n","torch.Size([48156, 1])\n","<torch.optim.lr_scheduler.LambdaLR object at 0x7f261ea66e80>\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1 : Train Loss of 1.64075 ; Valid Loss of 1.87565 ; Accuracy of 0.47852\n","Epoch 2 : Train Loss of 1.41508 ; Valid Loss of 2.01122 ; Accuracy of 0.50391\n","Epoch 3 : Train Loss of 1.34191 ; Valid Loss of 2.04490 ; Accuracy of 0.49902\n","Epoch 4 : Train Loss of 1.30946 ; Valid Loss of 2.07374 ; Accuracy of 0.49121\n","Epoch 5 : Train Loss of 1.27930 ; Valid Loss of 2.08159 ; Accuracy of 0.50293\n","Epoch 6 : Train Loss of 1.27120 ; Valid Loss of 2.16789 ; Accuracy of 0.47852\n","Epoch 7 : Train Loss of 1.23427 ; Valid Loss of 2.13265 ; Accuracy of 0.49512\n","Epoch 8 : Train Loss of 1.21638 ; Valid Loss of 2.15372 ; Accuracy of 0.49805\n","Epoch 9 : Train Loss of 1.21070 ; Valid Loss of 2.24018 ; Accuracy of 0.48828\n","Epoch 10 : Train Loss of 1.20425 ; Valid Loss of 2.20021 ; Accuracy of 0.50293\n","Epoch 11 : Train Loss of 1.19377 ; Valid Loss of 2.23568 ; Accuracy of 0.48438\n","Epoch 12 : Train Loss of 1.17137 ; Valid Loss of 2.19601 ; Accuracy of 0.50000\n","Epoch 13 : Train Loss of 1.15839 ; Valid Loss of 2.22780 ; Accuracy of 0.49121\n","Epoch 14 : Train Loss of 1.16140 ; Valid Loss of 2.25255 ; Accuracy of 0.49805\n","Epoch 15 : Train Loss of 1.13826 ; Valid Loss of 2.26323 ; Accuracy of 0.47852\n","Epoch 16 : Train Loss of 1.14245 ; Valid Loss of 2.27142 ; Accuracy of 0.49414\n","Epoch 17 : Train Loss of 1.12352 ; Valid Loss of 2.24908 ; Accuracy of 0.48926\n","Epoch 18 : Train Loss of 1.12530 ; Valid Loss of 2.24356 ; Accuracy of 0.50098\n","Epoch 19 : Train Loss of 1.10756 ; Valid Loss of 2.27578 ; Accuracy of 0.50488\n","Epoch 20 : Train Loss of 1.10768 ; Valid Loss of 2.27084 ; Accuracy of 0.49707\n","Epoch 21 : Train Loss of 1.10480 ; Valid Loss of 2.32816 ; Accuracy of 0.49512\n","Epoch 22 : Train Loss of 1.09489 ; Valid Loss of 2.27160 ; Accuracy of 0.49512\n","Epoch 23 : Train Loss of 1.08891 ; Valid Loss of 2.29962 ; Accuracy of 0.49121\n","Epoch 24 : Train Loss of 1.07754 ; Valid Loss of 2.32779 ; Accuracy of 0.50195\n","Epoch 25 : Train Loss of 1.08369 ; Valid Loss of 2.23092 ; Accuracy of 0.50488\n","Epoch 26 : Train Loss of 1.07287 ; Valid Loss of 2.31074 ; Accuracy of 0.50391\n","Epoch 27 : Train Loss of 1.07107 ; Valid Loss of 2.32271 ; Accuracy of 0.50293\n","Epoch 28 : Train Loss of 1.06470 ; Valid Loss of 2.36412 ; Accuracy of 0.49023\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tUTnTrk9nhFn"},"source":["import pickle\n","def save_obj(path, object):\n","    with open(path,'wb') as file:\n","        pickle.dump(object, file, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(path):\n","    with open(path, 'rb') as file:\n","        object = pickle.load(file)\n","    return object"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1aCyL5ink1s"},"source":["import pathlib\n","model_name = 'total'\n","date = '2020-10-06'\n","output_dir = pathlib.Path.cwd().parent / 'output'\n","fname = str(output_dir) + f'/{model_name}_{date}_output.pickle'\n","save_obj(fname, all_predictions)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkuKBgvrT2c7"},"source":["df_all = pd.concat(list(all_predictions.values()), axis = 0)\n","df_all.index = list(all_predictions.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sIXsqUGgULHV","executionInfo":{"status":"ok","timestamp":1602028101047,"user_tz":420,"elapsed":343,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"3e8ffc3d-3b21-46a6-a5b2-eaefee1ff6a3","colab":{"base_uri":"https://localhost:8080/"}},"source":["df_all.mean(axis = 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["216    0.469677\n","217    0.478509\n","218    0.463549\n","220    0.403555\n","221    0.428346\n","dtype: float32"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"QPw2wAVpUTbG","executionInfo":{"status":"ok","timestamp":1602028136001,"user_tz":420,"elapsed":335,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"52470be0-78cf-4970-92f8-4c4c17a12293","colab":{"base_uri":"https://localhost:8080/"}},"source":["'year' in all_features"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"xF5NKqh_Tqag","executionInfo":{"status":"ok","timestamp":1602027961001,"user_tz":420,"elapsed":320,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"b2ed5ddc-bab0-4a3a-d18c-8d8a15bfd672","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(fname)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Stanford SCPD/CS221/project/output/<module 'model' from '/content/drive/My Drive/Stanford SCPD/CS221/project/code/model.py'>_2020-10-06_output.pickle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m2Mbzll-4xK_","executionInfo":{"status":"ok","timestamp":1601886694900,"user_tz":420,"elapsed":716,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"5a88a0de-2657-411c-932b-c5525b6fe3f4","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["print(predictions)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{1: array([[0.4962696]], dtype=float32), 2: array([[0.5658849]], dtype=float32), 3: array([[0.55123526]], dtype=float32), 4: array([[0.51773494]], dtype=float32), 5: array([[0.5798069]], dtype=float32), 6: array([[0.61747384]], dtype=float32), 7: array([[0.5921563]], dtype=float32), 8: array([[0.51920474]], dtype=float32), 9: array([[0.5440958]], dtype=float32)}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N9MIlAIIsKo7"},"source":["ppp = {k : v.ravel() for k,v in predictions.items()}\n","pr = pd.DataFrame(ppp)\n","# probb = pr.mean(axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LLuQQGw42Qq","executionInfo":{"status":"ok","timestamp":1601886743645,"user_tz":420,"elapsed":328,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"d1728e55-10a4-4dd7-81bf-7f6f75bb9892","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["pr.mean(axis = 1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0.553762\n","dtype: float32"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"RfjqL7vd5DWK","executionInfo":{"status":"ok","timestamp":1601887012218,"user_tz":420,"elapsed":572,"user":{"displayName":"Jia Shuo Zhou","photoUrl":"","userId":"04669318006565986848"}},"outputId":"b85dacd3-1969-4a40-9710-0bafa338f3ff","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_pred_binary"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ True]])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"pPuaYhJX6AL3"},"source":[""],"execution_count":null,"outputs":[]}]}